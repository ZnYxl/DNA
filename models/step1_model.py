# models/step1_model.py - å®Œæ•´ä¿®å¤ç‰ˆ
import torch
import torch.nn as nn
import torch.nn.functional as F
from models.Model import Encoder, RNNBlock
from utils.Loss import CEBayesRiskLoss, KLDivergenceLoss
import numpy as np

class Step1EvidentialModel(nn.Module):
    """
    æ­¥éª¤ä¸€ï¼šEvidence-drivenè®­ç»ƒæ¨¡å‹ï¼ˆä¸¥æ ¼è‡ªç›‘ç£ç‰ˆæœ¬ï¼‰
    â— GTåªç”¨äºè¯„ä¼°ï¼Œä¸å‚ä¸è®­ç»ƒloss
    """
    def __init__(self, 
                 dim=256, 
                 max_length=150,
                 num_clusters=50,
                 device='cuda'):
        super().__init__()
        
        # ===== FedDNA æ ¸å¿ƒç»„ä»¶ =====
        self.encoder = Encoder(dim=dim)
        
        # âœ… ä¿®å¤ï¼šåŠ¨æ€é€‚é…length_adapter
        self.length_adapter = None  # å»¶è¿Ÿåˆå§‹åŒ–
        
        self.rnnblock = RNNBlock(in_channels=dim, lstm_hidden_dim=256, rnn_dropout_p=0.1)
        
        # ===== å¯¹æ¯”å­¦ä¹ ç»„ä»¶ =====
        self.projection_head = nn.Sequential(
            nn.Linear(dim, dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(dim, 128)
        )
        
        self.dim = dim
        self.max_length = max_length
        self.num_clusters = num_clusters
        self.device = device
    
    def _init_length_adapter_if_needed(self, seq_len):
        """å»¶è¿Ÿåˆå§‹åŒ–length_adapterï¼Œé¿å…å½¢çŠ¶ä¸åŒ¹é…"""
        if self.length_adapter is None:
            self.length_adapter = nn.Linear(seq_len, self.max_length).to(self.device)
            print(f"   ğŸ”§ åŠ¨æ€åˆå§‹åŒ–length_adapter: {seq_len} -> {self.max_length}")
    
    def encode_reads(self, reads):
        """
        âœ… ä½¿ç”¨FedDNA Encoderç¼–ç reads
        Args:
            reads: (B, L, 4) æ‰¹æ¬¡ä¸­çš„reads
        Returns:
            embeddings: (B, L, dim) ç¼–ç åçš„ç‰¹å¾
            pooled_emb: (B, dim) æ± åŒ–åçš„å…¨å±€ç‰¹å¾
        """
        B, L, D = reads.shape
        
        # FedDNA Encoder: Conv2d + ConMamba
        embeddings = self.encoder(reads)  # (B, L, dim)
        
        # å…¨å±€æ± åŒ–ç”¨äºå¯¹æ¯”å­¦ä¹ 
        pooled_emb = embeddings.mean(dim=1)  # (B, dim)
        
        return embeddings, pooled_emb
    
    def decode_to_evidence(self, embeddings):
        """
        âœ… ä½¿ç”¨FedDNA Decoderç”Ÿæˆevidence
        Args:
            embeddings: (B, L, dim)
        Returns:
            evidence: (B, L, 4) æ¯ä¸ªä½ç½®çš„ACGT evidence
            strength: (B, L) è¯æ®å¼ºåº¦
            alpha: (B, L, 4) Dirichletå‚æ•°
        """
        B, L, D = embeddings.shape
        
        # åŠ¨æ€åˆå§‹åŒ–length_adapter
        self._init_length_adapter_if_needed(L)
        
        # é•¿åº¦é€‚é…
        if L != self.max_length:
            adapted = embeddings.permute(0, 2, 1)  # (B, dim, L)
            adapted = self.length_adapter(adapted)  # (B, dim, max_length)
            adapted = adapted.permute(0, 2, 1)     # (B, max_length, dim)
        else:
            adapted = embeddings
        
        # FedDNA RNN Decoder
        evidence = self.rnnblock(adapted)  # (B, L, 4)
        
        # âœ… æ•°å€¼ç¨³å®šçš„evidenceå¤„ç†
        evidence = torch.clamp(evidence, min=1e-8, max=1e8)  # é˜²æ­¢æå€¼
        
        # æ­£ç¡®çš„evidence strengthè®¡ç®—
        K = evidence.size(-1)  # 4
        alpha = evidence + 1.0
        strength = torch.sum(alpha, dim=-1)  # (B, L)
        
        return evidence, strength, alpha
    
    def contrastive_learning_with_evidence_filter(self, pooled_emb, cluster_labels, strength, 
                                                 temperature=0.1, epoch=0, warmup_epochs=5):
        """
        âœ… ä¿®å¤ç‰ˆï¼šæ‰“ç ´æ­»é”çš„å¯¹æ¯”å­¦ä¹ 
        ç­–ç•¥ï¼š
        1. Warm-upæœŸï¼šæ— æ¡ä»¶ä¿¡ä»»Cloveræ ‡ç­¾ï¼Œå¼ºåˆ¶å­¦ä¹ ç‰¹å¾ã€‚
        2. åæœŸï¼šåˆ©ç”¨Evidenceç­›é€‰é«˜è´¨é‡æ ·æœ¬è¿›è¡Œå¾®è°ƒã€‚
        """
        # ---------------------------------------------------
        # 1ï¸âƒ£ Warm-up é˜¶æ®µï¼šå¼ºåˆ¶å­¦ä¹  (Bootstrap)
        # ---------------------------------------------------
        if epoch < warmup_epochs:
            # ç›´æ¥ä½¿ç”¨æ‰€æœ‰æ ·æœ¬ï¼Œä¸è¿›è¡Œç­›é€‰
            # è¿™ä¸€æ­¥è‡³å…³é‡è¦ï¼æ²¡æœ‰å®ƒï¼Œæ¨¡å‹æ°¸è¿œæ— æ³•å¯åŠ¨ã€‚
            valid_mask = torch.ones_like(strength.mean(dim=1), dtype=torch.bool)
            
            # ä½¿ç”¨ç®€å•çš„ mask (æ‰€æœ‰éå™ªå£°æ ·æœ¬)
            labels_expanded = cluster_labels.unsqueeze(1)
            positive_mask = (labels_expanded == labels_expanded.T).float()
            
            # è‡ªèº«mask
            logits_mask = torch.scatter(
                torch.ones_like(positive_mask),
                1,
                torch.arange(pooled_emb.size(0)).view(-1, 1).to(self.device),
                0
            )
            positive_mask = positive_mask * logits_mask
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            proj_emb = self.projection_head(pooled_emb)
            proj_emb = F.normalize(proj_emb, dim=-1)
            sim_matrix = torch.matmul(proj_emb, proj_emb.T) / temperature
            
            # InfoNCE Loss
            exp_sim = torch.exp(torch.clamp(sim_matrix, max=10))
            numerator = torch.sum(exp_sim * positive_mask, dim=1) + 1e-8
            denominator = torch.sum(exp_sim, dim=1) - torch.diag(exp_sim) + 1e-8
            
            loss = -torch.log(numerator / denominator)
            return loss.mean()

        # ---------------------------------------------------
        # 2ï¸âƒ£ Refinement é˜¶æ®µï¼šEvidence é©±åŠ¨çš„ç­›é€‰
        # ---------------------------------------------------
        if pooled_emb.size(0) < 2:
            return torch.tensor(0.0, device=self.device, requires_grad=True)
        
        confidence = strength.mean(dim=1)
        
        # åŠ¨æ€é˜ˆå€¼ï¼šå–å½“å‰batchçš„å‰60%é«˜ç½®ä¿¡åº¦æ ·æœ¬
        # æ³¨æ„ï¼šè¿™é‡ŒåŠ äº† detach() é˜²æ­¢æ¢¯åº¦å›ä¼ å½±å“é˜ˆå€¼è®¡ç®—ï¼Œè™½ç„¶ quantile æœ¬èº«ä¸å¯å¯¼
        conf_threshold = torch.quantile(confidence.detach(), 0.4) # ä¿ç•™60%
        conf_mask = confidence >= conf_threshold
        
        if conf_mask.sum() < 2:
            # å¦‚æœbatchå†…éƒ½æ²¡ä¿¡å¿ƒï¼Œå›é€€åˆ°ä½¿ç”¨æ‰€æœ‰æ ·æœ¬ï¼Œé¿å…æ¢¯åº¦æ¶ˆå¤±
            conf_mask = torch.ones_like(confidence, dtype=torch.bool)
            
        proj_emb = self.projection_head(pooled_emb)
        proj_emb = F.normalize(proj_emb, dim=-1)
        sim_matrix = torch.matmul(proj_emb, proj_emb.T) / temperature
        
        # æ„å»º Mask: (åŒç°‡) AND (ä¸¤è€…éƒ½æ˜¯é«˜ç½®ä¿¡åº¦)
        labels_expanded = cluster_labels.unsqueeze(1)
        clover_positive_mask = (labels_expanded == labels_expanded.T).float()
        evidence_positive_mask = (conf_mask.unsqueeze(1) & conf_mask.unsqueeze(0)).float()
        
        positive_mask = clover_positive_mask * evidence_positive_mask
        
        # è‡ªèº«å¯¹è§’çº¿è®¾ä¸º0
        logits_mask = torch.scatter(
            torch.ones_like(positive_mask),
            1,
            torch.arange(pooled_emb.size(0)).view(-1, 1).to(self.device),
            0
        )
        positive_mask = positive_mask * logits_mask
        
        exp_sim = torch.exp(torch.clamp(sim_matrix, max=10))
        numerator = torch.sum(exp_sim * positive_mask, dim=1) + 1e-8
        denominator = torch.sum(exp_sim, dim=1) - torch.diag(exp_sim) + 1e-8
        
        loss = -torch.log(numerator / denominator)
        
        # åªå¯¹å‚ä¸è®¡ç®—çš„æ ·æœ¬æ±‚å¹³å‡
        valid_indices = torch.where(torch.sum(positive_mask, dim=1) > 0)[0]
        if len(valid_indices) > 0:
            return loss[valid_indices].mean()
        else:
            return torch.tensor(0.0, device=self.device, requires_grad=True)
    
    def self_reconstruction_loss(self, evidence, alpha, cluster_labels, inputs):  # <--- æ–°å¢ inputs
        """
        âœ… ä¿®å¤ç‰ˆï¼šåŠ å…¥ Input Reconstructionï¼Œé˜²æ­¢ Mode Collapse
        """
        bayes_risk = CEBayesRiskLoss().to(self.device)
        kld_loss_fn = KLDivergenceLoss().to(self.device)

        # 1. æ ¸å¿ƒä¿®å¤ï¼šInput Reconstruction Loss (AE Loss)
        # è®©æ¨¡å‹å¿…é¡»å­¦ä¼šé‡å»ºè¾“å…¥çš„ ATCG åºåˆ—
        # inputs æ˜¯ one-hot ç¼–ç ï¼Œå¯ä»¥ç›´æ¥ä½œä¸º target
        input_recon_loss = bayes_risk(evidence, inputs)

        # --------------------------------------------------------
        # ä¸‹é¢æ˜¯ä½ åŸæ¥çš„ Consensus Loss (å¯ä»¥ä¿ç•™ä½œä¸ºæ­£åˆ™é¡¹ï¼Œä½†è¦é˜²æ­¢ä¸»å¯¼)
        # --------------------------------------------------------
        total_consensus_loss = torch.tensor(0.0, device=self.device, requires_grad=True)
        total_kl_loss = torch.tensor(0.0, device=self.device, requires_grad=True)
        fused_consensus = {}

        unique_labels = torch.unique(cluster_labels)
        processed_clusters = 0

        for label in unique_labels:
            if label < 0: continue
            cluster_mask = (cluster_labels == label)
            if cluster_mask.sum() < 2: continue

            # è·å–æ•°æ®
            cluster_evidence = evidence[cluster_mask]
            
            # è®¡ç®— Consensus (Target)
            # æ³¨æ„ï¼šè¿™é‡Œ detach() å¾ˆé‡è¦ï¼Œé˜²æ­¢æ¢¯åº¦æµå‘ Target å¯¼è‡´"ä½œå¼Š"
            weights = F.softmax(torch.sum(alpha[cluster_mask], dim=-1).mean(dim=1), dim=0).view(-1, 1, 1)
            fused_evidence_val = torch.sum(cluster_evidence * weights, dim=0, keepdim=True).detach() 
            fused_consensus[label.item()] = fused_evidence_val

            # Soft Target for Consistency
            fused_alpha_val = fused_evidence_val + 1.0
            target_prob = (fused_alpha_val / fused_alpha_val.sum(dim=-1, keepdim=True)).expand(cluster_mask.sum(), -1, -1)
            
            # Hard Target for KL
            target_one_hot = F.one_hot(fused_evidence_val.argmax(dim=-1), num_classes=4).float().expand(cluster_mask.sum(), -1, -1)

            # è®¡ç®—ç°‡å†…ä¸€è‡´æ€§æŸå¤±
            cons_loss = bayes_risk(cluster_evidence, target_prob)
            kl = kld_loss_fn(cluster_evidence, target_one_hot)

            total_consensus_loss = total_consensus_loss + cons_loss
            total_kl_loss = total_kl_loss + kl
            processed_clusters += 1

        if processed_clusters > 0:
            total_consensus_loss /= processed_clusters
            total_kl_loss /= processed_clusters

        # 2. ç»„åˆ Loss
        # ğŸ’¡ å»ºè®®æƒé‡ï¼š90% é‡å»ºè¾“å…¥ (ç¡®ä¿ä¸ççŒœ), 10% é€¼è¿‘ç°‡ä¸­å¿ƒ (ä¿ƒè¿›èšç±»)
        final_recon_loss = 1.0 * input_recon_loss + 0.1 * total_consensus_loss

        return final_recon_loss, total_kl_loss, fused_consensus
    
    def forward(self, reads, cluster_labels, epoch=0):
        # 1ï¸âƒ£ FedDNA Encoder
        embeddings, pooled_emb = self.encode_reads(reads)
        
        # 2ï¸âƒ£ FedDNA Decoder
        evidence, strength, alpha = self.decode_to_evidence(embeddings)
        
        # 3ï¸âƒ£ å¯¹æ¯”å­¦ä¹  (ä¿æŒ Warmup=5)
        contrastive_loss = self.contrastive_learning_with_evidence_filter(
            pooled_emb, cluster_labels, strength, epoch=epoch, warmup_epochs=5
        )
        
        # 4ï¸âƒ£ è‡ªé‡å»ºæŸå¤±
        recon_loss, kl_loss, fused_consensus = self.self_reconstruction_loss(
            evidence, alpha, cluster_labels, reads
        )
        
        # 5ï¸âƒ£ æ€»æŸå¤±ç­–ç•¥è°ƒæ•´ (ğŸš¨ æ ¸å¿ƒä¿®æ”¹ç‚¹)
        
        # ç­–ç•¥ A: æ¨è¿Ÿ KL ä»‹å…¥ (è®©æ¨¡å‹å…ˆä» Recon/Contrastive å­¦åˆ°è‡ªä¿¡)
        # ä» Epoch 10 å¼€å§‹ä»‹å…¥ï¼Œåˆ° Epoch 40 è¾¾åˆ°æœ€å¤§å€¼
        if epoch < 10:
            annealing_coef = 0.0
        else:
            annealing_coef = min(1.0, (epoch - 10) / 30)
            
        # ç­–ç•¥ B: æ°¸ä¹…æ€§ç¼©å° KL æƒé‡ (å› ä¸º KL åŸå§‹æ•°å€¼ 500+ å¤ªå¤§äº†ï¼Œå¿…é¡»ç¼©æ”¾)
        # æˆ‘ä»¬å¸Œæœ› KL Loss æœ€ç»ˆåœ¨ 10-50 å·¦å³ï¼Œè€Œä¸æ˜¯ 500
        scaled_kl_loss = kl_loss * 0.05  # ç¼©å° 20 å€
        
        # ç­–ç•¥ C: æ¿€åŠ±é¡¹ (é˜²æ­¢ Strength å½’é›¶)
        # å¦‚æœæ˜¯ Warm-up é˜¶æ®µï¼Œç»™ä¸€ç‚¹ç‚¹å¥–åŠ±è®©å®ƒäº§ç”Ÿ Strength
        if epoch < 10:
            l2_evidence = torch.mean(evidence ** 2) * 0.001
        else:
            l2_evidence = 0.0

        # æ€»æŸå¤±
        total_loss = contrastive_loss + 10.0 * recon_loss + annealing_coef * scaled_kl_loss + l2_evidence
        
        # ç»Ÿè®¡ä¿¡æ¯
        avg_strength = strength.mean().item()
        high_conf_ratio = (strength.mean(dim=1) > 4.5).float().mean().item()
        
        loss_dict = {
            'total': total_loss,
            'contrastive': contrastive_loss,
            'reconstruction': recon_loss,
            'kl_divergence': kl_loss, # è®°å½•åŸå§‹å€¼ä»¥ä¾¿è§‚å¯Ÿ
            'annealing_coef': annealing_coef
        }
        
        outputs = {
            'embeddings': embeddings,
            'evidence': evidence,
            'strength': strength,
            'alpha': alpha,
            'fused_consensus': fused_consensus,
            'avg_strength': avg_strength,
            'high_conf_ratio': high_conf_ratio
        }
        
        return loss_dict, outputs

def load_pretrained_feddna(model, checkpoint_path, device):
    """âœ… ä¿®å¤ï¼šæ›´æ™ºèƒ½çš„æƒé‡åŠ è½½"""
    print(f"ğŸ”„ åŠ è½½FedDNAé¢„è®­ç»ƒæƒé‡: {checkpoint_path}")
    
    try:
        checkpoint = torch.load(checkpoint_path, map_location=device)
        
        if isinstance(checkpoint, dict):
            if 'model' in checkpoint:
                pretrained_dict = checkpoint['model']
            elif 'state_dict' in checkpoint:
                pretrained_dict = checkpoint['state_dict']
            else:
                pretrained_dict = checkpoint
        else:
            pretrained_dict = checkpoint
        
        model_dict = model.state_dict()
        
        # æ™ºèƒ½åŠ è½½æƒé‡
        filtered_dict = {}
        skipped_keys = []
        
        for k, v in pretrained_dict.items():
            if k in model_dict:
                if model_dict[k].shape == v.shape:
                    filtered_dict[k] = v
                    print(f"   âœ… åŠ è½½: {k} {v.shape}")
                else:
                    skipped_keys.append(f"{k} (å½¢çŠ¶ä¸åŒ¹é…: æ¨¡å‹{model_dict[k].shape} vs æƒé‡{v.shape})")
            else:
                # âœ… è·³è¿‡length_adapterç›¸å…³æƒé‡ï¼Œå› ä¸ºæˆ‘ä»¬ä¼šåŠ¨æ€åˆå§‹åŒ–
                if 'length_adapter' in k:
                    print(f"   ğŸ”§ è·³è¿‡length_adapteræƒé‡ï¼ˆå°†åŠ¨æ€åˆå§‹åŒ–ï¼‰: {k}")
                else:
                    skipped_keys.append(f"{k} (æ¨¡å‹ä¸­ä¸å­˜åœ¨)")
        
        # æ›´æ–°æ¨¡å‹å‚æ•°
        if filtered_dict:
            model_dict.update(filtered_dict)
            model.load_state_dict(model_dict, strict=False)  # å…è®¸éƒ¨åˆ†åŠ è½½
            print(f"âœ… æˆåŠŸåŠ è½½ {len(filtered_dict)}/{len(pretrained_dict)} ä¸ªå‚æ•°")
        
        if skipped_keys:
            print(f"âš ï¸ è·³è¿‡çš„æƒé‡:")
            for key in skipped_keys[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"     {key}")
            if len(skipped_keys) > 5:
                print(f"     ... è¿˜æœ‰ {len(skipped_keys) - 5} ä¸ª")
        
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        print("   ç»§ç»­ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡")
    
    return model