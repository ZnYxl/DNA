# models/step2_refine.py
"""
Step2: Evidence-Guided Cluster Refinement (é˜² OOM + é«˜é€Ÿç‰ˆ)

åŸºäºå­¦ç”Ÿç‰ˆæœ¬çš„ index_add_ å‘é‡åŒ–æ€è·¯ï¼Œä¿®å¤ä»¥ä¸‹é—®é¢˜:
  [FIX-1] refine_reads è¿”å› 3 ä¸ªå€¼ (new_labels, noise_mask, stats)
  [FIX-2] refine_reads æ¥å— round_idx å‚æ•°ï¼Œå†…éƒ¨åš delta scaling
  [FIX-3] compute_global_delta ç­¾åä¸ runner ä¸€è‡´: (embeddings, labels, zone_ids, centroids)
  [FIX-4] refine è·ç¦»è®¡ç®—: CPU åŒè½´åˆ†å— matmulï¼Œé¿å… cdist(5K, 444K) OOM
  [FIX-5] compute_global_delta åªè¿”å›åŸå§‹ deltaï¼Œscaling ç•™ç»™ refine_reads
"""
import torch
import torch.nn.functional as F
import numpy as np
import time

# ---------------------------------------------------------------------------
# è¶…å‚å¸¸é‡
# ---------------------------------------------------------------------------
DIRTY_PERCENTILE   = 0.10
SAFE_PERCENTILE    = 0.70
MIN_ZONE1_SAFETY   = 3
ZONE2_WEIGHT_CAP   = 0.30
DELTA_P            = 95
ROUND1_DELTA_SCALE = 1.5


# ===========================================================================
# 1. ä¸‰åŒºåˆ¶åˆ’åˆ†
# ===========================================================================
def split_confidence_by_zone(u_epi, u_ale, labels):
    N      = len(labels)
    device = labels.device
    zone_ids = torch.zeros(N, dtype=torch.long, device=device)

    valid   = (labels >= 0)
    n_valid = valid.sum().item()
    if n_valid == 0:
        return zone_ids, {'zone1': 0, 'zone2': 0, 'zone3': 0, 'noise': N}

    # ç¬¬ä¸€åˆ€: U_ale Top 10% â†’ Zone III
    ale_threshold = torch.quantile(u_ale[valid], 1.0 - DIRTY_PERCENTILE)
    is_dirty = valid & (u_ale >= ale_threshold)
    zone_ids[is_dirty] = 3

    # ç¬¬äºŒåˆ€: å‰©ä½™ä¸­ U_epi Bottom 70% â†’ Zone I
    remaining = valid & (~is_dirty)
    if remaining.any():
        epi_threshold = torch.quantile(u_epi[remaining], SAFE_PERCENTILE)
        zone_ids[remaining & (u_epi <= epi_threshold)] = 1
        zone_ids[remaining & (u_epi >  epi_threshold)] = 2

    z1 = int((zone_ids == 1).sum().item())
    z2 = int((zone_ids == 2).sum().item())
    z3 = int((zone_ids == 3).sum().item())
    zn = int((zone_ids == 0).sum().item())

    print(f"   ğŸ“Š ä¸‰åŒºåˆ¶åˆ’åˆ†:")
    print(f"      Zone I  (Safe):   {z1:>8d}  ({z1/max(n_valid,1)*100:5.1f}%)")
    print(f"      Zone II (Hard):   {z2:>8d}  ({z2/max(n_valid,1)*100:5.1f}%)")
    print(f"      Zone III(Dirty):  {z3:>8d}  ({z3/max(n_valid,1)*100:5.1f}%)")
    print(f"      Noise   (skip):   {zn:>8d}")

    return zone_ids, {'zone1': z1, 'zone2': z2, 'zone3': z3, 'noise': zn}


# ===========================================================================
# 2. è¯æ®åŠ æƒè´¨å¿ƒ (CPU index_add_ å‘é‡åŒ–)
#
#    ç­¾å: compute_centroids_weighted(embeddings, labels, strength, zone_ids)
#    è¿”å›: (centroids_dict, cluster_sizes_dict)
# ===========================================================================
def compute_centroids_weighted(embeddings, labels, strength, zone_ids):
    t0 = time.time()

    # ---- å…¨éƒ¨æ¬åˆ° CPUï¼Œè§£å†³ GPU OOM ----
    # â˜… embeddings å·²åœ¨ runner ä¸­ in-place å½’ä¸€åŒ–, ä¸å†æ‹·è´
    emb_cpu  = embeddings.detach() if embeddings.device.type == 'cpu' else embeddings.detach().cpu()
    lbl_cpu  = labels.detach() if labels.device.type == 'cpu' else labels.detach().cpu()
    str_cpu  = strength.detach() if strength.device.type == 'cpu' else strength.detach().cpu()
    zone_cpu = zone_ids.detach() if zone_ids.device.type == 'cpu' else zone_ids.detach().cpu()

    # ç­›é€‰ Zone I + Zone II
    valid = (lbl_cpu >= 0) & ((zone_cpu == 1) | (zone_cpu == 2))
    sub_emb = emb_cpu[valid]
    sub_lbl = lbl_cpu[valid]
    sub_str = str_cpu[valid]
    sub_zon = zone_cpu[valid]

    if len(sub_lbl) == 0:
        return {}, {}

    max_label = int(sub_lbl.max().item()) + 1
    D = sub_emb.shape[1]

    # ---- å®‰å…¨é˜€: å‘é‡åŒ–ç»Ÿè®¡ Zone I æ•°é‡ ----
    z1_mask = (sub_zon == 1)
    z1_counts = torch.zeros(max_label, dtype=torch.long)
    if z1_mask.any():
        z1_counts.index_add_(0, sub_lbl[z1_mask],
                             torch.ones(int(z1_mask.sum()), dtype=torch.long))

    unsafe = (z1_counts < MIN_ZONE1_SAFETY)
    is_unsafe_read = unsafe[sub_lbl]

    weights = sub_str.clone()
    clamp_mask = is_unsafe_read & (sub_zon == 2)
    if clamp_mask.any():
        weights[clamp_mask] = weights[clamp_mask].clamp(max=ZONE2_WEIGHT_CAP)

    # ---- index_add_ åŠ æƒæ±‚å’Œ (æ ¸å¿ƒåŠ é€Ÿ) ----
    centroid_sum = torch.zeros(max_label, D)
    weight_sum   = torch.zeros(max_label)
    centroid_sum.index_add_(0, sub_lbl, sub_emb * weights.unsqueeze(1))
    weight_sum.index_add_(0, sub_lbl, weights)

    valid_mask = (weight_sum > 1e-6)
    final = torch.zeros(max_label, D)
    final[valid_mask] = centroid_sum[valid_mask] / weight_sum[valid_mask].unsqueeze(1)
    final = F.normalize(final, dim=-1)

    # è½¬ dict
    present = torch.nonzero(valid_mask).squeeze(1)
    centroids = {int(k): final[k] for k in present}

    # cluster_sizes (ä¿æŒæ¥å£å…¼å®¹)
    size_count = torch.zeros(max_label, dtype=torch.long)
    size_count.index_add_(0, sub_lbl, torch.ones(len(sub_lbl), dtype=torch.long))
    cluster_sizes = {int(k): int(size_count[k]) for k in present}

    n_safety = int(unsafe[present].sum().item()) if len(present) > 0 else 0
    t1 = time.time()
    print(f"\n   ğŸ“ è´¨å¿ƒ (CPU vectorized): {len(centroids)} ç°‡, "
          f"å®‰å…¨é˜€ {n_safety}, è€—æ—¶ {t1-t0:.1f}s")

    return centroids, cluster_sizes


# ===========================================================================
# 3. å…¨å±€è‡ªé€‚åº” Delta (CPU é‡‡æ · 10 ä¸‡ä¼°ç®—)
#
#    ç­¾å: compute_global_delta(embeddings, labels, zone_ids, centroids)
#                               â†‘ æ³¨æ„é¡ºåº! ä¸ runner è°ƒç”¨ä¸€è‡´
#    è¿”å›: delta (åŸå§‹ P95 å€¼, ä¸ä¹˜ ROUND1_DELTA_SCALE)
# ===========================================================================
def compute_global_delta(embeddings, labels, zone_ids, centroids):
    print(f"   ğŸ¯ è®¡ç®— Global Delta (P{DELTA_P})...")

    # â˜… embeddings å·²å½’ä¸€åŒ–, ä¸å†æ‹·è´
    emb_cpu  = embeddings.detach() if embeddings.device.type == 'cpu' else embeddings.detach().cpu()
    lbl_cpu  = labels.detach() if labels.device.type == 'cpu' else labels.detach().cpu()
    zone_cpu = zone_ids.detach() if zone_ids.device.type == 'cpu' else zone_ids.detach().cpu()

    mask = (lbl_cpu >= 0) & (zone_cpu == 1)
    z1_indices = torch.nonzero(mask).squeeze(1)

    if len(z1_indices) == 0:
        print(f"   âš ï¸ æ—  Zone I æ ·æœ¬, è¿”å› 0.5")
        return 0.5

    # é‡‡æ · 10 ä¸‡ (è¶³å¤Ÿå‡†ç¡®, é¿å…æ…¢)
    if len(z1_indices) > 100000:
        z1_indices = z1_indices[torch.randperm(len(z1_indices))[:100000]]

    sample_emb = emb_cpu[z1_indices]
    sample_lbl = lbl_cpu[z1_indices]

    # åŒ¹é…è´¨å¿ƒ
    target_list = []
    keep = []
    for i in range(len(sample_lbl)):
        lid = int(sample_lbl[i].item())
        if lid in centroids:
            target_list.append(centroids[lid])
            keep.append(i)

    if not target_list:
        print(f"   âš ï¸ æ— æ³•åŒ¹é…è´¨å¿ƒ, è¿”å› 0.5")
        return 0.5

    target_mat = torch.stack(target_list)
    sample_emb = sample_emb[keep]

    # L2 distance (normalized vectors): ||a-b|| = sqrt(2 - 2*<a,b>)
    sim = (sample_emb * target_mat).sum(dim=1)
    dists = torch.sqrt((2.0 - 2.0 * sim).clamp(min=0.0))

    delta = float(np.percentile(dists.numpy(), DELTA_P))
    print(f"   ğŸ¯ Global Delta = {delta:.4f} (åŸºäº {len(keep)} ä¸ª Zone I æ ·æœ¬)")
    return delta


# ===========================================================================
# è¾…åŠ©: åŒè½´åˆ†å—æœ€è¿‘é‚» (CPU, é˜² OOM)
#
# ä¸ºä»€ä¹ˆä¸èƒ½ç”¨ cdist?
#   query=5000, centroids=444K â†’ output (5000, 444000) Ã— 4B = 8.8GB â†’ å¿…çˆ†
#
# è§£æ³•: å¯¹ centroid è½´ä¹Ÿåˆ†å—
#   query_chunk Ã— centroid_chunk Ã— 4B = 3000 Ã— 80000 Ã— 4 = 960MB â†’ CPU å®‰å…¨
# ===========================================================================
def _chunked_nearest_centroid(query, centroid_matrix, centroid_ids,
                              query_chunk=3000, centroid_chunk=80000):
    """
    åœ¨ normalized ç©ºé—´ç”¨åˆ†å— matmul æ‰¾æœ€è¿‘è´¨å¿ƒã€‚
    è¿”å›: (min_dist, best_centroid_id) éƒ½æ˜¯ (N,) tensor
    """
    N = query.shape[0]
    K = centroid_matrix.shape[0]

    best_dist = torch.full((N,), float('inf'))
    best_idx  = torch.zeros(N, dtype=torch.long)

    for qi in range(0, N, query_chunk):
        qe = min(qi + query_chunk, N)
        q_batch = query[qi:qe]

        batch_best_dist = torch.full((qe - qi,), float('inf'))
        batch_best_idx  = torch.zeros(qe - qi, dtype=torch.long)

        for ci in range(0, K, centroid_chunk):
            ce = min(ci + centroid_chunk, K)
            c_batch = centroid_matrix[ci:ce]

            # cosine sim â†’ L2 for normalized vectors
            sim = q_batch @ c_batch.T                              # (q, c)
            dist = torch.sqrt((2.0 - 2.0 * sim).clamp(min=0.0))   # (q, c)

            chunk_min_d, chunk_min_i = dist.min(dim=1)

            improved = (chunk_min_d < batch_best_dist)
            batch_best_dist[improved] = chunk_min_d[improved]
            batch_best_idx[improved]  = chunk_min_i[improved] + ci  # åç§»é‡!

        best_dist[qi:qe] = batch_best_dist
        best_idx[qi:qe]  = batch_best_idx

        if qi > 0 and (qi // query_chunk) % 20 == 0:
            print(f"      refine è¿›åº¦: {qe}/{N}", flush=True)

    best_cid = centroid_ids[best_idx]
    return best_dist, best_cid


# ===========================================================================
# 4. Zone-aware ä¿®æ­£
#
#    ç­¾å: refine_reads(embeddings, labels, zone_ids, centroids, delta, round_idx=1)
#    è¿”å›: (new_labels, noise_mask, stats)  â† 3 ä¸ªå€¼!
# ===========================================================================
def refine_reads(embeddings, labels, zone_ids, centroids, delta, round_idx=1):
    device = embeddings.device
    new_labels = labels.clone()
    noise_mask = torch.zeros_like(labels, dtype=torch.bool)

    # ---- ROUND1_DELTA_SCALE åœ¨è¿™é‡Œåº”ç”¨ (ä¸åœ¨ compute_global_delta é‡Œ) ----
    eff_delta = delta * ROUND1_DELTA_SCALE if round_idx == 1 else delta
    print(f"\n   ğŸ”„ Zone-aware ä¿®æ­£ (Round {round_idx}, "
          f"delta={delta:.4f}, scale={'1.5' if round_idx==1 else '1.0'}, "
          f"eff_delta={eff_delta:.4f})")

    # Zone III â†’ å™ªå£°
    dirty = (zone_ids == 3)
    new_labels[dirty] = -1
    noise_mask[dirty] = True
    n_dirty = int(dirty.sum().item())

    # Zone I â†’ ä¸åŠ¨
    n_safe = int((zone_ids == 1).sum().item())

    # Zone II â†’ è·ç¦»åˆ¤å†³ (CPU åŒè½´åˆ†å—)
    hard_indices = torch.nonzero(zone_ids == 2).squeeze(1)
    n_hard = len(hard_indices)
    reassigned = 0
    marked_noise = 0

    if n_hard > 0 and len(centroids) > 0:
        t0 = time.time()
        print(f"   âš–ï¸ ä¿®æ­£ {n_hard} æ¡ Zone II (CPU åŒè½´åˆ†å—, "
              f"{len(centroids)} è´¨å¿ƒ)...")

        # ---- å…¨éƒ¨åœ¨ CPU, å·²å½’ä¸€åŒ– ----
        emb_cpu = embeddings.detach() if embeddings.device.type == 'cpu' else embeddings.detach().cpu()
        query = emb_cpu[hard_indices.cpu() if hard_indices.is_cuda else hard_indices]

        sorted_ids = sorted(centroids.keys())
        centroid_matrix = torch.stack([centroids[k] for k in sorted_ids])
        centroid_ids = torch.tensor(sorted_ids, dtype=torch.long)

        # åŒè½´åˆ†å—æœ€è¿‘é‚»
        min_dist, best_cid = _chunked_nearest_centroid(
            query, centroid_matrix, centroid_ids
        )

        # åˆ¤å†³
        within = (min_dist < eff_delta)

        # å½’é˜Ÿ
        gi_in = hard_indices[within]
        bi_in = best_cid[within].to(device)
        orig  = labels[gi_in]
        reassigned = int((orig != bi_in).sum().item())
        new_labels[gi_in] = bi_in

        # å™ªå£°
        gi_out = hard_indices[~within]
        new_labels[gi_out] = -1
        noise_mask[gi_out] = True
        marked_noise = int((~within).sum().item())

        t1 = time.time()
        print(f"      å®Œæˆ, è€—æ—¶ {t1-t0:.1f}s")

    stats = {
        'zone1_kept':       n_safe,
        'zone2_total':      n_hard,
        'zone2_reassigned': reassigned,
        'zone2_noise':      marked_noise,
        'zone3_dirty':      n_dirty,
    }

    print(f"   âœ… ä¿®æ­£ç»“æœ:")
    print(f"      Zone I  ä¿æŒ:    {stats['zone1_kept']}")
    print(f"      Zone II é‡åˆ†é…:  {stats['zone2_reassigned']}")
    print(f"      Zone II å™ªå£°:    {stats['zone2_noise']}")
    print(f"      Zone III ä¸¢å¼ƒ:   {stats['zone3_dirty']}")

    return new_labels, noise_mask, stats