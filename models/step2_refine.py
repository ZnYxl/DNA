# models/step2_refine.py
"""
Step2: Evidence-Guided Cluster Refinement  â€”  ä¸‰åŒºåˆ¶ç‰ˆæœ¬

ä¿®æ”¹æ¸…å• C çš„å…¨éƒ¨å®ç°ï¼š
  1. split_confidence_by_zone        â€” è§£è€¦åŒé‡ç­›é€‰ï¼ˆå…ˆåˆ‡ U_aleï¼Œå†åˆ‡ U_epiï¼‰
  2. compute_centroids_weighted      â€” Zone I+II è¯æ®åŠ æƒè´¨å¿ƒ + å°ç°‡å®‰å…¨é˜€
  3. compute_global_delta            â€” ç”¨ Safe æ ·æœ¬åˆ°è‡ªå·±è´¨å¿ƒçš„è·ç¦»åˆ†å¸ƒå– P95
  4. refine_reads                    â€” Zone-aware ä¿®æ­£ + Round-aware delta è°ƒåº¦
"""
import torch
import torch.nn.functional as F


# ---------------------------------------------------------------------------
# è¶…å‚å¸¸é‡
# ---------------------------------------------------------------------------
DIRTY_PERCENTILE   = 0.10   # U_ale å…¨å±€ Top 10% â†’ Zone III
SAFE_PERCENTILE    = 0.70   # å‰©ä½™ä¸­ U_epi Bottom 70% â†’ Zone I
MIN_ZONE1_SAFETY   = 3      # ç°‡å†… Zone I ä¸è¶³æ­¤æ•°æ—¶æ¿€æ´»å®‰å…¨é˜€
ZONE2_WEIGHT_CAP   = 0.30   # å®‰å…¨é˜€æ¿€æ´»åï¼ŒZone II æ¯ä¸ªæ ·æœ¬çš„æƒé‡ä¸Šé™
DELTA_P            = 95     # Global Delta å– P95
ROUND1_DELTA_SCALE = 1.5    # Round 1 å®½æ¾å€æ•°


# ===========================================================================
# 1. ä¸‰åŒºåˆ¶åˆ’åˆ†
#    ç¬¬ä¸€åˆ€ï¼šå…¨å±€ U_ale Top 10% â†’ Zone III (Dirty)
#    ç¬¬äºŒåˆ€ï¼šå‰©ä½™ä¸­ U_epi Bottom 70% â†’ Zone I (Safe)ï¼Œå…¶ä½™ â†’ Zone II (Hard)
#    å™ªå£°æ ‡ç­¾ (label < 0) çš„ä½ç½® zone = 0ï¼Œä¸å‚ä¸ä»»ä½•åç»­æµç¨‹
# ===========================================================================
def split_confidence_by_zone(u_epi, u_ale, labels):
    """
    u_epi:  (N,)  è®¤çŸ¥ä¸ç¡®å®šæ€§
    u_ale:  (N,)  å¶ç„¶ä¸ç¡®å®šæ€§
    labels: (N,)  å½“å‰ç°‡æ ‡ç­¾

    è¿”å›:
        zone_ids:   (N,) LongTensor  1=Safe 2=Hard 3=Dirty 0=å™ªå£°
        zone_stats: dict
    """
    N       = len(labels)
    device  = labels.device
    zone_ids = torch.zeros(N, dtype=torch.long, device=device)

    valid   = (labels >= 0)
    n_valid = valid.sum().item()
    if n_valid == 0:
        return zone_ids, {'zone1': 0, 'zone2': 0, 'zone3': 0, 'noise': N}

    # ---- ç¬¬ä¸€åˆ€: U_ale åˆ‡ Dirty ----
    u_ale_valid   = u_ale[valid]
    ale_threshold = torch.quantile(u_ale_valid, 1.0 - DIRTY_PERCENTILE)
    dirty_global  = torch.zeros(N, dtype=torch.bool, device=device)
    dirty_global[valid] = (u_ale_valid >= ale_threshold)
    zone_ids[dirty_global] = 3

    # ---- ç¬¬äºŒåˆ€: åœ¨"æœ‰æ•ˆä¸”éDirty"ä¸­åˆ‡ Safe / Hard ----
    remaining = valid & (~dirty_global)
    n_rem     = remaining.sum().item()

    if n_rem > 0:
        u_epi_rem     = u_epi[remaining]
        epi_threshold = torch.quantile(u_epi_rem, SAFE_PERCENTILE)

        safe_local  = (u_epi_rem <= epi_threshold)
        hard_local  = ~safe_local

        rem_indices = torch.where(remaining)[0]
        zone_ids[rem_indices[safe_local]] = 1
        zone_ids[rem_indices[hard_local]] = 2

    # ---- ç»Ÿè®¡ ----
    z1 = int((zone_ids == 1).sum().item())
    z2 = int((zone_ids == 2).sum().item())
    z3 = int((zone_ids == 3).sum().item())
    zn = int((zone_ids == 0).sum().item())

    print(f"   ğŸ“Š ä¸‰åŒºåˆ¶åˆ’åˆ†ç»“æœ:")
    print(f"      Zone I  (Safe):   {z1:>7d}  ({z1/max(n_valid,1)*100:5.1f}%)")
    print(f"      Zone II (Hard):   {z2:>7d}  ({z2/max(n_valid,1)*100:5.1f}%)")
    print(f"      Zone III(Dirty):  {z3:>7d}  ({z3/max(n_valid,1)*100:5.1f}%)")
    print(f"      Noise   (skip):   {zn:>7d}")

    return zone_ids, {'zone1': z1, 'zone2': z2, 'zone3': z3, 'noise': zn}


# ===========================================================================
# 2. è¯æ®åŠ æƒè´¨å¿ƒï¼ˆZone I + Zone IIï¼Œå«å®‰å…¨é˜€ï¼‰
#
#    C_k = Î£(S_i Â· z_i) / Î£(S_i)    S_i = strength of read i
#
#    å®‰å…¨é˜€è§¦å‘æ¡ä»¶: ç°‡å†… Zone I æ•°é‡ < MIN_ZONE1_SAFETY
#    è§¦å‘å: Zone II æ ·æœ¬çš„ S è¢«å¤¹ç´§åˆ° ZONE2_WEIGHT_CAP
#    æ•ˆæœ: å½’ä¸€åŒ–å Zone II å•ä¸ªæ ·æœ¬æƒé‡æä½ï¼Œä¸å½±å“è´¨å¿ƒåç§»
#          ä½†å®ƒä»¬çš„å­˜åœ¨å¢åŠ äº†æ ·æœ¬æ•°ï¼Œé™ä½æ–¹å·®
# ===========================================================================
def compute_centroids_weighted(embeddings, labels, strength, zone_ids):
    """
    embeddings: (N, D)
    labels:     (N,)
    strength:   (N,)   åºåˆ—çº§åˆ« evidence strength
    zone_ids:   (N,)   ä¸‰åŒºåˆ¶æ ‡ç­¾

    è¿”å›:
        centroids:     dict { cluster_id(int) -> CPU Tensor (D,) }
        cluster_sizes: dict { cluster_id(int) -> int }
    """
    print(f"\n   ğŸ§® è®¡ç®—è¯æ®åŠ æƒè´¨å¿ƒ (Zone I+IIï¼Œå«å®‰å…¨é˜€)...")
    device = embeddings.device

    # åªè®© Zone I å’Œ Zone II å‚ä¸
    participate = ((zone_ids == 1) | (zone_ids == 2)) & (labels >= 0)
    p_emb    = embeddings[participate]
    p_labels = labels[participate]
    p_str    = strength[participate]
    p_zones  = zone_ids[participate]

    if p_emb.shape[0] == 0:
        return {}, {}

    centroids     = {}
    cluster_sizes = {}
    safety_count  = 0

    for k in torch.unique(p_labels):
        k_int = int(k.item())
        mask  = (p_labels == k)
        n_k   = int(mask.sum().item())
        if n_k < 2:
            continue

        z1_count = int((p_zones[mask] == 1).sum().item())
        s_k      = p_str[mask].clone()

        # ---- å®‰å…¨é˜€ ----
        if z1_count < MIN_ZONE1_SAFETY:
            z2_local = (p_zones[mask] == 2)
            if z2_local.any():
                s_k[z2_local] = s_k[z2_local].clamp(max=ZONE2_WEIGHT_CAP)
            safety_count += 1

        # åŠ æƒå¹³å‡
        w        = s_k / s_k.sum()
        centroid = (w.unsqueeze(1) * p_emb[mask]).sum(dim=0)

        centroids[k_int]     = centroid.cpu()
        cluster_sizes[k_int] = n_k

    print(f"   ğŸ“ è´¨å¿ƒè®¡ç®—å®Œæˆ: æœ‰æ•ˆç°‡æ•° {len(centroids)}, å®‰å…¨é˜€è§¦å‘ {safety_count} æ¬¡")
    return centroids, cluster_sizes


# ===========================================================================
# 3. å…¨å±€è‡ªé€‚åº” Delta
#
#    ç»Ÿè®¡æ‰€æœ‰ Zone I (Safe) æ ·æœ¬åˆ°è‡ªå·±æ‰€å±ç°‡è´¨å¿ƒçš„è·ç¦»åˆ†å¸ƒï¼Œå– P95ã€‚
#    å«ä¹‰ï¼šSafe æ ·æœ¬ä¸­ 95% éƒ½åœ¨æ­¤åŠå¾„å†…ï¼Œè¶…å‡ºçš„å°±æ˜¯ç¦»ç¾¤ç‚¹ã€‚
# ===========================================================================
def compute_global_delta(embeddings, labels, zone_ids, centroids):
    """
    è¿”å›: delta (float)
    """
    print(f"   ğŸ¯ è®¡ç®— Global Delta (Safeâ†’è‡ªå·±è´¨å¿ƒçš„è·ç¦»åˆ†å¸ƒ, P{DELTA_P})...")
    device = embeddings.device

    safe_mask   = (zone_ids == 1) & (labels >= 0)
    safe_emb    = embeddings[safe_mask]
    safe_labels = labels[safe_mask]

    if safe_emb.shape[0] == 0:
        print(f"   âš ï¸ æ—  Safe æ ·æœ¬ï¼Œè¿”å›ç»éªŒå€¼ 0.5")
        return 0.5

    sorted_ids  = sorted(centroids.keys())
    if len(sorted_ids) == 0:
        return 0.5

    id_to_row       = {kid: i for i, kid in enumerate(sorted_ids)}
    centroid_matrix = torch.stack(
        [centroids[k] for k in sorted_ids]
    ).to(device)                                          # (K, D)

    # label â†’ centroid_matrix è¡Œç´¢å¼•
    safe_labels_list   = safe_labels.cpu().tolist()
    valid_sample_idx   = []
    valid_centroid_idx = []

    for i, lbl in enumerate(safe_labels_list):
        if lbl in id_to_row:
            valid_sample_idx.append(i)
            valid_centroid_idx.append(id_to_row[lbl])

    if len(valid_sample_idx) == 0:
        print(f"   âš ï¸ Safe æ ·æœ¬æ— æ³•åŒ¹é…åˆ°è´¨å¿ƒï¼Œè¿”å›ç»éªŒå€¼ 0.5")
        return 0.5

    valid_sample_idx   = torch.tensor(valid_sample_idx,  device=device)
    valid_centroid_idx = torch.tensor(valid_centroid_idx, device=device)

    # åˆ†å—è·ç¦»
    chunk  = 10000
    dists  = []
    for i in range(0, len(valid_sample_idx), chunk):
        end = min(i + chunk, len(valid_sample_idx))
        emb = safe_emb[valid_sample_idx[i:end]]
        cen = centroid_matrix[valid_centroid_idx[i:end]]
        dists.append(torch.norm(emb - cen, dim=1))

    all_dists = torch.cat(dists)
    delta     = torch.quantile(all_dists, DELTA_P / 100.0).item()

    print(f"   ğŸ¯ Global Delta = {delta:.4f}  (åŸºäº {len(all_dists)} ä¸ª Safe æ ·æœ¬)")
    return delta


# ===========================================================================
# 4. Zone-aware ä¿®æ­£
#
#    Zone I:   å®Œå…¨ä¿¡ä»»ï¼Œä¸åŠ¨
#    Zone II:  è·ç¦»åˆ¤å†³ â†’ < eff_delta å½’é˜Ÿï¼Œâ‰¥ å™ªå£°
#    Zone III: ç›´æ¥ç½® -1
#    Round 1 ç”¨ delta*1.5ï¼ˆå®½æ¾ï¼‰ï¼ŒRound 2+ ç”¨ deltaï¼ˆä¸¥æ ¼ï¼‰
# ===========================================================================
def refine_reads(embeddings, labels, zone_ids, centroids, delta, round_idx=1):
    """
    è¿”å›:
        new_labels: (N,)
        noise_mask: (N,) bool
        stats:      dict
    """
    new_labels = labels.clone()
    noise_mask = torch.zeros_like(labels, dtype=torch.bool)
    device     = embeddings.device

    eff_delta = delta * ROUND1_DELTA_SCALE if round_idx == 1 else delta
    print(f"\n   ğŸ”„ Zone-aware ä¿®æ­£  (Round {round_idx}, eff_delta={eff_delta:.4f})")

    # ---- Zone III â†’ ç›´æ¥å™ªå£° ----
    dirty      = (zone_ids == 3)
    new_labels[dirty] = -1
    noise_mask[dirty] = True
    n_dirty    = int(dirty.sum().item())

    # ---- Zone I â†’ ä¸åŠ¨ ----
    n_safe     = int((zone_ids == 1).sum().item())

    # ---- Zone II â†’ è·ç¦»åˆ¤å†³ ----
    hard_mask    = (zone_ids == 2)
    hard_indices = torch.where(hard_mask)[0]
    n_hard       = len(hard_indices)

    reassigned   = 0
    marked_noise = 0

    if n_hard > 0 and len(centroids) > 0:
        sorted_ids     = sorted(centroids.keys())
        cluster_matrix = torch.stack(
            [centroids[k] for k in sorted_ids]
        ).to(device)
        cluster_ids_t  = torch.tensor(sorted_ids, device=device)

        query = embeddings[hard_indices]

        chunk = 5000
        for i in range(0, n_hard, chunk):
            end   = min(i + chunk, n_hard)
            batch = query[i:end]

            dists          = torch.cdist(batch, cluster_matrix)
            min_d, min_idx = torch.min(dists, dim=1)
            best_ids       = cluster_ids_t[min_idx]

            within     = (min_d < eff_delta)
            global_idx = hard_indices[i:end]

            # å½’é˜Ÿ
            gi_in  = global_idx[within]
            bi_in  = best_ids[within]
            orig   = labels[gi_in]
            reassigned += int((orig != bi_in).sum().item())
            new_labels[gi_in] = bi_in

            # å™ªå£°
            gi_out = global_idx[~within]
            new_labels[gi_out] = -1
            noise_mask[gi_out] = True
            marked_noise += int((~within).sum().item())

    stats = {
        'zone1_kept':       n_safe,
        'zone2_total':      n_hard,
        'zone2_reassigned': reassigned,
        'zone2_noise':      marked_noise,
        'zone3_dirty':      n_dirty,
    }

    print(f"   âœ… ä¿®æ­£å®Œæˆ:")
    print(f"      Zone I  ä¿æŒä¸åŠ¨:  {stats['zone1_kept']}")
    print(f"      Zone II é‡æ–°åˆ†é…:  {stats['zone2_reassigned']}")
    print(f"      Zone II æ ‡è®°å™ªå£°:  {stats['zone2_noise']}")
    print(f"      Zone III ç›´æ¥ä¸¢å¼ƒ: {stats['zone3_dirty']}")

    return new_labels, noise_mask, stats
