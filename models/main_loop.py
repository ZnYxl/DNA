# models/main_loop.py
"""
SSI-EC é—­ç¯è¿­ä»£æ€»æ§ (v2 ç²¾ç®€ç‰ˆ)

v2 å˜æ›´:
  [NEW] è¿­ä»£ç»“æŸåè°ƒç”¨ Post-processing: å…¨é‡è·ç¦»åˆ†é… (æ¶ˆé™¤æ‰€æœ‰ -1)
  [NEW] æœ€ç»ˆè¯„ä¼°: å®Œæ•´æŒ‡æ ‡ä½“ç³» (ARI/NMI/Purity/Recovery/Recall@cluster)
  [NEW] æ”¶æ•›æ€§è¿½è¸ª: æ¯è½®æ ‡ç­¾å˜åŒ–ç‡

ä¿ç•™:
  [FIX] é¢„è®­ç»ƒæƒé‡è·¯å¾„ä¿®æ­£
  [FIX] --gt_tags_file æ”¯æŒ GT è¯„ä¼°
  [FIX] training_cap å¯é…ç½®

ç”¨æ³•:
  # exp_1
  python main_loop.py \\
    --experiment_dir .../exp_1_Real \\
    --max_length 150 \\
    --gt_tags_file .../exp1_bwa_tags_reads.txt

  # id20
  python main_loop.py \\
    --experiment_dir .../id20_Real \\
    --max_length 150 \\
    --gt_tags_file .../id20_tags_reads.txt
"""
import os
import argparse
import sys
import numpy as np

current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from models.step1_train import train_step1
from models.step2_runner import run_step2


def compute_label_change_rate(prev_labels_path, curr_labels_path):
    """
    æ”¶æ•›æ€§è¿½è¸ª: è®¡ç®—ä¸¤è½®ä¹‹é—´çš„æ ‡ç­¾å˜åŒ–ç‡
    = Hamming(labels_t, labels_{t-1}) / N
    """
    if prev_labels_path is None or not os.path.exists(prev_labels_path):
        return None
    if curr_labels_path is None or not os.path.exists(curr_labels_path):
        return None

    try:
        prev = np.loadtxt(prev_labels_path, dtype=int)
        curr = np.loadtxt(curr_labels_path, dtype=int)

        if len(prev) != len(curr):
            return None

        # åªæ¯”è¾ƒä¸¤è½®éƒ½æœ‰æœ‰æ•ˆæ ‡ç­¾çš„ reads
        valid = (prev >= 0) & (curr >= 0)
        if valid.sum() == 0:
            return None

        changed = (prev[valid] != curr[valid]).sum()
        rate = changed / valid.sum()
        return rate
    except Exception:
        return None


def main_loop():
    parser = argparse.ArgumentParser(description="SSI-EC Master Loop (v2)")

    # ===== æ•°æ®é›†é…ç½® =====
    parser.add_argument('--experiment_dir', type=str,
                        default='/mnt/st_data/liangxinyi/code/CC/Step0/Experiments/id20_Real',
                        help="å®éªŒæ ¹ç›®å½• (åŒ…å« 03_FedDNA_In/read.txt)")
    parser.add_argument('--max_length', type=int, default=150,
                        help="id20=150, Goldman=117, ERR036=152")

    # ===== GT è¯„ä¼° (å¯é€‰) =====
    parser.add_argument('--gt_tags_file', type=str,
                        default='/mnt/st_data/liangxinyi/code/CC/Step0/ç»™å¸ˆå¦¹çš„cloveræ•°æ®é›†/id20/id20_tags_reads.txt',
                        help="GT æ ‡ç­¾æ–‡ä»¶, æ— GTæ—¶è®¾ä¸º None")
    parser.add_argument('--gt_refs_file', type=str, default=None,
                        help="GT å‚è€ƒåºåˆ— FASTA (å¯é€‰)")

    # ===== è¿­ä»£é…ç½® =====
    parser.add_argument('--max_iterations', type=int, default=3)
    parser.add_argument('--device', type=str, default='cuda')

    # ===== é¢„è®­ç»ƒæƒé‡ =====
    parser.add_argument('--feddna_checkpoint', type=str,
                        default='/mnt/st_data/liangxinyi/code/result/FLDNA_I/I_1214234233/model/epoch1_I.pth')

    # ===== è®­ç»ƒè¶…å‚ =====
    parser.add_argument('--batch_size', type=int, default=256)
    parser.add_argument('--max_clusters_per_batch', type=int, default=64)
    parser.add_argument('--training_cap', type=int, default=2000000)
    parser.add_argument('--dim', type=int, default=256)
    parser.add_argument('--min_clusters', type=int, default=50)
    parser.add_argument('--weight_decay', type=float, default=1e-5)

    args = parser.parse_args()
    if args.gt_tags_file and args.gt_tags_file.lower() == 'none':
        args.gt_tags_file = None

    current_labels_path = None
    current_checkpoint_path = None
    current_state_path = None
    current_centroids_path = None

    # æ”¶æ•›æ€§è¿½è¸ª
    convergence_log = []

    print(f"ğŸš€ SSI-EC é—­ç¯è¿­ä»£å¯åŠ¨ (v2)")
    print(f"ğŸ“‚ å®éªŒç›®å½•: {args.experiment_dir}")
    print(f"ğŸ“ åºåˆ—é•¿åº¦: {args.max_length} bp")
    print(f"ğŸ” è¿­ä»£è½®æ•°: {args.max_iterations}")
    print(f"ğŸ”‹ é¢„è®­ç»ƒ:   {os.path.basename(args.feddna_checkpoint)}")
    if args.gt_tags_file:
        print(f"ğŸ“‹ GT è¯„ä¼°:  {os.path.basename(args.gt_tags_file)}")

    for iteration in range(1, args.max_iterations + 1):
        print(f"\n{'=' * 80}")
        print(f"ğŸ”„ Round {iteration} / {args.max_iterations}")
        print(f"{'=' * 80}\n")

        prev_labels_path = current_labels_path  # ä¿ç•™ä¸Šä¸€è½®æ ‡ç­¾ç”¨äºæ”¶æ•›æ€§è®¡ç®—

        # ============== Step 1 ==============
        print(f"[Step 1] Evidence Learning...")
        step1_out = os.path.join(args.experiment_dir, "results", f"iter_{iteration}_step1")

        step1_args = argparse.Namespace(
            experiment_dir=args.experiment_dir, output_dir=step1_out,
            batch_size=args.batch_size, max_clusters_per_batch=args.max_clusters_per_batch,
            weight_decay=args.weight_decay, dim=args.dim, max_length=args.max_length,
            min_clusters=args.min_clusters, device=args.device, round_idx=iteration,
            feddna_checkpoint=args.feddna_checkpoint,
            prev_checkpoint=current_checkpoint_path,
            refined_labels=current_labels_path, prev_state=current_state_path,
            training_cap=args.training_cap,
        )
        step1_checkpoint = train_step1(step1_args)
        if step1_checkpoint is None:
            print("âŒ Step 1 å¤±è´¥"); break

        # ============== Step 2 ==============
        print(f"\n[Step 2] Refine & Decode...")
        step2_out = os.path.join(args.experiment_dir, "results", f"iter_{iteration}_step2")

        step2_args = argparse.Namespace(
            experiment_dir=args.experiment_dir, step1_checkpoint=step1_checkpoint,
            output_dir=step2_out, dim=args.dim, max_length=args.max_length,
            device=args.device, round_idx=iteration,
            refined_labels=current_labels_path, prev_state=current_state_path,
            gt_tags_file=args.gt_tags_file, gt_refs_file=args.gt_refs_file,
            training_cap=args.training_cap,
        )
        results = run_step2(step2_args)

        # ============== çŠ¶æ€æ›´æ–° ==============
        if results and 'next_round_files' in results:
            nrf = results['next_round_files']
            current_labels_path = nrf['labels']
            current_state_path = nrf.get('state')
            current_centroids_path = nrf.get('centroids')
            current_checkpoint_path = step1_checkpoint
            print(f"\nâœ… Round {iteration} å®Œæˆ. æ ‡ç­¾: {os.path.basename(current_labels_path)}")

            # æ”¶æ•›æ€§è¿½è¸ª
            change_rate = compute_label_change_rate(prev_labels_path, current_labels_path)
            if change_rate is not None:
                convergence_log.append({
                    'round': iteration,
                    'label_change_rate': change_rate
                })
                print(f"   ğŸ“ˆ æ ‡ç­¾å˜åŒ–ç‡: {change_rate:.4f} ({change_rate*100:.2f}%)")
            else:
                print(f"   ğŸ“ˆ æ ‡ç­¾å˜åŒ–ç‡: N/A (é¦–è½®)")
        else:
            print("âŒ Step 2 å¤±è´¥"); break

    # =====================================================================
    # Post-processing: å…¨é‡è·ç¦»åˆ†é…
    # =====================================================================
    if current_labels_path and current_centroids_path and current_checkpoint_path:
        print(f"\n{'=' * 80}")
        print(f"ğŸ”§ Post-processing: å…¨é‡è·ç¦»åˆ†é…")
        print(f"{'=' * 80}")

        try:
            from models.post_process import post_process_final_assignment

            pp_output_dir = os.path.join(args.experiment_dir, "results", "final")
            final_labels_path = post_process_final_assignment(
                experiment_dir=args.experiment_dir,
                final_checkpoint_path=current_checkpoint_path,
                final_labels_path=current_labels_path,
                centroids_path=current_centroids_path,
                output_dir=pp_output_dir,
                device=args.device,
                dim=args.dim,
                max_length=args.max_length,
                gt_tags_file=args.gt_tags_file,
            )
            print(f"\nâœ… æœ€ç»ˆæ ‡ç­¾: {final_labels_path}")
        except Exception as e:
            print(f"âŒ Post-processing å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    # =====================================================================
    # æ”¶æ•›æ€§æŠ¥å‘Š
    # =====================================================================
    if convergence_log:
        print(f"\n{'=' * 60}")
        print(f"ğŸ“ˆ æ”¶æ•›æ€§æŠ¥å‘Š")
        print(f"{'=' * 60}")
        for entry in convergence_log:
            r = entry['round']
            cr = entry['label_change_rate']
            bar = 'â–ˆ' * int(cr * 100) + 'â–‘' * (50 - int(cr * 100))
            print(f"   Round {r}: {cr:.4f} ({cr*100:.2f}%) {bar}")

        # ä¿å­˜æ”¶æ•›æ€§æ—¥å¿—
        try:
            conv_path = os.path.join(args.experiment_dir, "results", "convergence_log.txt")
            os.makedirs(os.path.dirname(conv_path), exist_ok=True)
            with open(conv_path, 'w') as f:
                f.write("Round,Label_Change_Rate\n")
                for entry in convergence_log:
                    f.write(f"{entry['round']},{entry['label_change_rate']:.6f}\n")
            print(f"   ğŸ’¾ æ”¶æ•›æ€§æ—¥å¿—: {conv_path}")
        except Exception as e:
            print(f"   âš ï¸ ä¿å­˜æ”¶æ•›æ€§æ—¥å¿—å¤±è´¥: {e}")

    print(f"\nğŸ‰ å®éªŒå®Œæˆï¼ç»“æœ: {args.experiment_dir}/results/")


if __name__ == "__main__":
    main_loop()