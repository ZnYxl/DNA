# models/step1_train.py
"""
Step1 è®­ç»ƒä¸»ç¨‹ (Universal Edition)

ä¿®å¤æ¸…å•:
  [FIX-#7]  epoch æ•°é‡: R1=10, R2+=5 (ä¸å®é™…æµ‹è¯•ä¸€è‡´)
  [FIX-#6]  Visualizer args å®‰å…¨è·å– (getattr)
  [NEW]     training_cap / round_idx ä¼ é€’ç»™ Dataset
"""
import torch
import torch.optim as optim
import argparse
import os
import sys
import time
from datetime import datetime
import numpy as np

current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir  = os.path.dirname(current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

from models.step1_model import Step1EvidentialModel, load_pretrained_feddna
from models.step1_data  import CloverDataLoader, Step1Dataset, create_dynamic_sampler
from models.step1_visualizer import Step1Visualizer


# ---------------------------------------------------------------------------
# Hot Start è¶…å‚
# ---------------------------------------------------------------------------
ROUND1_EPOCHS = 10
ROUND1_LR     = 1e-4
ROUND2_EPOCHS = 5
ROUND2_LR     = 1e-5


class ListBatchSampler:
    def __init__(self, batches):
        self.batches = batches
    def __iter__(self):
        return iter(self.batches)
    def __len__(self):
        return len(self.batches)


def train_step1(args):
    """æ­¥éª¤ä¸€è®­ç»ƒä¸»å‡½æ•°"""
    device = torch.device(args.device if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ ä½¿ç”¨è®¾å¤‡: {device}")

    round_idx  = getattr(args, 'round_idx', 1)
    prev_state = getattr(args, 'prev_state', None)
    training_cap = getattr(args, 'training_cap', 2000000)

    # =====================================================================
    # 1. åŠ è½½æ•°æ®
    # =====================================================================
    print("\n" + "=" * 60)
    print("ğŸ“‚ æ•°æ®åŠ è½½")
    print("=" * 60)

    labels_path = getattr(args, 'refined_labels', None)
    data_loader = CloverDataLoader(args.experiment_dir, labels_path=labels_path)

    # [FIX] ä¼ é€’ training_cap å’Œ round_idx
    dataset = Step1Dataset(
        data_loader,
        max_len=args.max_length,
        training_cap=training_cap,
        inference_mode=False,
        round_idx=round_idx
    )

    # =====================================================================
    # 2. åˆ›å»ºæ¨¡å‹
    # =====================================================================
    print("\n" + "=" * 60)
    print("ğŸ§  æ¨¡å‹åˆ›å»º")
    print("=" * 60)

    num_clover_clusters = len(set(data_loader.clover_labels))
    num_gt_clusters = len(getattr(data_loader, 'gt_cluster_seqs', {}))
    num_clusters    = max(num_clover_clusters, num_gt_clusters, args.min_clusters)

    model = Step1EvidentialModel(
        dim=args.dim,
        max_length=args.max_length,
        num_clusters=num_clusters,
        device=device
    ).to(device)

    print(f"   æ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters()):,}")
    print(f"   å½“å‰ç°‡æ•°: {num_clover_clusters}")

    # =====================================================================
    # 3. Hot Start æƒé‡åŠ è½½
    # =====================================================================
    print("\n" + "=" * 60)
    print(f"ğŸ”‹ Hot Start (Round {round_idx})")
    print("=" * 60)

    if round_idx <= 1:
        feddna_ckpt = getattr(args, 'feddna_checkpoint', None)
        if feddna_ckpt and os.path.exists(feddna_ckpt):
            model = load_pretrained_feddna(model, feddna_ckpt, device)
        else:
            print(f"   âš ï¸ æœªæ‰¾åˆ°é¢„è®­ç»ƒæƒé‡ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")
    else:
        prev_ckpt = getattr(args, 'prev_checkpoint', None)
        if prev_ckpt and os.path.exists(prev_ckpt):
            try:
                ckpt = torch.load(prev_ckpt, map_location=device)
                sd   = ckpt.get('model_state_dict', ckpt)

                if 'length_adapter.weight' in sd:
                    import torch.nn as nn_
                    sh = sd['length_adapter.weight'].shape
                    if sh[0] == args.max_length:
                        model.length_adapter = nn_.Linear(sh[1], sh[0]).to(device)
                        print(f"   ğŸ”§ é¢„åˆå§‹åŒ– length_adapter: {sh}")
                    else:
                        print(f"   âš ï¸ é•¿åº¦ä¸åŒ¹é… ({sh[0]} vs {args.max_length})ï¼Œé‡ç½®")

                model.load_state_dict(sd, strict=False)
                print(f"   âœ… åŠ è½½ä¸Šä¸€è½®æƒé‡æˆåŠŸ")
            except Exception as e:
                print(f"   âš ï¸ åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–")
        else:
            print(f"   âš ï¸ æ— ä¸Šä¸€è½® checkpointï¼Œéšæœºåˆå§‹åŒ–")

    # =====================================================================
    # 4. ä¼˜åŒ–å™¨ + è°ƒåº¦å™¨
    # =====================================================================
    epochs = ROUND1_EPOCHS if round_idx <= 1 else ROUND2_EPOCHS
    lr     = ROUND1_LR     if round_idx <= 1 else ROUND2_LR

    print(f"\n   ğŸ“ è®­ç»ƒè¶…å‚: epochs={epochs}, lr={lr}")

    optimizer  = optim.AdamW(model.parameters(), lr=lr, weight_decay=args.weight_decay)
    scheduler  = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)

    # =====================================================================
    # 5. è®­ç»ƒå¾ªç¯
    # =====================================================================
    print("\n" + "=" * 60)
    print("ğŸš€ å¼€å§‹è®­ç»ƒ")
    print("=" * 60)

    model.train()

    training_history = {
        'total_loss': [], 'avg_strength': [], 'high_conf_ratio': [],
        'contrastive_loss': [], 'reconstruction_loss': [], 'kl_loss': [],
        'u_epi_mean': [], 'u_ale_mean': [], 'queue_count': []
    }

    for epoch in range(epochs):
        start_time = time.time()

        batch_indices_list = create_dynamic_sampler(
            dataset,
            batch_size=args.batch_size,
            max_clusters_per_batch=args.max_clusters_per_batch,
            state_path=prev_state,
            round_idx=round_idx
        )

        batch_sampler = ListBatchSampler(batch_indices_list)
        train_loader  = torch.utils.data.DataLoader(
            dataset,
            batch_sampler=batch_sampler,
            num_workers=4,
            pin_memory=True
        )

        epoch_loss = epoch_con = epoch_rec = epoch_kl = 0
        epoch_str = epoch_hc = epoch_u_epi = epoch_u_ale = epoch_qc = 0
        num_batches = 0
        total_batches = len(batch_indices_list)

        print(f"\nğŸ”„ Epoch {epoch + 1}/{epochs} (å…± {total_batches} Batches)")

        for i, batch_data in enumerate(train_loader):
            reads_batch  = batch_data['encoding'].to(device)
            labels_batch = batch_data['clover_label'].to(device)

            loss_dict, outputs = model(reads_batch, labels_batch, epoch=epoch)

            optimizer.zero_grad()
            loss_dict['total'].backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            epoch_loss  += loss_dict['total'].item()
            epoch_con   += loss_dict['contrastive'].item()
            epoch_rec   += loss_dict['reconstruction'].item()
            epoch_kl    += loss_dict['kl_divergence'].item()
            epoch_str   += outputs['avg_strength']
            epoch_hc    += outputs['high_conf_ratio']
            epoch_u_epi += outputs.get('u_epi_mean', 0.0)
            epoch_u_ale += outputs.get('u_ale_mean', 0.0)
            epoch_qc    += outputs.get('queue_count', 0)
            num_batches += 1

            if (i + 1) % 50 == 0:
                print(f"   [Batch {i+1}/{total_batches}] "
                      f"Loss: {loss_dict['total'].item():.4f} | "
                      f"Str: {outputs['avg_strength']:.1f} | "
                      f"U_epi: {outputs.get('u_epi_mean',0):.4f}",
                      end='\r')

        scheduler.step()
        epoch_time = time.time() - start_time
        avg = lambda x: x / max(num_batches, 1)

        training_history['total_loss'].append(avg(epoch_loss))
        training_history['contrastive_loss'].append(avg(epoch_con))
        training_history['reconstruction_loss'].append(avg(epoch_rec))
        training_history['kl_loss'].append(avg(epoch_kl))
        training_history['avg_strength'].append(avg(epoch_str))
        training_history['high_conf_ratio'].append(avg(epoch_hc))
        training_history['u_epi_mean'].append(avg(epoch_u_epi))
        training_history['u_ale_mean'].append(avg(epoch_u_ale))
        training_history['queue_count'].append(avg(epoch_qc))

        print(f"\n   âœ… Epoch {epoch+1} ({epoch_time:.1f}s) | "
              f"Loss: {avg(epoch_loss):.4f} | Str: {avg(epoch_str):.1f} | "
              f"U_epi: {avg(epoch_u_epi):.4f}")

    # =====================================================================
    # 6. ä¿å­˜
    # =====================================================================
    os.makedirs(os.path.join(args.output_dir, "models"), exist_ok=True)
    final_path = os.path.join(args.output_dir, "models", "step1_final_model.pth")

    # [FIX-#6] æŠŠ epochs å’Œ lr å†™å…¥ args ä¾› visualizer ä½¿ç”¨
    args.epochs = epochs
    args.lr = lr

    torch.save({
        'model_state_dict': model.state_dict(),
        'args': vars(args)
    }, final_path)

    print(f"\nğŸ’¾ æ¨¡å‹å·²ä¿å­˜: {final_path}")

    # å¯è§†åŒ–
    try:
        visualizer = Step1Visualizer(args.output_dir)
        visualizer.generate_all_outputs(training_history, model, args)
    except Exception as e:
        print(f"âš ï¸ å¯è§†åŒ–ç”Ÿæˆè·³è¿‡: {e}")

    return final_path


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Step 1 Training')
    parser.add_argument('--experiment_dir',         type=str,   required=True)
    parser.add_argument('--feddna_checkpoint',      type=str,   default=None)
    parser.add_argument('--prev_checkpoint',        type=str,   default=None)
    parser.add_argument('--refined_labels',         type=str,   default=None)
    parser.add_argument('--prev_state',             type=str,   default=None)
    parser.add_argument('--round_idx',              type=int,   default=1)
    parser.add_argument('--dim',                    type=int,   default=256)
    parser.add_argument('--max_length',             type=int,   default=150)
    parser.add_argument('--min_clusters',           type=int,   default=50)
    parser.add_argument('--device',                 type=str,   default='cuda')
    parser.add_argument('--batch_size',             type=int,   default=64)
    parser.add_argument('--max_clusters_per_batch', type=int,   default=8)
    parser.add_argument('--weight_decay',           type=float, default=1e-5)
    parser.add_argument('--training_cap',           type=int,   default=2000000)
    parser.add_argument('--output_dir',             type=str,   default='./step1_results')

    args = parser.parse_args()
    os.makedirs(args.output_dir, exist_ok=True)
    train_step1(args)