================================================================================
Step1 Model Architecture
================================================================================

üèóÔ∏è Ê®°ÂûãÁªìÊûÑ:
Step1EvidentialModel(
  (encoder): Encoder(
    (upsampling): Conv2dUpampling(
      (sequential): Sequential(
        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU()
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (4): ReLU()
      )
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (conmamba): ConmambaBlock(
      (ff1): Scale(
        (fn): PreNorm(
          (fn): FeedForward(
            (net): Sequential(
              (0): Linear(in_features=256, out_features=1024, bias=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Linear(in_features=1024, out_features=256, bias=True)
              (4): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (conv): ConvModule(
        (net): Sequential(
          (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (1): Rearrange('b n c -> b c n')
          (2): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))
          (3): GLU()
          (4): DepthWiseConv1d(
            (conv): Conv1d(512, 512, kernel_size=(31,), stride=(1,), groups=512, bias=False)
          )
          (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (6): Swish()
          (7): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
          (8): Rearrange('b c n -> b n c')
          (9): Dropout(p=0.1, inplace=False)
        )
      )
      (ff2): Scale(
        (fn): PreNorm(
          (fn): FeedForward(
            (net): Sequential(
              (0): Linear(in_features=256, out_features=1024, bias=True)
              (1): Swish()
              (2): Dropout(p=0.1, inplace=False)
              (3): Linear(in_features=1024, out_features=256, bias=True)
              (4): Dropout(p=0.1, inplace=False)
            )
          )
          (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
      )
      (mamba): MambaBlock(
        (mamba): Mamba(
          (in_proj): Linear(in_features=256, out_features=1024, bias=False)
          (conv1d): Conv1d(512, 512, kernel_size=(4,), stride=(1,), padding=(3,), groups=512)
          (act): SiLU()
          (x_proj): Linear(in_features=512, out_features=144, bias=False)
          (dt_proj): Linear(in_features=16, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=256, bias=False)
        )
        (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
      (post_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    )
  )
  (rnnblock): RNNBlock(
    (rnn): LSTM(256, 256, num_layers=2, batch_first=True)
    (linear): Linear(in_features=256, out_features=4, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (projection_head): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): ReLU()
    (2): Dropout(p=0.1, inplace=False)
    (3): Linear(in_features=256, out_features=128, bias=True)
  )
  (length_adapter): Linear(in_features=150, out_features=150, bias=True)
)

üìä ÂèÇÊï∞ÁªüËÆ°:
   ÊÄªÂèÇÊï∞: 3,189,310
   ÂèØËÆ≠ÁªÉÂèÇÊï∞: 3,189,310
   ÂÜªÁªìÂèÇÊï∞: 0

üîç ÂêÑÂ±ÇÂèÇÊï∞ËØ¶ÊÉÖ:
   encoder.upsampling.sequential.0.weight: torch.Size([64, 1, 3, 3]) (576 params)
   encoder.upsampling.sequential.0.bias: torch.Size([64]) (64 params)
   encoder.upsampling.sequential.2.weight: torch.Size([64, 64, 3, 3]) (36,864 params)
   encoder.upsampling.sequential.2.bias: torch.Size([64]) (64 params)
   encoder.upsampling.sequential.3.weight: torch.Size([64]) (64 params)
   encoder.upsampling.sequential.3.bias: torch.Size([64]) (64 params)
   encoder.conmamba.ff1.fn.fn.net.0.weight: torch.Size([1024, 256]) (262,144 params)
   encoder.conmamba.ff1.fn.fn.net.0.bias: torch.Size([1024]) (1,024 params)
   encoder.conmamba.ff1.fn.fn.net.3.weight: torch.Size([256, 1024]) (262,144 params)
   encoder.conmamba.ff1.fn.fn.net.3.bias: torch.Size([256]) (256 params)
   encoder.conmamba.ff1.fn.norm.weight: torch.Size([256]) (256 params)
   encoder.conmamba.ff1.fn.norm.bias: torch.Size([256]) (256 params)
   encoder.conmamba.conv.net.0.weight: torch.Size([256]) (256 params)
   encoder.conmamba.conv.net.0.bias: torch.Size([256]) (256 params)
   encoder.conmamba.conv.net.2.weight: torch.Size([1024, 256, 1]) (262,144 params)
   encoder.conmamba.conv.net.2.bias: torch.Size([1024]) (1,024 params)
   encoder.conmamba.conv.net.4.conv.weight: torch.Size([512, 1, 31]) (15,872 params)
   encoder.conmamba.conv.net.5.weight: torch.Size([512]) (512 params)
   encoder.conmamba.conv.net.5.bias: torch.Size([512]) (512 params)
   encoder.conmamba.conv.net.7.weight: torch.Size([256, 512, 1]) (131,072 params)
   encoder.conmamba.conv.net.7.bias: torch.Size([256]) (256 params)
   encoder.conmamba.ff2.fn.fn.net.0.weight: torch.Size([1024, 256]) (262,144 params)
   encoder.conmamba.ff2.fn.fn.net.0.bias: torch.Size([1024]) (1,024 params)
   encoder.conmamba.ff2.fn.fn.net.3.weight: torch.Size([256, 1024]) (262,144 params)
   encoder.conmamba.ff2.fn.fn.net.3.bias: torch.Size([256]) (256 params)
   encoder.conmamba.ff2.fn.norm.weight: torch.Size([256]) (256 params)
   encoder.conmamba.ff2.fn.norm.bias: torch.Size([256]) (256 params)
   encoder.conmamba.mamba.mamba.A_log: torch.Size([512, 64]) (32,768 params)
   encoder.conmamba.mamba.mamba.D: torch.Size([512]) (512 params)
   encoder.conmamba.mamba.mamba.in_proj.weight: torch.Size([1024, 256]) (262,144 params)
   encoder.conmamba.mamba.mamba.conv1d.weight: torch.Size([512, 1, 4]) (2,048 params)
   encoder.conmamba.mamba.mamba.conv1d.bias: torch.Size([512]) (512 params)
   encoder.conmamba.mamba.mamba.x_proj.weight: torch.Size([144, 512]) (73,728 params)
   encoder.conmamba.mamba.mamba.dt_proj.weight: torch.Size([512, 16]) (8,192 params)
   encoder.conmamba.mamba.mamba.dt_proj.bias: torch.Size([512]) (512 params)
   encoder.conmamba.mamba.mamba.out_proj.weight: torch.Size([256, 512]) (131,072 params)
   encoder.conmamba.mamba.norm.weight: torch.Size([256]) (256 params)
   encoder.conmamba.mamba.norm.bias: torch.Size([256]) (256 params)
   encoder.conmamba.post_norm.weight: torch.Size([256]) (256 params)
   encoder.conmamba.post_norm.bias: torch.Size([256]) (256 params)
   rnnblock.rnn.weight_ih_l0: torch.Size([1024, 256]) (262,144 params)
   rnnblock.rnn.weight_hh_l0: torch.Size([1024, 256]) (262,144 params)
   rnnblock.rnn.bias_ih_l0: torch.Size([1024]) (1,024 params)
   rnnblock.rnn.bias_hh_l0: torch.Size([1024]) (1,024 params)
   rnnblock.rnn.weight_ih_l1: torch.Size([1024, 256]) (262,144 params)
   rnnblock.rnn.weight_hh_l1: torch.Size([1024, 256]) (262,144 params)
   rnnblock.rnn.bias_ih_l1: torch.Size([1024]) (1,024 params)
   rnnblock.rnn.bias_hh_l1: torch.Size([1024]) (1,024 params)
   rnnblock.linear.weight: torch.Size([4, 256]) (1,024 params)
   rnnblock.linear.bias: torch.Size([4]) (4 params)
   projection_head.0.weight: torch.Size([256, 256]) (65,536 params)
   projection_head.0.bias: torch.Size([256]) (256 params)
   projection_head.3.weight: torch.Size([128, 256]) (32,768 params)
   projection_head.3.bias: torch.Size([128]) (128 params)
   length_adapter.weight: torch.Size([150, 150]) (22,500 params)
   length_adapter.bias: torch.Size([150]) (150 params)
