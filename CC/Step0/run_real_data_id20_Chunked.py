import os
import sys
import subprocess
import glob
import shutil
import array
from collections import defaultdict

# ================= å®éªŒé…ç½® =================
DATASET_NAME = "id20"
SOURCE_DIR = "ç»™å¸ˆå¦¹çš„cloveræ•°æ®é›†/id20"
# ID20 çš„æœ‰æ•ˆè½½è·é•¿åº¦ (å»å¼•ç‰©å)
# åŸé•¿ 150 - å¼•ç‰©çº¦ 40 = 110
CLOVER_SEQ_LENGTH = 110 
CHUNK_SIZE = 5000000 
CLOVER_PROCESSES = 0 

# === å…³é”®ï¼šå¼•ç‰©é”šç‚¹ (ç”¨äºå®šä½ Payload) ===
# Forward Primer ç»“å°¾: ...AGTGCAACAAG [TCAATCCG] -> Payload
ANCHOR_FWD = "TCAATCCG" 
# Payload æˆªå–é•¿åº¦ (ä»é”šç‚¹åå¼€å§‹å–å¤šå°‘bp)
PAYLOAD_EXTRACT_LEN = 115 

# ===========================================

def load_fasta_references(fasta_path):
    print(f"ğŸ“– [Ref] è¯»å–å‚è€ƒåºåˆ—: {os.path.basename(fasta_path)} ...")
    refs = {}
    with open(fasta_path, 'r') as f:
        # è¯»å–æ‰€æœ‰è¡Œ
        lines = [l.strip() for l in f if l.strip()]
    
    # è‡ªåŠ¨æ£€æµ‹æ ¼å¼
    if lines[0].startswith(">"):
        # æ ‡å‡† FASTA
        current_tag = None
        for line in lines:
            if line.startswith(">"):
                current_tag = line[1:]
            elif current_tag:
                refs[current_tag] = line
    else:
        # ID20 ç‰¹æ®Šæ ¼å¼: Line 1 = ID, Line 2 = Seq
        print("   â„¹ï¸ æ£€æµ‹åˆ°æ—  '>' æ ¼å¼ï¼Œå¯ç”¨åŒè¡Œè¯»å–æ¨¡å¼...")
        for i in range(0, len(lines), 2):
            if i + 1 < len(lines):
                tag = lines[i]
                seq = lines[i+1]
                refs[tag] = seq
                
    print(f"   âœ… åŠ è½½äº† {len(refs)} æ¡å‚è€ƒåºåˆ— (Ground Truth)")
    return refs

def extract_payload(sequence):
    """
    æ™ºèƒ½æå–æœ‰æ•ˆè½½è·ï¼š
    1. æœç´¢ Fwd Primer çš„é”šç‚¹
    2. æå–é”šç‚¹åçš„åºåˆ—ä½œä¸º Payload
    3. å¦‚æœæ‰¾ä¸åˆ°é”šç‚¹ï¼Œè¿”å›åŸåºåˆ—(æˆªæ–­)
    """
    pos = sequence.find(ANCHOR_FWD)
    if pos != -1:
        # æ‰¾åˆ°äº†é”šç‚¹ï¼Œå–é”šç‚¹ä¹‹åçš„å†…å®¹
        start = pos + len(ANCHOR_FWD)
        # æå–å¹¶æˆªæ–­/è¡¥é½åˆ°å›ºå®šé•¿åº¦
        payload = sequence[start : start + CLOVER_SEQ_LENGTH]
    else:
        # æ²¡æ‰¾åˆ°é”šç‚¹(å¯èƒ½æ˜¯å¤´éƒ¨ç¼ºå¤±)ï¼Œç›´æ¥å–å‰æ®µ
        payload = sequence[:CLOVER_SEQ_LENGTH]
    
    # é•¿åº¦å¯¹é½ï¼šå¦‚æœçŸ­äº†å°±è¡¥Nï¼Œé•¿äº†å·²æˆªæ–­
    if len(payload) < CLOVER_SEQ_LENGTH:
        payload = payload.ljust(CLOVER_SEQ_LENGTH, 'N')
        
    return payload

def process_id20_fixed():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    exp_dir = os.path.join(current_dir, "Experiments", f"{DATASET_NAME}_Real")
    
    dir_raw = os.path.join(exp_dir, "01_FormattedInput")
    dir_clover = os.path.join(exp_dir, "02_CloverOut")
    dir_feddna = os.path.join(exp_dir, "03_FedDNA_In")
    dir_temp = os.path.join(exp_dir, "99_Temp")
    dir_chunks = os.path.join(exp_dir, "00_Chunks")
    
    # æ¸…ç†æ—§çš„åˆ‡ç‰‡ï¼Œé˜²æ­¢æ··æ·†
    if os.path.exists(dir_chunks):
        shutil.rmtree(dir_chunks)
    
    for d in [dir_raw, dir_clover, dir_feddna, dir_temp, dir_chunks]:
        os.makedirs(d, exist_ok=True)

    # ä¼˜å…ˆè¯»å–æ¸…æ´—åçš„æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¦åˆ™è¯»å–åŸå§‹æ•°æ®
    clean_reads_file = "id20_tags_reads_clean.txt"
    raw_reads_file = "id20_tags_reads.txt"
    
    if os.path.exists(os.path.join(SOURCE_DIR, clean_reads_file)):
        print(f"âœ¨ ä½¿ç”¨æ¸…æ´—åçš„æ•°æ®: {clean_reads_file}")
        src_reads_path = os.path.join(SOURCE_DIR, clean_reads_file)
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°æ¸…æ´—æ•°æ®ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: {raw_reads_file}")
        src_reads_path = os.path.join(SOURCE_DIR, raw_reads_file)

    src_ref_path = os.path.join(SOURCE_DIR, "id20_refs.fasta")
    
    # === Step 1: æ™ºèƒ½åˆ‡ç‰‡ä¸å»å¼•ç‰© ===
    print(f"\n[Step 1] åˆ‡ç‰‡å¹¶æå– Payload (å»é™¤å…¬å…±å¼•ç‰©)...")
    if not os.path.exists(src_reads_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æºæ–‡ä»¶ {src_reads_path}")
        return

    chunk_idx = 0
    line_count = 0
    current_out = None
    
    with open(src_reads_path, 'r') as fin:
        for line in fin:
            if line_count % CHUNK_SIZE == 0:
                if current_out: current_out.close()
                chunk_name = os.path.join(dir_chunks, f"chunk_{chunk_idx:03d}.txt")
                current_out = open(chunk_name, 'w')
                print(f"   æ­£åœ¨ç”Ÿæˆåˆ‡ç‰‡: chunk_{chunk_idx:03d}.txt ...", end='\r')
                chunk_idx += 1
            
            parts = line.strip().split()
            if len(parts) >= 2:
                raw_seq = parts[-1]
                # === æ ¸å¿ƒä¿®æ”¹: æå– Payload ===
                clean_seq = extract_payload(raw_seq)
                # ===========================
                global_line_idx = line_count + 1
                current_out.write(f"{global_line_idx} {clean_seq}\n")
            
            line_count += 1
            
    if current_out: current_out.close()
    print(f"\n   âœ… åˆ‡ç‰‡å®Œæˆã€‚å…± {line_count} æ¡ readsã€‚")
    existing_chunks = sorted(glob.glob(os.path.join(dir_chunks, "chunk_*.txt")))

    # === Step 2: é€å—è¿è¡Œ Clover ===
    print(f"\n[Step 2] è¿è¡Œ Clover (L={CLOVER_SEQ_LENGTH})...")
    env = os.environ.copy()
    env["PYTHONPATH"] = os.path.join(current_dir, "Clover") + os.pathsep + env.get("PYTHONPATH", "")
    
    final_clover_result = os.path.join(dir_clover, "clover_result_merged.txt")
    
    # ä¸ºäº†ä¿è¯ç»“æœæ­£ç¡®ï¼Œå»ºè®®æ¯æ¬¡é‡è·‘ Step 2
    if os.path.exists(final_clover_result):
        os.remove(final_clover_result)
        
    with open(final_clover_result, 'w') as f_merged:
        pass 
        
    for i, chunk_path in enumerate(existing_chunks):
        chunk_name = os.path.basename(chunk_path)
        chunk_out_base = os.path.join(dir_chunks, f"out_{chunk_name}")
        chunk_out_txt = chunk_out_base + ".txt"
        
        print(f"   ğŸš€ [{i+1}/{len(existing_chunks)}] å¤„ç†åˆ‡ç‰‡: {chunk_name}")
        
        # æ³¨æ„: è¿™é‡Œä½¿ç”¨æå–åçš„ payload é•¿åº¦ (110)
        cmd = [sys.executable, "-m", "clover.main", "-I", chunk_path, 
               "-O", chunk_out_base, "-L", str(CLOVER_SEQ_LENGTH), "-P", str(CLOVER_PROCESSES), "--no-tag"]
        try:
            subprocess.run(cmd, check=True, env=env) 
        except subprocess.CalledProcessError as e:
            print(f"\nâŒ åˆ‡ç‰‡ {chunk_name} å¤„ç†å¤±è´¥ï¼Exit Code: {e.returncode}")
            return
        
        # åˆå¹¶
        with open(chunk_out_txt, 'r') as f_in, open(final_clover_result, 'a') as f_out:
            shutil.copyfileobj(f_in, f_out)
        os.remove(chunk_out_txt)
        
    print(f"   âœ… Clover èšç±»å®Œæˆã€‚")

    # === Step 3: åˆå¹¶ä¸æ’åº ===
    print(f"\n[Step 3] ç”Ÿæˆ FedDNA è¾“å…¥...")
    
    cluster_map = array.array('i') 
    def stream_tokens(path):
        with open(path, 'r') as f:
            buf = ""
            while True:
                chunk = f.read(1024*1024)
                if not chunk: break
                cleaned = chunk.replace('[', ' ').replace(']', ' ').replace('(', ' ').replace(')', ' ').replace(',', ' ').replace("'", " ").replace('"', " ")
                buf += cleaned
                tokens = buf.split()
                if chunk[-1].isspace() or chunk[-1] in "[](),'\"":
                    for t in tokens: yield t
                    buf = ""
                else:
                    if tokens:
                        for t in tokens[:-1]: yield t
                        buf = tokens[-1]
                    else: pass
            if buf.strip(): yield buf.strip()

    print("   [3.1] åŠ è½½èšç±»æ˜ å°„...")
    token_gen = stream_tokens(final_clover_result)
    try:
        while True:
            idx_str = next(token_gen)
            cid_str = next(token_gen)
            cluster_map.append(int(cid_str))
    except StopIteration:
        pass

    print("   [3.2] æŠ•ç¥¨ Reference...")
    cluster_votes = defaultdict(lambda: defaultdict(int)) 
    with open(src_reads_path, 'r') as f:
        valid_idx = 0
        for line in f:
            parts = line.strip().split()
            if len(parts) < 2: continue
            tag_in_read = parts[0]
            if valid_idx < len(cluster_map):
                cid = cluster_map[valid_idx]
                if cid != -1: cluster_votes[cid][tag_in_read] += 1
            valid_idx += 1
            if valid_idx % 5000000 == 0: print(f"      å·²æŠ•ç¥¨ {valid_idx} æ¡...", end='\r')

    print("\n      ç»“ç®—æŠ•ç¥¨...")
    ref_dict = load_fasta_references(src_ref_path)
    cluster_ref_seqs = {} 
    
    matched_count = 0
    for cid, votes in cluster_votes.items():
        if not votes: continue
        best_tag = max(votes, key=votes.get)
        if best_tag in ref_dict: 
            cluster_ref_seqs[cid] = ref_dict[best_tag]
            matched_count += 1
            
    print(f"      æˆåŠŸåŒ¹é… Reference: {matched_count} (ç›®æ ‡: ~60ä¸‡)")

    del cluster_votes, ref_dict
    
    print("   [3.3] ç”Ÿæˆæ’åºä¸­é—´æ–‡ä»¶...")
    temp_unsorted = os.path.join(dir_temp, "unsorted_reads.txt")
    temp_sorted = os.path.join(dir_temp, "sorted_reads.txt")
    
    # æ³¨æ„ï¼šè¿™é‡Œå†™å…¥çš„æ˜¯åŸå§‹å®Œæ•´ reads (src_reads_path)ï¼Œè€Œä¸æ˜¯ payload
    # å› ä¸º FedDNA è®­ç»ƒé€šå¸¸éœ€è¦å®Œæ•´çš„ reads (å«å¼•ç‰©)
    with open(src_reads_path, 'r') as fin, open(temp_unsorted, 'w') as fout:
        valid_idx = 0
        for line in fin:
            parts = line.strip().split()
            if len(parts) < 2: continue
            if valid_idx < len(cluster_map):
                cid = cluster_map[valid_idx]
                if cid != -1 and cid in cluster_ref_seqs:
                    fout.write(f"{cid}\t{parts[-1]}\n")
            valid_idx += 1
            if valid_idx % 5000000 == 0: print(f"      å·²é¢„å¤„ç† {valid_idx} æ¡...", end='\r')
    
    del cluster_map
    print("\n   [3.4] å¤–éƒ¨æ’åº...")
    subprocess.run(f"sort -n -k1,1 -S 50% {temp_unsorted} -o {temp_sorted}", shell=True, check=True)
    os.remove(temp_unsorted)

    print("   [3.5] å†™å…¥æœ€ç»ˆæ–‡ä»¶...")
    out_read = os.path.join(dir_feddna, "read.txt")
    out_ref = os.path.join(dir_feddna, "ref.txt")
    
    current_cid = None
    cluster_count = 0
    with open(temp_sorted, 'r') as fin, open(out_read, 'w') as fr, open(out_ref, 'w') as ff:
        for line in fin:
            parts = line.strip().split('\t')
            if len(parts) != 2: continue
            cid = int(parts[0])
            seq = parts[1]
            if cid != current_cid:
                if current_cid is not None: fr.write("===============================\n")
                current_cid = cid
                cluster_count += 1
                ref_seq = cluster_ref_seqs[cid]
                ff.write(ref_seq + "\n")
                fr.write(ref_seq + "\n")
            fr.write(seq + "\n")
        if current_cid is not None: fr.write("===============================\n")
    
    if os.path.exists(temp_sorted): os.remove(temp_sorted)
    print(f"\nğŸ‰ id20 ä¿®å¤ç‰ˆå¤„ç†å®Œæ¯•ï¼")
    print(f"ğŸ“Š æœ€ç»ˆæœ‰æ•ˆç°‡: {cluster_count} (åº”è¯¥æ¥è¿‘ 60ä¸‡)")

if __name__ == "__main__":
    process_id20_fixed()