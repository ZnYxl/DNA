import os
import sys
import array
from collections import defaultdict, Counter

# ================= é…ç½®åŒºåŸŸ =================
# 1. åŸå§‹å¸¦æ ‡ç­¾çš„æ•°æ®æ–‡ä»¶ (Ground Truth)
# æ³¨æ„ï¼šè¿™é‡Œæ˜¯ exp_1 çš„è·¯å¾„
GT_FILE = "/mnt/st_data/liangxinyi/code/CC/Step0/ç»™å¸ˆå¦¹çš„cloveræ•°æ®é›†/exp_1/exp1_tags_reads.txt"

# 2. Clover èšç±»è¾“å‡ºæ–‡ä»¶ (Prediction)
# å¯¹åº” run_real_data_exp1_Fixed.py ç”Ÿæˆçš„ç»“æœ
CLOVER_OUT_FILE = "./Experiments/exp_1_Real/02_CloverOut/clover_result_merged.txt"

# ===========================================

class CompactGroundTruth:
    def __init__(self):
        self.tag_to_id = {}    # å”¯ä¸€ Tag (str) -> int ID
        self.id_to_tag = []    # int ID -> å”¯ä¸€ Tag (str)
        # ä½¿ç”¨ 'I' (unsigned int) æ•°ç»„å­˜å‚¨ï¼Œæçœå†…å­˜
        self.read_labels = array.array('I') 
        
    def load(self, file_path):
        print(f"ğŸ“– [1/3] æ­£åœ¨åŠ è½½ Ground Truth (exp_1)...")
        if not os.path.exists(file_path):
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
            sys.exit(1)

        with open(file_path, 'r') as f:
            for i, line in enumerate(f):
                parts = line.strip().split()
                if not parts:
                    self.read_labels.append(0)
                    continue
                
                # exp_1 æ ¼å¼: Tag Sequence (ä¾‹å¦‚ "6512 TCCT...")
                tag = parts[0]
                
                if tag not in self.tag_to_id:
                    new_id = len(self.id_to_tag) + 1 
                    self.tag_to_id[tag] = new_id
                    self.id_to_tag.append(tag)
                
                self.read_labels.append(self.tag_to_id[tag])
                
                if (i + 1) % 1000000 == 0:
                    print(f"   å·²ç´¢å¼• {i + 1} è¡Œ...", end='\r')
                        
        print(f"\n   âœ… GT åŠ è½½å®Œæˆã€‚æ€» Reads: {len(self.read_labels)}")
        print(f"   - å”¯ä¸€ Tags æ•°: {len(self.id_to_tag)}")

    def get_tag_id(self, read_idx):
        if read_idx < 0 or read_idx >= len(self.read_labels):
            return 0
        return self.read_labels[read_idx]


def stream_clover_tokens(file_path):
    """æµå¼è§£æ Clover ç»“æœ"""
    with open(file_path, 'r') as f:
        buffer = ""
        while True:
            chunk = f.read(1024*1024)
            if not chunk: break
            
            cleaned = chunk.replace('[', ' ').replace(']', ' ')\
                           .replace('(', ' ').replace(')', ' ')\
                           .replace(',', ' ').replace("'", " ").replace('"', " ")
            buffer += cleaned
            tokens = buffer.split()
            
            if chunk[-1].isspace() or chunk[-1] in "[](),'\"":
                for t in tokens: yield t
                buffer = ""
            else:
                if len(tokens) > 0:
                    for t in tokens[:-1]: yield t
                    buffer = tokens[-1]
                else: pass
        if buffer.strip(): yield buffer.strip()

def evaluate(gt_data, clover_path):
    print(f"\nğŸš€ [2/3] æµå¼å¤„ç†èšç±»ç»“æœ (Token Stream)...")
    
    cluster_stats = defaultdict(Counter)
    total_reads_clustered = 0
    
    token_stream = stream_clover_tokens(clover_path)
    
    try:
        while True:
            try:
                idx_token = next(token_stream)
                cid_token = next(token_stream)
            except StopIteration:
                break
            
            # Clover è¾“å‡ºçš„ç´¢å¼•é€šå¸¸æ˜¯ 1-basedï¼Œä½†ä¹Ÿå¯èƒ½æ˜¯åˆ‡ç‰‡æ—¶çš„å…¨å±€è¡Œå·
            # æˆ‘ä»¬è„šæœ¬é‡Œå†™çš„æ˜¯ global_line_idxï¼Œæ‰€ä»¥æ˜¯ 1-based
            line_idx = int(idx_token)
            cluster_id = cid_token 
            
            if str(cluster_id) == '-1':
                continue
            
            # è½¬æ¢ä¸º 0-based ç´¢å¼•å»æŸ¥ GT
            read_idx = line_idx - 1
            true_tag_id = gt_data.get_tag_id(read_idx)
            
            if true_tag_id != 0:
                cluster_stats[str(cluster_id)][true_tag_id] += 1
                total_reads_clustered += 1
                
            if total_reads_clustered % 1000000 == 0 and total_reads_clustered > 0:
                print(f"   å·²ç»Ÿè®¡ {total_reads_clustered} ä¸ªèšç±»æˆå‘˜...", end='\r')

    except ValueError as e:
        print(f"\nâš ï¸ è§£æè­¦å‘Š: æ•°æ®æ ¼å¼å¼‚å¸¸: {e}")

    # === [3/3] ç”ŸæˆæŠ¥å‘Š ===
    print(f"\n\nğŸ“Š æ­£åœ¨æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯...")
    
    correct_reads_count = 0
    recovered_tag_ids = set()
    cluster_purities = []
    
    for cid, counts in cluster_stats.items():
        if not counts: continue
        
        # æ‰¾å‡ºè¯¥ç°‡çš„ä¸»å¯¼ Tag
        dominant_tag_id, dominant_count = counts.most_common(1)[0]
        total_in_cluster = sum(counts.values())
        
        purity = dominant_count / total_in_cluster
        cluster_purities.append(purity)
        
        correct_reads_count += dominant_count
        recovered_tag_ids.add(dominant_tag_id)

    total_unique_tags = len(gt_data.id_to_tag)
    avg_purity = sum(cluster_purities) / len(cluster_purities) if cluster_purities else 0
    micro_accuracy = correct_reads_count / total_reads_clustered if total_reads_clustered else 0
    recovery_rate = len(recovered_tag_ids) / total_unique_tags if total_unique_tags else 0
    
    print("\n" + "="*40)
    print("       ğŸ“Š CLOVER è¯„ä¼°æŠ¥å‘Š - exp_1 æ•°æ®é›†")
    print("="*40)
    print(f"1. åŸå§‹ Tag æ¢å¤ç‡ (Recovery Rate):")
    print(f"   {len(recovered_tag_ids)} / {total_unique_tags}  ({recovery_rate*100:.2f}%)")
    print(f"   (æ³¨ï¼šå¦‚æœæ­¤æ•°å€¼æ¥è¿‘ 100%ï¼Œè¯´æ˜å»å¼•ç‰©ç­–ç•¥å¤§è·å…¨èƒœï¼)")
    
    print(f"\n2. å¹³å‡ç°‡çº¯åº¦ (Average Purity):")
    print(f"   {avg_purity*100:.2f}%")
    
    print(f"\n3. æ•´ä½“å‡†ç¡®ç‡ (Micro Accuracy):")
    print(f"   {micro_accuracy*100:.2f}%")
    
    print(f"\n4. ç»Ÿè®¡æ‘˜è¦:")
    print(f"   æœ‰æ•ˆèšç±» Reads æ•°: {total_reads_clustered}")
    print(f"   ç”Ÿæˆçš„ç°‡æ•°é‡: {len(cluster_stats)}")
    print("="*40)

if __name__ == "__main__":
    if not os.path.exists(CLOVER_OUT_FILE):
        print(f"âŒ æ‰¾ä¸åˆ° Clover è¾“å‡ºæ–‡ä»¶: {CLOVER_OUT_FILE}")
        print(f"   è¯·å…ˆè¿è¡Œ run_real_data_exp1_Fixed.py ç”Ÿæˆç»“æœã€‚")
        sys.exit(1)

    gt = CompactGroundTruth()
    gt.load(GT_FILE)
    evaluate(gt, CLOVER_OUT_FILE)