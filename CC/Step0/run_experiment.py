# run_experiment.py - æ”¹è¿›ç‰ˆ
import os
import sys
import subprocess
import datetime
import utils

# ================= æ”¹è¿›çš„å®éªŒé…ç½® =================
EXP_NAME = "Improved_Clover_Pipeline"
SEQ_LENGTH = 150
NUM_CLUSTERS = 8        # ğŸ”¥ å‡å°‘ç°‡æ•°ï¼Œæé«˜æˆåŠŸç‡
READS_PER_CLUSTER = 25  # ğŸ”¥ å¢åŠ æ¯ç°‡readsæ•°
CLOVER_PROCESSES = 0
REFERENCE_TYPE = "diverse"  # ğŸ”¥ æ–°å¢ï¼šå‚è€ƒåºåˆ—ç±»å‹ ("diverse" æˆ– "motif")
MIN_DISTANCE = 0.25     # ğŸ”¥ æ–°å¢ï¼šç°‡é—´æœ€å°è·ç¦»
# ===========================================

def run():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    
    # 1. å‡†å¤‡æ–‡ä»¶å¤¹
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    base_dir = os.path.join(current_dir, "Experiments", f"{timestamp}_{EXP_NAME}")
    
    dir_raw = os.path.join(base_dir, "01_RawData")
    dir_clover = os.path.join(base_dir, "02_CloverOut")
    dir_feddna = os.path.join(base_dir, "03_FedDNA_In")
    
    for d in [dir_raw, dir_clover, dir_feddna]:
        os.makedirs(d, exist_ok=True)
        
    print(f"ğŸš€ å¼€å§‹æ”¹è¿›å®éªŒ: {EXP_NAME}")
    print(f"ğŸ“‚ å®éªŒç›®å½•: {base_dir}")
    print(f"âš™ï¸  å®éªŒå‚æ•°:")
    print(f"   ç°‡æ•°: {NUM_CLUSTERS}")
    print(f"   æ¯ç°‡reads: {READS_PER_CLUSTER}")
    print(f"   åºåˆ—é•¿åº¦: {SEQ_LENGTH}")
    print(f"   å‚è€ƒåºåˆ—ç±»å‹: {REFERENCE_TYPE}")
    print(f"   æœ€å°ç°‡é—´è·ç¦»: {MIN_DISTANCE}")
    
    # 2. ç”Ÿæˆæ”¹è¿›æ•°æ®
    print("\n[Step 1] ç”Ÿæˆæ”¹è¿›çš„æ¨¡æ‹Ÿæ•°æ®...")
    try:
        raw_reads_path, gt_path = utils.generate_data(
            output_dir=dir_raw,
            num_clusters=NUM_CLUSTERS,
            reads_per_cluster=READS_PER_CLUSTER,
            seq_len=SEQ_LENGTH,
            reference_type=REFERENCE_TYPE,
            min_distance=MIN_DISTANCE
        )
        print(f"âœ… æ”¹è¿›æ•°æ®å·²ç”Ÿæˆ: {raw_reads_path}")
        
        # éªŒè¯æ•°æ®è´¨é‡
        if utils.validate_generated_data(gt_path, raw_reads_path):
            print("âœ… æ•°æ®è´¨é‡éªŒè¯é€šè¿‡")
        else:
            print("âš ï¸  æ•°æ®è´¨é‡éªŒè¯æœ‰é—®é¢˜ï¼Œä½†ç»§ç»­æ‰§è¡Œ")
            
    except Exception as e:
        print(f"âŒ æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # 3. è¿è¡Œ Clover
    print("\n[Step 2] è¿è¡Œ Clover èšç±»...")
    
    clover_out_arg = os.path.join(dir_clover, "clover_result") 
    clover_out_real = clover_out_arg + ".txt"
    
    env = os.environ.copy()
    clover_repo_path = os.path.join(current_dir, "Clover")
    env["PYTHONPATH"] = clover_repo_path + os.pathsep + env.get("PYTHONPATH", "")
    
    cmd = [
        sys.executable, "-m", "clover.main",
        "-I", raw_reads_path,
        "-O", clover_out_arg,
        "-L", str(SEQ_LENGTH),
        "-P", str(CLOVER_PROCESSES),
        "--no-tag"
    ]
    
    print(f"ğŸ”§ Cloverå‘½ä»¤: {' '.join(cmd)}")
    
    try:
        result = subprocess.run(cmd, check=True, env=env, 
                              capture_output=True, text=True)
        print("âœ… Cloverè¿è¡ŒæˆåŠŸ")
        if result.stdout:
            print(f"   è¾“å‡º: {result.stdout[:200]}...")
        if result.stderr:
            print(f"   è­¦å‘Š: {result.stderr[:200]}...")
            
    except subprocess.CalledProcessError as e:
        print(f"âŒ Clover è¿è¡Œå¤±è´¥: {e}")
        print(f"   è¿”å›ç : {e.returncode}")
        if e.stdout:
            print(f"   æ ‡å‡†è¾“å‡º: {e.stdout}")
        if e.stderr:
            print(f"   é”™è¯¯è¾“å‡º: {e.stderr}")
        return

    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
    if not os.path.exists(clover_out_real):
        print(f"âŒ ä¸¥é‡é”™è¯¯: Cloverè¾“å‡ºæ–‡ä»¶æœªæ‰¾åˆ°ï¼")
        print(f"   é¢„æœŸè·¯å¾„: {clover_out_real}")
        print(f"   ç›®å½•å†…å®¹: {os.listdir(dir_clover)}")
        return
    else:
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(clover_out_real)
        print(f"âœ… Clover è¾“å‡ºæ–‡ä»¶å­˜åœ¨: {clover_out_real} ({file_size} bytes)")
        
        # é¢„è§ˆæ–‡ä»¶å†…å®¹
        try:
            with open(clover_out_real, 'r') as f:
                preview = f.read(200)
                print(f"   æ–‡ä»¶é¢„è§ˆ: {preview}...")
        except Exception as e:
            print(f"   æ— æ³•é¢„è§ˆæ–‡ä»¶: {e}")

    # 4. è½¬æ¢æ ¼å¼
    print("\n[Step 3] è½¬æ¢ä¸º FedDNA æ ¼å¼...")
    try:
        count, final_path = utils.clover_to_feddna(
            clover_out_real, raw_reads_path, dir_feddna
        )
        
        # 5. ç”Ÿæˆå®éªŒæ€»ç»“
        summary_path = os.path.join(base_dir, "experiment_summary.txt")
        with open(summary_path, 'w') as f:
            f.write(f"=== æ”¹è¿›å®éªŒæ€»ç»“ ===\n")
            f.write(f"å®éªŒåç§°: {EXP_NAME}\n")
            f.write(f"æ—¶é—´æˆ³: {timestamp}\n")
            f.write(f"å®éªŒç›®å½•: {base_dir}\n\n")
            
            f.write(f"=== å®éªŒå‚æ•° ===\n")
            f.write(f"ç°‡æ•°: {NUM_CLUSTERS}\n")
            f.write(f"æ¯ç°‡reads: {READS_PER_CLUSTER}\n")
            f.write(f"åºåˆ—é•¿åº¦: {SEQ_LENGTH}\n")
            f.write(f"å‚è€ƒåºåˆ—ç±»å‹: {REFERENCE_TYPE}\n")
            f.write(f"æœ€å°ç°‡é—´è·ç¦»: {MIN_DISTANCE}\n\n")
            
            f.write(f"=== ç»“æœç»Ÿè®¡ ===\n")
            f.write(f"Cloveræœ‰æ•ˆç°‡æ•°: {count}\n")
            f.write(f"åŸå§‹ç°‡æ•°: {NUM_CLUSTERS}\n")
            f.write(f"èšç±»æˆåŠŸç‡: {count/NUM_CLUSTERS*100:.1f}%\n")
            f.write(f"FedDNAè¾“å…¥æ–‡ä»¶: {final_path}\n")
        
        print("-" * 50)
        print(f"ğŸ‰ æ”¹è¿›å®éªŒåœ†æ»¡ç»“æŸï¼")
        print(f"ğŸ“Š Cloveræœ‰æ•ˆç°‡æ•°: {count}/{NUM_CLUSTERS} ({count/NUM_CLUSTERS*100:.1f}%)")
        print(f"ğŸ‘‰ FedDNA è¾“å…¥æ–‡ä»¶å·²å°±ç»ª: {dir_feddna}")
        print(f"ğŸ“‹ å®éªŒæ€»ç»“: {summary_path}")
        print(f"ğŸ“ˆ æ•°æ®ç»Ÿè®¡: {os.path.join(dir_raw, 'data_stats.txt')}")
        print("-" * 50)
        
        # 6. ä¸ºåç»­ç¥ç»ç½‘ç»œè®­ç»ƒå‡†å¤‡æ•°æ®
        prepare_for_neural_network(base_dir, dir_feddna)
        
    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def prepare_for_neural_network(base_dir, feddna_dir):
    """ğŸ”¥ ä¸ºç¥ç»ç½‘ç»œè®­ç»ƒå‡†å¤‡æ•°æ®"""
    try:
        # åˆ›å»ºç¥ç»ç½‘ç»œæ•°æ®ç›®å½•
        nn_dir = os.path.join(base_dir, "04_NeuralNet_Ready")
        os.makedirs(nn_dir, exist_ok=True)
        
        # å¤åˆ¶FedDNAæ ¼å¼çš„æ–‡ä»¶
        import shutil
        read_file = os.path.join(feddna_dir, "read.txt")
        ref_file = os.path.join(feddna_dir, "reference.txt")
        
        if os.path.exists(read_file) and os.path.exists(ref_file):
            shutil.copy2(read_file, nn_dir)
            shutil.copy2(ref_file, nn_dir)
            
            # åˆ›å»ºé…ç½®æ–‡ä»¶
            config_path = os.path.join(nn_dir, "training_config.txt")
            with open(config_path, 'w') as f:
                f.write("=== ç¥ç»ç½‘ç»œè®­ç»ƒé…ç½®å»ºè®® ===\n")
                f.write(f"æ•°æ®ç›®å½•: {nn_dir}\n")
                f.write(f"åºåˆ—é•¿åº¦: {SEQ_LENGTH}\n")
                f.write(f"é¢„æœŸç°‡æ•°: æ ¹æ®Cloverç»“æœè°ƒæ•´\n\n")
                
                f.write("=== è®­ç»ƒå‚æ•°å»ºè®® ===\n")
                f.write("batch_size: 1\n")
                f.write("learning_rate: 1e-4\n")
                f.write("max_epochs: 10\n")
                f.write("convergence_threshold: 0.08\n")
                f.write("min_epochs: 4\n\n")
                
                f.write("=== æ¨¡å‹å‚æ•°å»ºè®® ===\n")
                f.write("hidden_dim: 128\n")
                f.write("num_layers: 3\n")
                f.write("num_heads: 8\n")
                f.write("dropout: 0.1\n")
                f.write("contrastive_dim: 64\n")
            
            print(f"ğŸ§  ç¥ç»ç½‘ç»œæ•°æ®å·²å‡†å¤‡: {nn_dir}")
            print(f"ğŸ“‹ è®­ç»ƒé…ç½®å»ºè®®: {config_path}")
            
    except Exception as e:
        print(f"âš ï¸  ç¥ç»ç½‘ç»œæ•°æ®å‡†å¤‡å¤±è´¥: {e}")

if __name__ == "__main__":
    run()
