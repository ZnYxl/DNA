import os
import sys
import subprocess
import array
import gc
from collections import defaultdict, Counter

# ================= å®éªŒé…ç½® =================
DATASET_NAME = "Goldman"  # æ•°æ®é›†åç§°
SOURCE_DIR = "ç»™å¸ˆå¦¹çš„cloveræ•°æ®é›†"
SEQ_LENGTH = 117          # Goldman æ•°æ®é›†çš„åºåˆ—é•¿åº¦
CLOVER_PROCESSES = 0      # 0 è¡¨ç¤ºè‡ªåŠ¨ä½¿ç”¨æ‰€æœ‰æ ¸å¿ƒ

# ===========================================

def load_fasta_references(fasta_path):
    print(f"ğŸ“– [Ref] è¯»å–å‚è€ƒåºåˆ—: {os.path.basename(fasta_path)} ...")
    refs = {}
    current_tag = None
    with open(fasta_path, 'r') as f:
        for line in f:
            line = line.strip()
            if not line: continue
            
            # å…¼å®¹æ ‡å‡†çš„ FASTA (>ID) å’Œä½ å¯èƒ½é‡åˆ°çš„çº¯æ–‡æœ¬ ID
            if line.startswith(">"):
                current_tag = line[1:]
            # å¦‚æœè¿™ä¸€è¡Œå…¨æ˜¯æ•°å­—/å­—æ¯ä¸”å¾ˆçŸ­ï¼ˆä¸åƒDNAåºåˆ—ï¼‰ï¼Œå¯èƒ½æ˜¯ä¸å¸¦>çš„ID
            elif len(line) < 50 and set(line).issubset(set("0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ_")):
                 # è¿™åªæ˜¯ä¸€ä¸ªå¯å‘å¼åˆ¤æ–­ï¼Œé˜²æ­¢è¯¯åˆ¤çŸ­åºåˆ—ã€‚æ ‡å‡†FASTAåº”è¯¥æœ‰>
                 # å¦‚æœä½ çš„æ–‡ä»¶ç¡®å®æ²¡æœ‰>ï¼Œè¿™é‡Œä¼šå°è¯•æ•è·ID
                 # ä½†æ ¹æ®ä¹‹å‰çš„è®°å½•ï¼ŒGoldman_fa.fasta åº”è¯¥æ˜¯æ ‡å‡†çš„ï¼Œæ‰€ä»¥è¿™é‡Œä¸»è¦ä¾é  >
                 pass 
            else:
                # è®¤ä¸ºæ˜¯åºåˆ—
                if current_tag:
                    refs[current_tag] = line
    print(f"   âœ… åŠ è½½äº† {len(refs)} æ¡å‚è€ƒåºåˆ—")
    return refs

def stream_clover_results(file_path):
    """æµå¼è§£æ Clover ç»“æœï¼Œå…¼å®¹å„ç§æ ¼å¼"""
    with open(file_path, 'r') as f:
        buffer = ""
        while True:
            chunk = f.read(1024*1024) # 1MB chunks
            if not chunk: break
            
            # æ¸…æ´—å­—ç¬¦
            cleaned = chunk.replace('[', ' ').replace(']', ' ')\
                           .replace('(', ' ').replace(')', ' ')\
                           .replace(',', ' ').replace("'", " ").replace('"', " ")
            buffer += cleaned
            tokens = buffer.split()
            
            if chunk[-1].isspace() or chunk[-1] in "[](),'\"":
                for t in tokens: yield t
                buffer = ""
            else:
                if len(tokens) > 0:
                    for t in tokens[:-1]: yield t
                    buffer = tokens[-1]
                else: pass
        if buffer.strip(): yield buffer.strip()

def process_goldman_data():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    # ä½¿ç”¨ç‹¬ç«‹çš„æ–‡ä»¶å¤¹ Goldman_Real
    exp_dir = os.path.join(current_dir, "Experiments", f"{DATASET_NAME}_Real")
    
    dir_raw = os.path.join(exp_dir, "01_FormattedInput")
    dir_clover = os.path.join(exp_dir, "02_CloverOut")
    dir_feddna = os.path.join(exp_dir, "03_FedDNA_In")
    dir_temp = os.path.join(exp_dir, "99_Temp") # ä¸´æ—¶æ–‡ä»¶ç›®å½•
    
    for d in [dir_raw, dir_clover, dir_feddna, dir_temp]:
        os.makedirs(d, exist_ok=True)

    # Goldman ç‰¹å®šçš„æ–‡ä»¶å
    reads_file = "now_goldman_tags_reads.txt"
    ref_file = "Goldman_fa.fasta"
    
    src_reads_path = os.path.join(SOURCE_DIR, reads_file)
    src_ref_path = os.path.join(SOURCE_DIR, ref_file)
    clover_input_path = os.path.join(dir_raw, "clover_input.txt")
    clover_out_file = os.path.join(dir_clover, "clover_result")

    # === Step 1: æ£€æŸ¥æˆ–ç”Ÿæˆè¾“å…¥ ===
    if not os.path.exists(clover_input_path) or os.path.getsize(clover_input_path) < 1024:
        print(f"\n[Step 1] ç”Ÿæˆ Clover è¾“å…¥ (Goldman)...")
        if not os.path.exists(src_reads_path):
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æºæ–‡ä»¶ {src_reads_path}")
            return

        with open(src_reads_path, 'r') as fin, open(clover_input_path, 'w') as fout:
            line_idx = 1
            for line in fin:
                parts = line.strip().split()
                if len(parts) < 2: continue
                # Goldman æ ¼å¼: Tag Sequence
                # æ³¨æ„ï¼šparts[-1] è‡ªåŠ¨å–æœ€åä¸€ä¸ªéç©ºå­—æ®µä½œä¸ºåºåˆ—ï¼Œå…¼å®¹ä¸­é—´å¯èƒ½çš„ç©ºæ ¼
                fout.write(f"{line_idx} {parts[-1]}\n")
                line_idx += 1
                
                if line_idx % 1000000 == 0:
                    print(f"   å·²æ ¼å¼åŒ– {line_idx} æ¡...", end='\r')
        print(f"\n   âœ… æ ¼å¼åŒ–å®Œæˆã€‚")
    else:
        print(f"\n[Step 1] è¾“å…¥æ–‡ä»¶å·²å°±ç»ªã€‚")

    # === Step 2: è¿è¡Œ Clover ===
    real_clover_out = clover_out_file + ".txt"
    if not os.path.exists(real_clover_out) or os.path.getsize(real_clover_out) < 1024:
        print(f"\n[Step 2] è¿è¡Œ Clover (L={SEQ_LENGTH})...")
        env = os.environ.copy()
        env["PYTHONPATH"] = os.path.join(current_dir, "Clover") + os.pathsep + env.get("PYTHONPATH", "")
        
        # æ³¨æ„: -L å‚æ•°å·²æ”¹ä¸º 117
        cmd = [sys.executable, "-m", "clover.main", "-I", clover_input_path, 
               "-O", clover_out_file, "-L", str(SEQ_LENGTH), "-P", str(CLOVER_PROCESSES), "--no-tag"]
        
        try:
            print(f"   æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
            subprocess.run(cmd, check=True, env=env)
        except subprocess.CalledProcessError as e:
            print(f"âŒ Clover è¿è¡Œå¤±è´¥: {e}")
            return
    else:
        print(f"\n[Step 2] Clover ç»“æœå·²å°±ç»ªï¼Œè·³è¿‡è¿è¡Œã€‚")

    # === Step 3: å¤–éƒ¨æ’åºæ³•ç”Ÿæˆ FedDNA æ ¼å¼ ===
    print(f"\n[Step 3] è§£æç»“æœå¹¶ç”Ÿæˆ FedDNA è¾“å…¥ (External Sort Mode)...")
    
    # 3.1 åŠ è½½ Cluster Map (å†…å­˜ä¼˜åŒ–)
    print("   [3.1] åŠ è½½èšç±»æ˜ å°„...")
    cluster_map = array.array('i') 
    
    token_gen = stream_clover_results(real_clover_out)
    try:
        while True:
            idx_str = next(token_gen) # æ¶ˆè€—æ‰ç´¢å¼•
            cid_str = next(token_gen) # è·å– Cluster ID
            cluster_map.append(int(cid_str))
    except StopIteration:
        pass
    
    print(f"      æ˜ å°„åŠ è½½å®Œæ¯•ï¼Œå…± {len(cluster_map)} æ¡è®°å½•ã€‚")

    # 3.2 å¤šæ•°æŠ•ç¥¨ç¡®å®š Reference
    print("   [3.2] æ‰«æåŸå§‹æ–‡ä»¶ï¼Œè¿›è¡Œ Reference æŠ•ç¥¨...")
    cluster_votes = defaultdict(lambda: defaultdict(int)) 
    
    with open(src_reads_path, 'r') as f:
        valid_idx = 0
        for line in f:
            parts = line.strip().split()
            if len(parts) < 2: continue
            
            tag = parts[0]
            if valid_idx < len(cluster_map):
                cid = cluster_map[valid_idx]
                if cid != -1:
                    cluster_votes[cid][tag] += 1
            valid_idx += 1
            
            if valid_idx % 1000000 == 0:
                print(f"      å·²æŠ•ç¥¨ {valid_idx} æ¡...", end='\r')

    print("\n      æ­£åœ¨ç»“ç®—æŠ•ç¥¨...")
    ref_dict = load_fasta_references(src_ref_path)
    cluster_ref_seqs = {} 
    
    # ä¿®æ­£é€»è¾‘ï¼šå¦‚æœ ref_dict ä¸ºç©ºï¼ˆæ¯”å¦‚FASTAè§£æå¤±è´¥ï¼‰ï¼Œè¿™é‡Œä¼šæŠ¥è­¦
    if not ref_dict:
        print("âš ï¸ è­¦å‘Šï¼šå‚è€ƒåºåˆ—å­—å…¸ä¸ºç©ºï¼è¯·æ£€æŸ¥ Goldman_fa.fasta æ ¼å¼ã€‚")
        print("   å¦‚æœè¯¥æ–‡ä»¶æ²¡æœ‰ > ç¬¦å·ï¼Œè¯·æ‰‹åŠ¨ä¿®æ”¹è„šæœ¬ä¸­çš„ load_fasta_references å‡½æ•°ã€‚")

    for cid, votes in cluster_votes.items():
        if not votes: continue
        most_common_tag = max(votes, key=votes.get)
        
        # å°è¯•ç›´æ¥åŒ¹é…
        if most_common_tag in ref_dict:
            cluster_ref_seqs[cid] = ref_dict[most_common_tag]
        # å°è¯•å»æ‰å¯èƒ½å­˜åœ¨çš„ > ç¬¦å·å†åŒ¹é…ï¼ˆä»¥é˜²ä¸‡ä¸€ï¼‰
        elif most_common_tag.replace(">", "") in ref_dict:
            cluster_ref_seqs[cid] = ref_dict[most_common_tag.replace(">", "")]
            
    del cluster_votes
    del ref_dict
    gc.collect()
    
    # 3.3 ç”Ÿæˆä¸´æ—¶æ’åºæ–‡ä»¶
    print("   [3.3] ç”Ÿæˆä¸­é—´æ–‡ä»¶ç”¨äºå¤–éƒ¨æ’åº...")
    temp_unsorted = os.path.join(dir_temp, "unsorted_reads.txt")
    temp_sorted = os.path.join(dir_temp, "sorted_reads.txt")
    
    with open(src_reads_path, 'r') as fin, open(temp_unsorted, 'w') as fout:
        valid_idx = 0
        for line in fin:
            parts = line.strip().split()
            if len(parts) < 2: continue
            
            if valid_idx < len(cluster_map):
                cid = cluster_map[valid_idx]
                # åªæœ‰æ‰¾åˆ°äº†å¯¹åº” Reference çš„ç°‡æ‰ä¼šè¢«å†™å…¥
                if cid != -1 and cid in cluster_ref_seqs:
                    seq = parts[-1]
                    fout.write(f"{cid}\t{seq}\n")
            valid_idx += 1
            
            if valid_idx % 1000000 == 0:
                print(f"      å·²é¢„å¤„ç† {valid_idx} æ¡...", end='\r')

    del cluster_map
    gc.collect()

    # 3.4 å¤–éƒ¨æ’åº
    print("\n   [3.4] æ‰§è¡Œå¤–éƒ¨æ’åº (Linux Sort)...")
    # -n æŒ‰æ•°å€¼æ’, -S 50% ä½¿ç”¨50%å†…å­˜
    sort_cmd = f"sort -n -k1,1 -S 50% {temp_unsorted} -o {temp_sorted}"
    subprocess.run(sort_cmd, shell=True, check=True)
    
    os.remove(temp_unsorted)

    # 3.5 è¾“å‡ºæœ€ç»ˆç»“æœ
    print("   [3.5] å†™å…¥æœ€ç»ˆ FedDNA æ ¼å¼...")
    out_read = os.path.join(dir_feddna, "read.txt")
    out_ref = os.path.join(dir_feddna, "ref.txt")
    
    current_cid = None
    
    with open(temp_sorted, 'r') as fin, open(out_read, 'w') as fr, open(out_ref, 'w') as ff:
        for line in fin:
            parts = line.strip().split('\t')
            if len(parts) != 2: continue
            
            cid = int(parts[0])
            seq = parts[1]
            
            if cid != current_cid:
                if current_cid is not None:
                    fr.write("===============================\n")
                
                current_cid = cid
                ref_seq = cluster_ref_seqs[cid]
                ff.write(ref_seq + "\n")
                fr.write(ref_seq + "\n")
            
            fr.write(seq + "\n")
            
        if current_cid is not None:
            fr.write("===============================\n")

    if os.path.exists(temp_sorted):
        os.remove(temp_sorted)

    print("-" * 40)
    print(f"ğŸ‰ Goldman æ•°æ®å¤„ç†å®Œæˆï¼")
    print(f"ğŸ‘‰ ç»“æœä½ç½®: {dir_feddna}")
    print("-" * 40)

if __name__ == "__main__":
    process_goldman_data()