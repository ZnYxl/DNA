import os
import sys
import subprocess
import glob
import shutil
import array
from collections import defaultdict

# ================= é…ç½®åŒºåŸŸ =================
# å®éªŒä¸»ç›®å½•
BASE_EXP_DIR = "/mnt/st_data/liangxinyi/code/CC/Step0/Experiments/exp_1_Final"
# è¾“å…¥æ•°æ® (æ¥è‡ª Step 1 çš„è¾“å‡º)
CLEAN_DATA_DIR = os.path.join(BASE_EXP_DIR, "00_CleanData")
SRC_READS = os.path.join(CLEAN_DATA_DIR, "reads_clean.txt")
SRC_REFS = os.path.join(CLEAN_DATA_DIR, "refs_clean.fasta")

# Clover å‚æ•°
SEQ_LENGTH = 100  # å·²ç»å»è¿‡å¼•ç‰©äº†ï¼Œç°åœ¨æ˜¯ 100
CHUNK_SIZE = 5000000
CLOVER_PROCESSES = 0
# ===========================================

def load_clean_refs(fasta_path):
    print(f"ğŸ“– è¯»å–å‚è€ƒåºåˆ—...")
    refs = {}
    with open(fasta_path, 'r') as f:
        lines = [l.strip() for l in f if l.strip()]
    
    if lines[0].startswith(">"):
        curr = None
        for l in lines:
            if l.startswith(">"): curr = l[1:]
            elif curr: refs[curr] = l
    else:
        for i in range(0, len(lines), 2):
            refs[lines[i]] = lines[i+1]
    return refs

def run_pipeline():
    # ç›®å½•å‡†å¤‡
    dir_chunks = os.path.join(BASE_EXP_DIR, "01_Chunks")
    dir_clover = os.path.join(BASE_EXP_DIR, "02_CloverOut")
    dir_feddna = os.path.join(BASE_EXP_DIR, "03_FedDNA_In")
    dir_temp = os.path.join(BASE_EXP_DIR, "99_Temp")
    
    for d in [dir_chunks, dir_clover, dir_feddna, dir_temp]:
        os.makedirs(d, exist_ok=True)
        
    # === 1. åˆ‡ç‰‡ (Chunking) ===
    print(f"\n[Step 1] åˆ‡ç‰‡ (ç›´æ¥è¯»å–å¹²å‡€æ•°æ®)...")
    if not os.path.exists(SRC_READS):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° {SRC_READS}ï¼Œè¯·å…ˆè¿è¡Œ 01_preprocess_trim.py")
        return

    chunk_idx = 0
    line_count = 0
    current_out = None
    
    # æ£€æŸ¥æ˜¯å¦å·²åˆ‡åˆ†
    existing_chunks = sorted(glob.glob(os.path.join(dir_chunks, "chunk_*.txt")))
    if not existing_chunks:
        with open(SRC_READS, 'r') as fin:
            for line in fin:
                if line_count % CHUNK_SIZE == 0:
                    if current_out: current_out.close()
                    chunk_name = os.path.join(dir_chunks, f"chunk_{chunk_idx:03d}.txt")
                    current_out = open(chunk_name, 'w')
                    print(f"   æ­£åœ¨ç”Ÿæˆ: chunk_{chunk_idx:03d}.txt ...", end='\r')
                    chunk_idx += 1
                
                parts = line.strip().split()
                if len(parts) >= 2:
                    # å†™å…¥æ ¼å¼: è¡Œå· åºåˆ— (å·²ç»æ˜¯å¹²å‡€åºåˆ—äº†)
                    current_out.write(f"{line_count + 1} {parts[-1]}\n")
                line_count += 1
        if current_out: current_out.close()
        print(f"\n   âœ… åˆ‡ç‰‡å®Œæˆã€‚")
        existing_chunks = sorted(glob.glob(os.path.join(dir_chunks, "chunk_*.txt")))
    else:
        print(f"   æ£€æµ‹åˆ°å·²æœ‰åˆ‡ç‰‡ï¼Œè·³è¿‡ã€‚")

    # === 2. è¿è¡Œ Clover ===
    print(f"\n[Step 2] è¿è¡Œ Clover...")
    current_dir = os.path.dirname(os.path.abspath(__file__))
    env = os.environ.copy()
    env["PYTHONPATH"] = os.path.join(current_dir, "Clover") + os.pathsep + env.get("PYTHONPATH", "")
    
    final_clover_result = os.path.join(dir_clover, "clover_result_merged.txt")
    
    # å¦‚æœæ²¡è·‘å®Œæ‰è·‘
    if not os.path.exists(final_clover_result):
        with open(final_clover_result, 'w') as f_merged: pass
        
        for i, chunk_path in enumerate(existing_chunks):
            chunk_name = os.path.basename(chunk_path)
            chunk_out_base = os.path.join(dir_chunks, f"out_{chunk_name}")
            chunk_out_txt = chunk_out_base + ".txt"
            
            print(f"   ğŸš€ [{i+1}/{len(existing_chunks)}] å¤„ç†: {chunk_name}")
            cmd = [sys.executable, "-m", "clover.main", "-I", chunk_path, 
                   "-O", chunk_out_base, "-L", str(SEQ_LENGTH), "-P", str(CLOVER_PROCESSES), "--no-tag"]
            subprocess.run(cmd, check=True, env=env)
            
            with open(chunk_out_txt, 'r') as f_in, open(final_clover_result, 'a') as f_out:
                shutil.copyfileobj(f_in, f_out)
            os.remove(chunk_out_txt)
    else:
        print(f"   æ£€æµ‹åˆ°èšç±»ç»“æœå·²å­˜åœ¨ï¼Œè·³è¿‡ã€‚")

    # === 3. ç”Ÿæˆ FedDNA æ ¼å¼ ===
    print(f"\n[Step 3] ç”Ÿæˆ FedDNA è¾“å…¥...")
    
    # 3.1 åŠ è½½ Clover ç»“æœ
    print("   åŠ è½½èšç±»æ˜ å°„...")
    cluster_map = array.array('i')
    with open(final_clover_result, 'r') as f:
        tokens = f.read().replace('[',' ').replace(']',' ').replace(',',' ').split()
        for i in range(0, len(tokens), 2):
            cluster_map.append(int(tokens[i+1]))
            
    # 3.2 æŠ•ç¥¨ Reference
    print("   æŠ•ç¥¨ Reference...")
    votes = defaultdict(lambda: defaultdict(int))
    with open(SRC_READS, 'r') as f:
        for i, line in enumerate(f):
            if i >= len(cluster_map): break
            cid = cluster_map[i]
            if cid != -1:
                parts = line.strip().split()
                if parts: votes[cid][parts[0]] += 1
    
    # 3.3 ç¡®å®š Ref
    raw_refs = load_clean_refs(SRC_REFS)
    cluster_ref = {}
    for cid, v in votes.items():
        best_tag = max(v, key=v.get)
        if best_tag in raw_refs:
            cluster_ref[cid] = raw_refs[best_tag] # å·²ç»æ˜¯å¹²å‡€çš„äº†

    # 3.4 å†™å…¥æœ€ç»ˆæ–‡ä»¶
    print("   å†™å…¥æœ€ç»ˆæ–‡ä»¶...")
    out_read = os.path.join(dir_feddna, "read.txt")
    out_ref = os.path.join(dir_feddna, "ref.txt")
    
    curr_cid = None
    cluster_cnt = 0
    
    # ç›´æ¥è¯» reads_clean.txt å†™å…¥ï¼Œä¸éœ€è¦å†æ’åº (Cloverè¾“å‡ºæœ¬èº«å°±æ˜¯æŒ‰åºçš„æ˜ å°„ï¼Œä½†å¦‚æœéœ€è¦æŠŠåŒä¸€ä¸ªç°‡çš„æ”¾ä¸€èµ·ï¼Œæœ€å¥½è¿˜æ˜¯æ’ä¸ªåº)
    # ä¸ºäº†ä¿é™©ï¼Œæˆ‘ä»¬è¿˜æ˜¯ç”Ÿæˆä¸´æ—¶æ–‡ä»¶æ’ä¸ªåºï¼Œè™½ç„¶ reads é¡ºåºå’Œ map æ˜¯ä¸€è‡´çš„ï¼Œä½†æˆ‘ä»¬è¦æŠŠåŒä¸€ cluster çš„èšåˆåœ¨ä¸€èµ·
    
    temp_unsorted = os.path.join(dir_temp, "unsorted.txt")
    temp_sorted = os.path.join(dir_temp, "sorted.txt")
    
    with open(SRC_READS, 'r') as fin, open(temp_unsorted, 'w') as fout:
        for i, line in enumerate(fin):
            if i >= len(cluster_map): break
            cid = cluster_map[i]
            if cid != -1 and cid in cluster_ref:
                # å†™å…¥: ClusterID åºåˆ—
                parts = line.strip().split()
                fout.write(f"{cid}\t{parts[-1]}\n")
                
    subprocess.run(f"sort -n -k1,1 -S 50% {temp_unsorted} -o {temp_sorted}", shell=True, check=True)
    os.remove(temp_unsorted)
    
    with open(temp_sorted, 'r') as fin, open(out_read, 'w') as fr, open(out_ref, 'w') as ff:
        for line in fin:
            parts = line.strip().split('\t')
            cid = int(parts[0])
            seq = parts[1]
            
            if cid != curr_cid:
                if curr_cid is not None: fr.write("===============================\n")
                curr_cid = cid
                cluster_cnt += 1
                ref_s = cluster_ref[cid]
                ff.write(ref_s + "\n")
                fr.write(ref_s + "\n")
            fr.write(seq + "\n")
            
        if curr_cid is not None: fr.write("===============================\n")
    
    if os.path.exists(temp_sorted): os.remove(temp_sorted)
    print(f"\nğŸ‰ æµç¨‹ç»“æŸï¼")
    print(f"   æœ‰æ•ˆç°‡æ•°é‡: {cluster_cnt}")
    print(f"   ç»“æœä½ç½®: {dir_feddna}")

if __name__ == "__main__":
    run_pipeline()