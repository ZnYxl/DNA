"""
run_real_data.py
================
å¤„ç†çœŸå® DNA æ•°æ®é›†çš„æµæ°´çº¿ï¼ˆERR036/Fountain, Goldman, ODNAï¼‰ã€‚
ä¿®å¤ç‰ˆ (v2 - ä¸­æ–‡æ—¥å¿—)ï¼š
1. å†…å­˜ä¼˜åŒ–ï¼šå…¨ç¨‹æµå¼å¤„ç† FASTAï¼Œè§£å†³ 8GB+ æ•°æ®é›† OOM é—®é¢˜ã€‚
2. æ ¼å¼ä¿®å¤ï¼šé€‚é… Clover è¾“å‡ºçš„ Python List æ ¼å¼ ([('id','id'),...])ï¼Œä½¿ç”¨ mmap è§£æã€‚
"""

import os
import sys
import subprocess
import collections
import re
import mmap

# ç¡®ä¿èƒ½ import ç”¨æˆ·è‡ªå·±çš„ utils.py
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
try:
    import utils
except ImportError:
    print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ° utils.pyã€‚éƒ¨åˆ†åŠŸèƒ½å¯èƒ½ç¼ºå¤±ã€‚")

# ==============================================================================
# é…ç½®åŒº
# ==============================================================================

DATA_DIR = "/hy-tmp/code/CC/Step0/ç»™å¸ˆå¦¹çš„cloveræ•°æ®é›†"
CLOVER_REPO = os.path.join(os.path.dirname(os.path.abspath(__file__)), "Clover")

DATASETS = {
    "ERR036":  {"fasta": "ERR036_fa.fasta"},
    "Goldman": {"fasta": "Goldman_fa.fasta"},
    "ODNA":    {"fasta": "ODNA_fa.fasta"},
}

CLOVER_PROCESSES = 0  # 0=å•è¿›ç¨‹
USE_LOW_MEMORY = True # å¼€å¯ä½å†…å­˜æ¨¡å¼

# ==============================================================================
# æ ¸å¿ƒå·¥å…·ï¼šæµå¼ FASTA å¤„ç†
# ==============================================================================

def yield_fasta_records(fasta_path):
    """
    ç”Ÿæˆå™¨ï¼šé€æ¡è¯»å– FASTAï¼Œä¸å ç”¨å†…å­˜ã€‚
    yield (header_id, sequence_str)
    """
    with open(fasta_path, 'r', encoding='utf-8', errors='ignore') as f:
        header = None
        seq_parts = []
        for line in f:
            line = line.strip()
            if not line:
                continue
            if line.startswith('>'):
                if header:
                    yield header, "".join(seq_parts).upper()
                # æå– IDï¼šå– > åé¢çš„ç¬¬ä¸€ä¸ªå­—ç¬¦ä¸²
                header = line[1:].split()[0]
                seq_parts = []
            else:
                seq_parts.append(line)
        # æœ€åä¸€æ¡
        if header:
            yield header, "".join(seq_parts).upper()

def analyze_length_distribution_streaming(fasta_path):
    """ç¬¬ä¸€éæ‰«æï¼šç»Ÿè®¡é•¿åº¦åˆ†å¸ƒ"""
    counter = collections.Counter()
    print(f"    æ­£åœ¨æ‰«æé•¿åº¦åˆ†å¸ƒ...")
    for idx, (_, seq) in enumerate(yield_fasta_records(fasta_path)):
        counter[len(seq)] += 1
        if (idx + 1) % 5000000 == 0:
            print(f"      å·²æ‰«æ {idx + 1:,} æ¡åºåˆ—...")
    return counter

def filter_and_write_streaming(fasta_path, output_path, target_length):
    """ç¬¬äºŒéæ‰«æï¼šè¿‡æ»¤å¹¶å†™å…¥ raw_reads.txt"""
    count = 0
    with open(output_path, 'w') as f_out:
        for idx, (rid, seq) in enumerate(yield_fasta_records(fasta_path)):
            if len(seq) == target_length:
                f_out.write(f"{rid}\t{seq}\n")
                count += 1
            if (idx + 1) % 5000000 == 0:
                print(f"      å·²å¤„ç† {idx + 1:,} æ¡åºåˆ—...")
    return count

# ==============================================================================
# æ ¸å¿ƒå·¥å…·ï¼šClover è¿è¡Œä¸è§£æ
# ==============================================================================

def run_clover(raw_reads_path, clover_out_dir, output_basename, seq_length):
    """è¿è¡Œ Clover"""
    env = os.environ.copy()
    env["PYTHONPATH"] = CLOVER_REPO + os.pathsep + env.get("PYTHONPATH", "")
    os.makedirs(clover_out_dir, exist_ok=True)

    cmd = [
        sys.executable, "-m", "clover.main",
        "-I", os.path.abspath(raw_reads_path),
        "-O", output_basename,
        "-L", str(seq_length),
        "-P", str(CLOVER_PROCESSES),
        "--no-tag"
    ]
    if USE_LOW_MEMORY:
        cmd.append("--low")

    print(f"    æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    subprocess.run(cmd, check=True, env=env, cwd=clover_out_dir)

def parse_clover_python_list_format(file_path):
    """
    ä½¿ç”¨ mmap è§£æå·¨å¤§çš„ Python List å­—ç¬¦ä¸²æ–‡ä»¶ã€‚
    æ ¼å¼: [('id1', 'id2'), ('id3', 'id4')...]
    yield (read_id, cluster_id)
    """
    if not os.path.exists(file_path) or os.path.getsize(file_path) == 0:
        return

    # æ­£åˆ™åŒ¹é… ('id1', 'id2') å…è®¸ä¸­é—´æœ‰ç©ºæ ¼
    # Encode pattern to bytes for mmap
    pattern = re.compile(rb"\(\s*'([^']+)'\s*,\s*'([^']+)'\s*\)")

    with open(file_path, 'r+b') as f:
        # ä½¿ç”¨ mmap é¿å…åŠ è½½æ•´ä¸ªæ–‡ä»¶
        with mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ) as mm:
            for match in pattern.finditer(mm):
                # æå– bytes å¹¶è§£ç ä¸º str
                r_id = match.group(1).decode('utf-8')
                c_id = match.group(2).decode('utf-8')
                yield r_id, c_id

def clover_to_feddna_streaming(clover_result_path, raw_reads_path, output_dir):
    """
    æµå¼è½¬æ¢ï¼šæ”¯æŒ Clover çš„ Python List è¾“å‡ºæ ¼å¼
    """
    os.makedirs(output_dir, exist_ok=True)
    
    # 1. æ‰«æ Clover ç»“æœ (cluster -> [reads])
    print(f"    [1/3] è§£æ Clover ç»“æœ (ä½¿ç”¨ mmap)...")
    cluster_members = collections.defaultdict(list)
    count = 0
    
    # è‡ªåŠ¨åˆ¤æ–­æ˜¯ list æ ¼å¼è¿˜æ˜¯ tab æ ¼å¼
    # è¯»å–å‰å‡ ä¸ªå­—èŠ‚åˆ¤æ–­
    is_list_format = False
    with open(clover_result_path, 'r') as f:
        start = f.read(10)
        if start.strip().startswith('['):
            is_list_format = True

    if is_list_format:
        print("      æ£€æµ‹åˆ° Python åˆ—è¡¨æ ¼å¼ (ä¾‹å¦‚ [('id', 'id')...])")
        iterator = parse_clover_python_list_format(clover_result_path)
    else:
        print("      æ£€æµ‹åˆ° TSV æ ¼å¼")
        # ç®€å•çš„ç”Ÿæˆå™¨é€‚é…å™¨
        def tsv_iter():
            with open(clover_result_path, 'r') as f:
                for line in f:
                    parts = line.strip().split('\t')
                    if len(parts) >= 2: yield parts[0], parts[1]
        iterator = tsv_iter()

    for r_id, c_id in iterator:
        cluster_members[c_id].append(r_id)
        count += 1
        if count % 1000000 == 0:
            print(f"      å·²å‘ç° {count:,} å¯¹åŒ¹é…...")

    num_clusters = len(cluster_members)
    print(f"    âœ… å‘ç° {num_clusters:,} ä¸ªç°‡ï¼Œå…±åˆ†é… {count:,} æ¡ readsã€‚")
    
    if num_clusters == 0:
        print("    âš ï¸ è­¦å‘Š: æœªå‘ç°ä»»ä½•ç°‡ï¼è¯·æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ ¼å¼ã€‚")
        return 0, output_dir

    # 2. ç´¢å¼•éœ€è¦çš„ Read åºåˆ—
    print(f"    [2/3] ä» raw_reads ç´¢å¼•åºåˆ—...")
    needed_reads = set()
    for members in cluster_members.values():
        needed_reads.update(members)
    
    read_seqs = {}
    with open(raw_reads_path, 'r') as f:
        for line in f:
            parts = line.strip().split('\t')
            if len(parts) == 2:
                rid, seq = parts
                if rid in needed_reads:
                    read_seqs[rid] = seq
    
    print(f"    âœ… å·²ç´¢å¼• {len(read_seqs):,} æ¡åºåˆ—ã€‚")

    # 3. å†™å…¥ FedDNA
    print(f"    [3/3] å†™å…¥ FedDNA è¾“å…¥æ–‡ä»¶...")
    read_file = os.path.join(output_dir, "read.txt")
    ref_file = os.path.join(output_dir, "ref.txt")
    
    with open(read_file, 'w') as f_read, open(ref_file, 'w') as f_ref:
        for c_id, members in cluster_members.items():
            # è·å–åºåˆ—
            seqs = [read_seqs[rid] for rid in members if rid in read_seqs]
            if not seqs: continue
            
            # å†™å…¥ Reference (Center)
            # æ³¨æ„ï¼šClover çš„ c_id æœ‰æ—¶å°±æ˜¯ center read idï¼Œæœ‰æ—¶æ˜¯è™šæ‹Ÿçš„
            # è¿™é‡Œç®€å•å–ç°‡ä¸­ç¬¬ä¸€æ¡ä½œä¸º refï¼Œæˆ–è€…å¦‚æœä½ ç¡®ä¿¡ c_id æ˜¯ read id ä¸”åœ¨ seqs é‡Œï¼Œå¯ä»¥ç”¨å®ƒ
            center_seq = seqs[0]
            if c_id in read_seqs:
                center_seq = read_seqs[c_id]
            
            f_ref.write(center_seq + "\n")
            for s in seqs:
                f_read.write(s + "\n")
            f_read.write("===============================\n")

    return num_clusters, output_dir

# ==============================================================================
# ä¸»é€»è¾‘
# ==============================================================================

def process_dataset(dataset_name, fasta_filename, output_base_dir):
    print(f"\n{'='*60}\n  æ•°æ®é›†: {dataset_name}\n{'='*60}")
    
    fasta_path = os.path.join(DATA_DIR, fasta_filename)
    if not os.path.exists(fasta_path):
        print(f"  âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {fasta_path}")
        return None

    base_dir = os.path.join(output_base_dir, dataset_name)
    dir_raw = os.path.join(base_dir, "01_RawData")
    dir_clover = os.path.join(base_dir, "02_CloverOut")
    dir_feddna = os.path.join(base_dir, "03_FedDNA_In")
    for d in [dir_raw, dir_clover, dir_feddna]:
        os.makedirs(d, exist_ok=True)

    # Step 1 & 2: æµå¼ç»Ÿè®¡é•¿åº¦ä¸è¿‡æ»¤
    # ---------------------------
    raw_reads_path = os.path.join(dir_raw, "raw_reads.txt")
    
    # åªæœ‰å½“ raw_reads.txt ä¸å­˜åœ¨æˆ–æƒ³è¦é‡æ–°è·‘æ—¶æ‰æ‰§è¡Œ
    if not os.path.exists(raw_reads_path) or os.path.getsize(raw_reads_path) == 0:
        print("  [æ­¥éª¤ 1-2] åˆ†æä¸è¿‡æ»¤ (æµå¼)...")
        length_dist = analyze_length_distribution_streaming(fasta_path)
        if not length_dist:
            print("  âŒ æœªå‘ç° readsã€‚")
            return None
            
        modal_length, count = length_dist.most_common(1)[0]
        print(f"    ä¼—æ•°é•¿åº¦ (Modal Length): {modal_length} bp (æ•°é‡: {count})")
        
        kept_count = filter_and_write_streaming(fasta_path, raw_reads_path, modal_length)
        print(f"  âœ… å·²å†™å…¥ {kept_count} æ¡ reads åˆ° {raw_reads_path}")
    else:
        print(f"  æç¤º: raw_reads.txt å·²å­˜åœ¨ï¼Œè·³è¿‡è¿‡æ»¤æ­¥éª¤ã€‚")
        # ç®€å•è¯»å–ç¬¬ä¸€è¡Œè·å–é•¿åº¦ï¼ˆå‡è®¾ä¸€è‡´ï¼‰
        with open(raw_reads_path) as f:
            line = f.readline()
            if line:
                modal_length = len(line.split('\t')[1].strip())
            else:
                modal_length = 0 # å¼‚å¸¸å¤„ç†
        kept_count = "æœªçŸ¥ (å·²ç¼“å­˜)"

    # Step 3: è¿è¡Œ Clover
    # ---------------------------
    print(f"  [æ­¥éª¤ 3] è¿è¡Œ Clover (L={modal_length})...")
    output_basename = "clover_result"
    
    # æ£€æŸ¥ç»“æœæ–‡ä»¶ä½ç½®
    if USE_LOW_MEMORY:
        clover_result_file = os.path.join(dir_clover, "all_" + output_basename + ".txt")
    else:
        clover_result_file = os.path.join(dir_clover, output_basename + ".txt")
    
    if not os.path.exists(clover_result_file) or os.path.getsize(clover_result_file) == 0:
        try:
            run_clover(raw_reads_path, dir_clover, output_basename, modal_length)
        except subprocess.CalledProcessError as e:
            print(f"  âŒ Clover è¿è¡Œå¤±è´¥: {e}")
            return None
    else:
        print(f"  âœ… Clover è¾“å‡ºå·²å­˜åœ¨: {clover_result_file}")

    # Step 4: è½¬æ¢ FedDNA (ä¿®å¤æ ¼å¼è§£æ)
    # ---------------------------
    print(f"  [æ­¥éª¤ 4] è½¬æ¢ä¸º FedDNA æ ¼å¼...")
    clusters, _ = clover_to_feddna_streaming(clover_result_file, raw_reads_path, dir_feddna)
    
    return {"dataset": dataset_name, "clusters": clusters}

def run():
    output_base = os.path.join(os.path.dirname(os.path.abspath(__file__)), "Experiments")
    print("ğŸš€ æµæ°´çº¿å¼€å§‹æ‰§è¡Œ")
    
    for name, cfg in DATASETS.items():
        process_dataset(name, cfg["fasta"], output_base)

if __name__ == "__main__":
    run()