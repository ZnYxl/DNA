import os
import sys
import subprocess
import glob
import shutil
import array
from collections import defaultdict

# ================= å®éªŒé…ç½® =================
DATASET_NAME = "exp_1"
# æ³¨æ„ï¼šè¿™é‡Œä¿®æ”¹ä¸ºä½  exp_1 çš„å®é™…è·¯å¾„
SOURCE_DIR = "/mnt/st_data/liangxinyi/code/CC/Step0/ç»™å¸ˆå¦¹çš„cloveræ•°æ®é›†/exp_1"

# === å…³é”®ï¼šå»å¼•ç‰©é…ç½® ===
# æ ¹æ® Reference é•¿åº¦(150) - Fwd(25) - Rev(25) â‰ˆ 100bp
CLOVER_SEQ_LENGTH = 100 

# é”šç‚¹ï¼šForward Primer çš„ååŠæ®µ (ç”¨äºå®šä½ Payload èµ·å§‹)
# åŸ Fwd: TCCTGTGCTGCCTGTAATGAGCCAA
ANCHOR_FWD = "GTAATGAGCCAA" 

# å—å¤§å° (æ•°æ®é‡ä¸å¤§å…¶å®å¯ä»¥ä¸€æ¬¡è·‘ï¼Œä½†åˆ†å—æ›´ç¨³)
CHUNK_SIZE = 5000000 
CLOVER_PROCESSES = 0 

# ===========================================

def load_fasta_references(fasta_path):
    print(f"ğŸ“– [Ref] è¯»å–å‚è€ƒåºåˆ—: {os.path.basename(fasta_path)} ...")
    refs = {}
    with open(fasta_path, 'r') as f:
        lines = [l.strip() for l in f if l.strip()]
    
    if lines[0].startswith(">"):
        current_tag = None
        for line in lines:
            if line.startswith(">"):
                current_tag = line[1:]
            elif current_tag:
                refs[current_tag] = line
    else:
        print("   â„¹ï¸ æ£€æµ‹åˆ°æ—  '>' æ ¼å¼ï¼Œå¯ç”¨åŒè¡Œè¯»å–æ¨¡å¼...")
        for i in range(0, len(lines), 2):
            if i + 1 < len(lines):
                tag = lines[i]
                seq = lines[i+1]
                refs[tag] = seq
                
    print(f"   âœ… åŠ è½½äº† {len(refs)} æ¡å‚è€ƒåºåˆ— (Ground Truth)")
    return refs

def extract_payload(sequence):
    """
    é’ˆå¯¹ exp_1 çš„å»å¼•ç‰©é€»è¾‘ï¼š
    å¯»æ‰¾é”šç‚¹ "GTAATGAGCCAA"ï¼Œæˆªå–å…¶åçš„ 100bp
    """
    pos = sequence.find(ANCHOR_FWD)
    if pos != -1:
        # æ‰¾åˆ°äº†é”šç‚¹ï¼ŒPayload ä»é”šç‚¹ç»“æŸå¤„å¼€å§‹
        start = pos + len(ANCHOR_FWD)
        payload = sequence[start : start + CLOVER_SEQ_LENGTH]
    else:
        # æ²¡æ‰¾åˆ°é”šç‚¹ (å¯èƒ½å¤´éƒ¨çªå˜ä¸¥é‡)ï¼Œå°è¯•ç›´æ¥å–ä¸­é—´æ®µ
        # å‡è®¾å¼•ç‰©çº¦ 25bpï¼Œç›´æ¥è·³è¿‡å‰ 25bp (è¿™æ˜¯ä¸€ç§å¤‡é€‰ç­–ç•¥)
        # æˆ–è€…ç›´æ¥è¿”å›ç©ºï¼Œè§†ä½œåƒåœ¾æ•°æ®ã€‚è¿™é‡Œæˆ‘ä»¬å°è¯•å®¹é”™ï¼š
        # å¦‚æœé•¿åº¦å¤Ÿï¼Œç¡¬åˆ‡ï¼›ä¸å¤Ÿè¡¥N
        if len(sequence) > 25:
             payload = sequence[25 : 25 + CLOVER_SEQ_LENGTH]
        else:
             payload = sequence # æçŸ­ï¼Œéšå®ƒå»å§

    # é•¿åº¦å¼ºè¡Œå¯¹é½
    if len(payload) < CLOVER_SEQ_LENGTH:
        payload = payload.ljust(CLOVER_SEQ_LENGTH, 'N')
    elif len(payload) > CLOVER_SEQ_LENGTH:
        payload = payload[:CLOVER_SEQ_LENGTH]
        
    return payload

def process_exp1_fixed():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    # æ³¨æ„ï¼šè¾“å‡ºç›®å½•æ”¹ä¸ºäº† exp_1_Real
    exp_dir = os.path.join(current_dir, "Experiments", f"{DATASET_NAME}_Real")
    
    dir_raw = os.path.join(exp_dir, "01_FormattedInput")
    dir_clover = os.path.join(exp_dir, "02_CloverOut")
    dir_feddna = os.path.join(exp_dir, "03_FedDNA_In")
    dir_temp = os.path.join(exp_dir, "99_Temp")
    dir_chunks = os.path.join(exp_dir, "00_Chunks")
    
    # æ¸…ç†æ—§åˆ‡ç‰‡
    if os.path.exists(dir_chunks): shutil.rmtree(dir_chunks)
    
    for d in [dir_raw, dir_clover, dir_feddna, dir_temp, dir_chunks]:
        os.makedirs(d, exist_ok=True)

    src_reads_path = os.path.join(SOURCE_DIR, "exp1_tags_reads.txt")
    src_ref_path = os.path.join(SOURCE_DIR, "exp1_refs.fasta")
    
    # === Step 1: åˆ‡ç‰‡å¹¶å»å¼•ç‰© ===
    print(f"\n[Step 1] åˆ‡ç‰‡å¹¶æå– Payload (å»é™¤å¼•ç‰©)...")
    if not os.path.exists(src_reads_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æºæ–‡ä»¶ {src_reads_path}")
        return

    chunk_idx = 0
    line_count = 0
    current_out = None
    
    with open(src_reads_path, 'r') as fin:
        for line in fin:
            if line_count % CHUNK_SIZE == 0:
                if current_out: current_out.close()
                chunk_name = os.path.join(dir_chunks, f"chunk_{chunk_idx:03d}.txt")
                current_out = open(chunk_name, 'w')
                print(f"   æ­£åœ¨ç”Ÿæˆåˆ‡ç‰‡: chunk_{chunk_idx:03d}.txt ...", end='\r')
                chunk_idx += 1
            
            parts = line.strip().split()
            if len(parts) >= 2:
                raw_seq = parts[-1]
                # === æå– Payload ===
                clean_seq = extract_payload(raw_seq)
                # =================
                global_line_idx = line_count + 1
                current_out.write(f"{global_line_idx} {clean_seq}\n")
            
            line_count += 1
            
    if current_out: current_out.close()
    print(f"\n   âœ… åˆ‡ç‰‡å®Œæˆã€‚å…± {line_count} æ¡ readsã€‚")
    existing_chunks = sorted(glob.glob(os.path.join(dir_chunks, "chunk_*.txt")))

    # === Step 2: é€å—è¿è¡Œ Clover ===
    print(f"\n[Step 2] è¿è¡Œ Clover (L={CLOVER_SEQ_LENGTH})...")
    env = os.environ.copy()
    env["PYTHONPATH"] = os.path.join(current_dir, "Clover") + os.pathsep + env.get("PYTHONPATH", "")
    
    final_clover_result = os.path.join(dir_clover, "clover_result_merged.txt")
    if os.path.exists(final_clover_result): os.remove(final_clover_result)
        
    with open(final_clover_result, 'w') as f_merged: pass 
        
    for i, chunk_path in enumerate(existing_chunks):
        chunk_name = os.path.basename(chunk_path)
        chunk_out_base = os.path.join(dir_chunks, f"out_{chunk_name}")
        chunk_out_txt = chunk_out_base + ".txt"
        
        print(f"   ğŸš€ [{i+1}/{len(existing_chunks)}] å¤„ç†åˆ‡ç‰‡: {chunk_name}")
        cmd = [sys.executable, "-m", "clover.main", "-I", chunk_path, 
               "-O", chunk_out_base, "-L", str(CLOVER_SEQ_LENGTH), "-P", str(CLOVER_PROCESSES), "--no-tag"]
        try:
            subprocess.run(cmd, check=True, env=env) 
        except subprocess.CalledProcessError as e:
            print(f"\nâŒ åˆ‡ç‰‡å¤±è´¥! Exit Code: {e.returncode}")
            return
        
        with open(chunk_out_txt, 'r') as f_in, open(final_clover_result, 'a') as f_out:
            shutil.copyfileobj(f_in, f_out)
        os.remove(chunk_out_txt)
        
    print(f"   âœ… Clover èšç±»å®Œæˆã€‚")

    # === Step 3: åˆå¹¶ä¸æ’åº ===
    print(f"\n[Step 3] ç”Ÿæˆ FedDNA è¾“å…¥...")
    
    cluster_map = array.array('i') 
    def stream_tokens(path):
        with open(path, 'r') as f:
            buf = ""
            while True:
                chunk = f.read(1024*1024)
                if not chunk: break
                cleaned = chunk.replace('[', ' ').replace(']', ' ').replace('(', ' ').replace(')', ' ').replace(',', ' ').replace("'", " ").replace('"', " ")
                buf += cleaned
                tokens = buf.split()
                if chunk[-1].isspace() or chunk[-1] in "[](),'\"":
                    for t in tokens: yield t
                    buf = ""
                else:
                    if tokens:
                        for t in tokens[:-1]: yield t
                        buf = tokens[-1]
                    else: pass
            if buf.strip(): yield buf.strip()

    print("   [3.1] åŠ è½½èšç±»æ˜ å°„...")
    token_gen = stream_tokens(final_clover_result)
    try:
        while True:
            idx_str = next(token_gen)
            cid_str = next(token_gen)
            cluster_map.append(int(cid_str))
    except StopIteration: pass

    print("   [3.2] æŠ•ç¥¨ Reference...")
    cluster_votes = defaultdict(lambda: defaultdict(int)) 
    with open(src_reads_path, 'r') as f:
        valid_idx = 0
        for line in f:
            parts = line.strip().split()
            if len(parts) < 2: continue
            tag_in_read = parts[0]
            if valid_idx < len(cluster_map):
                cid = cluster_map[valid_idx]
                if cid != -1: cluster_votes[cid][tag_in_read] += 1
            valid_idx += 1
            if valid_idx % 1000000 == 0: print(f"      å·²æŠ•ç¥¨ {valid_idx} æ¡...", end='\r')

    print("\n      ç»“ç®—æŠ•ç¥¨...")
    ref_dict = load_fasta_references(src_ref_path)
    cluster_ref_seqs = {} 
    
    matched_count = 0
    for cid, votes in cluster_votes.items():
        if not votes: continue
        best_tag = max(votes, key=votes.get)
        if best_tag in ref_dict: 
            cluster_ref_seqs[cid] = ref_dict[best_tag]
            matched_count += 1
            
    print(f"      æˆåŠŸåŒ¹é… Reference: {matched_count}")

    del cluster_votes, ref_dict
    
    print("   [3.3] ç”Ÿæˆæ’åºä¸­é—´æ–‡ä»¶...")
    temp_unsorted = os.path.join(dir_temp, "unsorted_reads.txt")
    temp_sorted = os.path.join(dir_temp, "sorted_reads.txt")
    
    with open(src_reads_path, 'r') as fin, open(temp_unsorted, 'w') as fout:
        valid_idx = 0
        for line in fin:
            parts = line.strip().split()
            if len(parts) < 2: continue
            if valid_idx < len(cluster_map):
                cid = cluster_map[valid_idx]
                if cid != -1 and cid in cluster_ref_seqs:
                    fout.write(f"{cid}\t{parts[-1]}\n")
            valid_idx += 1
            if valid_idx % 1000000 == 0: print(f"      å·²é¢„å¤„ç† {valid_idx} æ¡...", end='\r')
    
    del cluster_map
    print("\n   [3.4] å¤–éƒ¨æ’åº...")
    subprocess.run(f"sort -n -k1,1 -S 50% {temp_unsorted} -o {temp_sorted}", shell=True, check=True)
    os.remove(temp_unsorted)

    print("   [3.5] å†™å…¥æœ€ç»ˆæ–‡ä»¶...")
    out_read = os.path.join(dir_feddna, "read.txt")
    out_ref = os.path.join(dir_feddna, "ref.txt")
    
    current_cid = None
    cluster_count = 0
    with open(temp_sorted, 'r') as fin, open(out_read, 'w') as fr, open(out_ref, 'w') as ff:
        for line in fin:
            parts = line.strip().split('\t')
            if len(parts) != 2: continue
            cid = int(parts[0])
            seq = parts[1]
            if cid != current_cid:
                if current_cid is not None: fr.write("===============================\n")
                current_cid = cid
                cluster_count += 1
                ref_seq = cluster_ref_seqs[cid]
                ff.write(ref_seq + "\n")
                fr.write(ref_seq + "\n")
            fr.write(seq + "\n")
        if current_cid is not None: fr.write("===============================\n")
    
    if os.path.exists(temp_sorted): os.remove(temp_sorted)
    print(f"\nğŸ‰ exp_1 å¤„ç†å®Œæ¯•ï¼")
    print(f"ğŸ“Š æœ€ç»ˆæœ‰æ•ˆç°‡: {cluster_count}")

if __name__ == "__main__":
    process_exp1_fixed()