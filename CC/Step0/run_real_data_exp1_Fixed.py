import os
import sys
import subprocess
import glob
import shutil
import re
from collections import defaultdict

# ================= å®éªŒé…ç½® =================
DATASET_NAME = "exp_1"
SOURCE_DIR = "/mnt/st_data/liangxinyi/code/CC/Step0/ç»™å¸ˆå¦¹çš„cloveræ•°æ®é›†/exp_1"

# === å»å¼•ç‰©é…ç½® ===
CLOVER_SEQ_LENGTH = 100
ANCHOR_FWD = "GTAATGAGCCAA"

CHUNK_SIZE = 5000000
CLOVER_PROCESSES = 0

# ===========================================


def load_fasta_references(fasta_path):
    print(f"ğŸ“– [Ref] è¯»å–å‚è€ƒåºåˆ—: {os.path.basename(fasta_path)} ...")
    refs = {}
    with open(fasta_path, 'r') as f:
        lines = [l.strip() for l in f if l.strip()]

    if lines[0].startswith(">"):
        current_tag = None
        for line in lines:
            if line.startswith(">"):
                current_tag = line[1:]
            elif current_tag:
                refs[current_tag] = line
    else:
        print("   â„¹ï¸ æ£€æµ‹åˆ°æ—  '>' æ ¼å¼ï¼Œå¯ç”¨åŒè¡Œè¯»å–æ¨¡å¼...")
        for i in range(0, len(lines), 2):
            if i + 1 < len(lines):
                tag = lines[i]
                seq = lines[i + 1]
                refs[tag] = seq

    print(f"   âœ… åŠ è½½äº† {len(refs)} æ¡å‚è€ƒåºåˆ— (Ground Truth)")
    return refs


def extract_payload(sequence):
    """
    é’ˆå¯¹ exp_1 çš„å»å¼•ç‰©é€»è¾‘:
    å¯»æ‰¾é”šç‚¹ "GTAATGAGCCAA"ï¼Œæˆªå–å…¶åçš„ 100bp
    """
    pos = sequence.find(ANCHOR_FWD)
    if pos != -1:
        start = pos + len(ANCHOR_FWD)
        payload = sequence[start: start + CLOVER_SEQ_LENGTH]
    else:
        if len(sequence) > 25:
            payload = sequence[25: 25 + CLOVER_SEQ_LENGTH]
        else:
            payload = sequence

    if len(payload) < CLOVER_SEQ_LENGTH:
        payload = payload.ljust(CLOVER_SEQ_LENGTH, 'N')
    elif len(payload) > CLOVER_SEQ_LENGTH:
        payload = payload[:CLOVER_SEQ_LENGTH]

    return payload


def process_exp1_fixed():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    exp_dir = os.path.join(current_dir, "Experiments", f"{DATASET_NAME}_Real_last")

    dir_raw = os.path.join(exp_dir, "01_FormattedInput")
    dir_clover = os.path.join(exp_dir, "02_CloverOut")
    dir_feddna = os.path.join(exp_dir, "03_FedDNA_In")
    dir_temp = os.path.join(exp_dir, "99_Temp")
    dir_chunks = os.path.join(exp_dir, "00_Chunks")

    if os.path.exists(dir_chunks):
        shutil.rmtree(dir_chunks)

    for d in [dir_raw, dir_clover, dir_feddna, dir_temp, dir_chunks]:
        os.makedirs(d, exist_ok=True)

    src_reads_path = os.path.join(SOURCE_DIR, "exp1_tags_reads.txt")
    src_ref_path = os.path.join(SOURCE_DIR, "exp1_refs.fasta")

    # === Step 1: åˆ‡ç‰‡å¹¶å»å¼•ç‰© (ç»™ Clover ç”¨) ===
    print(f"\n[Step 1] åˆ‡ç‰‡å¹¶æå– Payload (å»é™¤å¼•ç‰©)...")
    if not os.path.exists(src_reads_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æºæ–‡ä»¶ {src_reads_path}")
        return

    chunk_idx = 0
    line_count = 0
    current_out = None

    with open(src_reads_path, 'r') as fin:
        for line in fin:
            if line_count % CHUNK_SIZE == 0:
                if current_out:
                    current_out.close()
                chunk_name = os.path.join(dir_chunks, f"chunk_{chunk_idx:03d}.txt")
                current_out = open(chunk_name, 'w')
                print(f"   æ­£åœ¨ç”Ÿæˆåˆ‡ç‰‡: chunk_{chunk_idx:03d}.txt ...", end='\r')
                chunk_idx += 1

            parts = line.strip().split()
            if len(parts) >= 2:
                raw_seq = parts[-1]
                clean_seq = extract_payload(raw_seq)
                global_line_idx = line_count + 1
                current_out.write(f"{global_line_idx} {clean_seq}\n")

            line_count += 1

    if current_out:
        current_out.close()
    print(f"\n   âœ… åˆ‡ç‰‡å®Œæˆã€‚å…± {line_count} æ¡ readsã€‚")
    existing_chunks = sorted(glob.glob(os.path.join(dir_chunks, "chunk_*.txt")))

    # === Step 2: é€å—è¿è¡Œ Clover ===
    print(f"\n[Step 2] è¿è¡Œ Clover (L={CLOVER_SEQ_LENGTH})...")
    env = os.environ.copy()
    env["PYTHONPATH"] = os.path.join(current_dir, "Clover") + os.pathsep + env.get("PYTHONPATH", "")

    final_clover_result = os.path.join(dir_clover, "clover_result_merged.txt")
    if os.path.exists(final_clover_result):
        os.remove(final_clover_result)
    with open(final_clover_result, 'w') as f_merged:
        pass

    for i, chunk_path in enumerate(existing_chunks):
        chunk_name = os.path.basename(chunk_path)
        chunk_out_base = os.path.join(dir_chunks, f"out_{chunk_name}")
        chunk_out_txt = chunk_out_base + ".txt"

        print(f"   ğŸš€ [{i + 1}/{len(existing_chunks)}] å¤„ç†åˆ‡ç‰‡: {chunk_name}")
        cmd = [sys.executable, "-m", "clover.main", "-I", chunk_path,
               "-O", chunk_out_base, "-L", str(CLOVER_SEQ_LENGTH), "-P", str(CLOVER_PROCESSES), "--no-tag"]
        try:
            subprocess.run(cmd, check=True, env=env)
        except subprocess.CalledProcessError as e:
            print(f"\nâŒ åˆ‡ç‰‡å¤±è´¥! Exit Code: {e.returncode}")
            return

        with open(chunk_out_txt, 'r') as f_in, open(final_clover_result, 'a') as f_out:
            shutil.copyfileobj(f_in, f_out)
        os.remove(chunk_out_txt)

    print(f"   âœ… Clover èšç±»å®Œæˆã€‚")

    # =========================================================================
    # === Step 3: è§£æ Clover è¾“å‡º (å…³é”®ä¿®å¤: ç”¨ idx åšæ­£ç¡®æ˜ å°„) ===
    # =========================================================================
    print(f"\n[Step 3] è§£æ Clover è¾“å‡º (ä¿®å¤ç‰ˆ: æŒ‰ idx æ˜ å°„)...")

    # â”€â”€â”€ 3.1 è§£æ Clover tuple è¾“å‡º â†’ idxâ†’cid å­—å…¸ â”€â”€â”€
    print("   [3.1] è§£æ Clover (idx, cid) å¯¹...")
    with open(final_clover_result, 'r') as f:
        content = f.read()

    # åŒ¹é… ('idx', 'cid') æˆ– (idx, cid) æ ¼å¼
    pairs = re.findall(r"\('?(\d+)'?,\s*'?(\d+)'?\)", content)
    print(f"         Clover éå™ªå£°è¾“å‡º: {len(pairs)} æ¡")

    # â”€â”€â”€ å…³é”®ä¿®å¤ â”€â”€â”€
    # Clover çš„ idx æ˜¯åŸºäº chunk è¾“å…¥çš„è¡Œå· (1-based)
    # æˆ‘ä»¬çš„ chunk å†™å…¥æ—¶ç”¨äº† global_line_idx = line_count + 1 (1-based)
    # æ‰€ä»¥ idx å°±æ˜¯åŸå§‹ reads çš„ 1-based è¡Œå·
    idx_to_cid = {}
    for idx_str, cid_str in pairs:
        idx_to_cid[int(idx_str)] = int(cid_str)

    del content, pairs  # é‡Šæ”¾å†…å­˜

    total_reads = line_count
    noise_count = total_reads - len(idx_to_cid)
    print(f"         æ€» reads: {total_reads}")
    print(f"         æœ‰æ ‡ç­¾:  {len(idx_to_cid)}")
    print(f"         å™ªå£°:    {noise_count} ({noise_count / total_reads * 100:.1f}%)")

    # â”€â”€â”€ 3.2 æŠ•ç¥¨ Reference â”€â”€â”€
    print("   [3.2] æŠ•ç¥¨ Reference...")
    cluster_votes = defaultdict(lambda: defaultdict(int))
    with open(src_reads_path, 'r') as f:
        for line_idx_0based, line in enumerate(f):
            parts = line.strip().split()
            if len(parts) < 2:
                continue
            tag_in_read = parts[0]
            line_idx_1based = line_idx_0based + 1

            if line_idx_1based in idx_to_cid:
                cid = idx_to_cid[line_idx_1based]
                cluster_votes[cid][tag_in_read] += 1

            if (line_idx_0based + 1) % 1000000 == 0:
                print(f"      å·²æŠ•ç¥¨ {line_idx_0based + 1} æ¡...", end='\r')

    print(f"\n      ç»“ç®—æŠ•ç¥¨...")
    ref_dict = load_fasta_references(src_ref_path)
    cluster_ref_seqs = {}

    matched_count = 0
    for cid, votes in cluster_votes.items():
        if not votes:
            continue
        best_tag = max(votes, key=votes.get)
        if best_tag in ref_dict:
            cluster_ref_seqs[cid] = ref_dict[best_tag]
            matched_count += 1

    print(f"      æˆåŠŸåŒ¹é… Reference: {matched_count}")
    del cluster_votes, ref_dict

    # â”€â”€â”€ 3.3 ç”Ÿæˆæ’åºä¸­é—´æ–‡ä»¶ (åŸå§‹ reads, å«å¼•ç‰©) â”€â”€â”€
    print("   [3.3] ç”Ÿæˆæ’åºä¸­é—´æ–‡ä»¶...")
    temp_unsorted = os.path.join(dir_temp, "unsorted_reads.txt")
    temp_sorted = os.path.join(dir_temp, "sorted_reads.txt")

    with open(src_reads_path, 'r') as fin, open(temp_unsorted, 'w') as fout:
        for line_idx_0based, line in enumerate(fin):
            parts = line.strip().split()
            if len(parts) < 2:
                continue
            line_idx_1based = line_idx_0based + 1

            if line_idx_1based in idx_to_cid:
                cid = idx_to_cid[line_idx_1based]
                if cid in cluster_ref_seqs:
                    # å†™å…¥åŸå§‹ read (å«å¼•ç‰©), ä¸æ˜¯å»å¼•ç‰©åçš„ payload
                    fout.write(f"{cid}\t{parts[-1]}\n")

            if (line_idx_0based + 1) % 1000000 == 0:
                print(f"      å·²é¢„å¤„ç† {line_idx_0based + 1} æ¡...", end='\r')

    del idx_to_cid

    print("\n   [3.4] å¤–éƒ¨æ’åº...")
    subprocess.run(f"sort -n -k1,1 -S 50% {temp_unsorted} -o {temp_sorted}",
                   shell=True, check=True)
    os.remove(temp_unsorted)

    print("   [3.5] å†™å…¥æœ€ç»ˆæ–‡ä»¶...")
    out_read = os.path.join(dir_feddna, "read.txt")
    out_ref = os.path.join(dir_feddna, "ref.txt")

    current_cid = None
    cluster_count = 0
    read_count = 0
    with open(temp_sorted, 'r') as fin, \
            open(out_read, 'w') as fr, \
            open(out_ref, 'w') as ff:
        for line in fin:
            parts = line.strip().split('\t')
            if len(parts) != 2:
                continue
            cid = int(parts[0])
            seq = parts[1]
            if cid != current_cid:
                if current_cid is not None:
                    fr.write("===============================\n")
                current_cid = cid
                cluster_count += 1
                ref_seq = cluster_ref_seqs[cid]
                ff.write(ref_seq + "\n")
                fr.write(ref_seq + "\n")
            fr.write(seq + "\n")
            read_count += 1
        if current_cid is not None:
            fr.write("===============================\n")

    if os.path.exists(temp_sorted):
        os.remove(temp_sorted)

    print(f"\nğŸ‰ exp_1 å¤„ç†å®Œæ¯•ï¼")
    print(f"ğŸ“Š æœ€ç»ˆæœ‰æ•ˆç°‡: {cluster_count}")
    print(f"ğŸ“Š æœ€ç»ˆæœ‰æ•ˆ reads: {read_count}")


if __name__ == "__main__":
    process_exp1_fixed()