"""
fix_id20_step3.py  â€”  ä»…é‡è·‘ Step 3 (è§£æ Clover è¾“å‡º â†’ ç”Ÿæˆ FedDNA_In)

ä¿®å¤:
  1. idx æ˜ å°„: ç”¨ Clover tuple çš„ idx åšå­—å…¸æ˜ å°„ (éé¡ºåºå¡«å……)
  2. reads è£å‰ª: 177bp â†’ ~150bp (å» Illumina adapter, ä¿ç•™å¼•ç‰©, ä¸ ref ä¸€è‡´)

ç”¨æ³•:
  cd /mnt/st_data/liangxinyi/code/CC/Step0
  python fix_id20_step3.py
"""
import os
import re
import subprocess
import shutil
from collections import defaultdict

# ================= é…ç½® =================
SOURCE_DIR = "/mnt/st_data/liangxinyi/code/CC/Step0/ç»™å¸ˆå¦¹çš„cloveræ•°æ®é›†/id20"
EXP_DIR = "/mnt/st_data/liangxinyi/code/CC/Step0/Experiments/id20_Real"

CLOVER_RESULT = os.path.join(EXP_DIR, "02_CloverOut", "clover_result_merged.txt")
SRC_READS = os.path.join(SOURCE_DIR, "id20_tags_reads.txt")
SRC_REFS = os.path.join(SOURCE_DIR, "id20_refs.fasta")

FEDDNA_DIR = os.path.join(EXP_DIR, "03_FedDNA_In")
TEMP_DIR = os.path.join(EXP_DIR, "99_Temp")

# id20 å¼•ç‰©ç‰¹å¾
FWD_PRIMER = "AGTGCAACAAGTCAATCCGT"    # 20bp
REV_PRIMER = "AATTGAATGCTTGCTTGCCG"    # 20bp
# é”šç‚¹: forward primer å°¾éƒ¨ (æ›´çŸ­æ›´çµæ´»)
ANCHOR_FWD = "TCAATCCGT"
# ref é•¿åº¦
REF_LEN = 150
# ========================================


def extract_model_input(sequence):
    """
    ä» 177bp read ä¸­æå– ~150bp ç»™æ¨¡å‹:
    æ–¹æ¡ˆ: æ‰¾åˆ° forward primer é”šç‚¹, å–é”šç‚¹å‰20bpä½ç½®å¼€å§‹çš„ 150bp
    è¿™æ ·ä¿ç•™ [fwd_primer + payload + rev_primer], ä¸¢å¼ƒ Illumina adapter
    """
    pos = sequence.find(ANCHOR_FWD)
    if pos != -1:
        # é”šç‚¹åœ¨ forward primer å†…, æ‰¾åˆ° primer å¼€å¤´
        # ANCHOR_FWD æ˜¯ primer çš„å°¾éƒ¨, primer å®Œæ•´æ˜¯ 20bp
        # æ‰€ä»¥ primer èµ·å§‹ = pos - (20 - len(ANCHOR_FWD))
        primer_start = max(0, pos - (len(FWD_PRIMER) - len(ANCHOR_FWD)))
        extracted = sequence[primer_start: primer_start + REF_LEN]
    else:
        # æ‰¾ä¸åˆ°é”šç‚¹, ç›´æ¥å–å‰ 150bp
        extracted = sequence[:REF_LEN]

    # é•¿åº¦å¯¹é½
    if len(extracted) < REF_LEN:
        extracted = extracted.ljust(REF_LEN, 'N')
    elif len(extracted) > REF_LEN:
        extracted = extracted[:REF_LEN]

    return extracted


def load_fasta_references(fasta_path):
    print(f"ğŸ“– è¯»å–å‚è€ƒåºåˆ—: {os.path.basename(fasta_path)} ...")
    refs = {}
    with open(fasta_path, 'r') as f:
        lines = [l.strip() for l in f if l.strip()]

    if lines[0].startswith(">"):
        current_tag = None
        for line in lines:
            if line.startswith(">"):
                current_tag = line[1:]
            elif current_tag:
                refs[current_tag] = line
    else:
        for i in range(0, len(lines), 2):
            if i + 1 < len(lines):
                refs[lines[i]] = lines[i + 1]

    print(f"   âœ… {len(refs)} æ¡å‚è€ƒåºåˆ—")
    return refs


def main():
    os.makedirs(FEDDNA_DIR, exist_ok=True)
    os.makedirs(TEMP_DIR, exist_ok=True)

    # =========================================================================
    # Step 3.1: è§£æ Clover (idx, cid) â†’ å­—å…¸æ˜ å°„
    # =========================================================================
    print("\n[3.1] è§£æ Clover (idx, cid) å¯¹...")
    with open(CLOVER_RESULT, 'r') as f:
        content = f.read()

    pairs = re.findall(r"\('?(\d+)'?,\s*'?(\d+)'?\)", content)
    print(f"      Clover éå™ªå£°: {len(pairs)} æ¡")

    idx_to_cid = {}
    for idx_str, cid_str in pairs:
        idx_to_cid[int(idx_str)] = int(cid_str)

    del content, pairs

    # ç»Ÿè®¡æ€» reads
    total_reads = 0
    with open(SRC_READS, 'r') as f:
        for _ in f:
            total_reads += 1
    noise_count = total_reads - len(idx_to_cid)
    print(f"      æ€» reads:   {total_reads}")
    print(f"      æœ‰æ ‡ç­¾:     {len(idx_to_cid)}")
    print(f"      å™ªå£°:       {noise_count} ({noise_count / total_reads * 100:.1f}%)")

    # =========================================================================
    # Step 3.2: æŠ•ç¥¨ Reference
    # =========================================================================
    print("\n[3.2] æŠ•ç¥¨ Reference...")
    cluster_votes = defaultdict(lambda: defaultdict(int))
    with open(SRC_READS, 'r') as f:
        for line_idx_0based, line in enumerate(f):
            parts = line.strip().split()
            if len(parts) < 2:
                continue
            tag = parts[0]
            line_idx_1based = line_idx_0based + 1

            if line_idx_1based in idx_to_cid:
                cid = idx_to_cid[line_idx_1based]
                cluster_votes[cid][tag] += 1

            if (line_idx_0based + 1) % 5000000 == 0:
                print(f"      å·²æŠ•ç¥¨ {line_idx_0based + 1} æ¡...", end='\r')

    print(f"\n      ç»“ç®—æŠ•ç¥¨...")
    ref_dict = load_fasta_references(SRC_REFS)
    cluster_ref_seqs = {}
    matched_count = 0
    for cid, votes in cluster_votes.items():
        best_tag = max(votes, key=votes.get)
        if best_tag in ref_dict:
            cluster_ref_seqs[cid] = ref_dict[best_tag]
            matched_count += 1

    print(f"      æˆåŠŸåŒ¹é… Reference: {matched_count}")
    del cluster_votes, ref_dict

    # =========================================================================
    # Step 3.3: ç”Ÿæˆæ’åºä¸­é—´æ–‡ä»¶ (è£å‰ª reads è‡³ ~150bp)
    # =========================================================================
    print("\n[3.3] ç”Ÿæˆæ’åºä¸­é—´æ–‡ä»¶ (reads è£å‰ªè‡³ 150bp)...")
    temp_unsorted = os.path.join(TEMP_DIR, "unsorted_reads.txt")
    temp_sorted = os.path.join(TEMP_DIR, "sorted_reads.txt")

    # ç»Ÿè®¡é”šç‚¹å‘½ä¸­ç‡
    anchor_hit = 0
    anchor_miss = 0
    written = 0

    with open(SRC_READS, 'r') as fin, open(temp_unsorted, 'w') as fout:
        for line_idx_0based, line in enumerate(fin):
            parts = line.strip().split()
            if len(parts) < 2:
                continue
            line_idx_1based = line_idx_0based + 1

            if line_idx_1based in idx_to_cid:
                cid = idx_to_cid[line_idx_1based]
                if cid in cluster_ref_seqs:
                    raw_seq = parts[-1]
                    # è£å‰ª 177bp â†’ 150bp (å» adapter, ä¿ç•™å¼•ç‰©)
                    model_seq = extract_model_input(raw_seq)

                    if ANCHOR_FWD in raw_seq:
                        anchor_hit += 1
                    else:
                        anchor_miss += 1

                    fout.write(f"{cid}\t{model_seq}\n")
                    written += 1

            if (line_idx_0based + 1) % 5000000 == 0:
                print(f"      å·²å¤„ç† {line_idx_0based + 1} æ¡...", end='\r')

    del idx_to_cid

    total_anchored = anchor_hit + anchor_miss
    print(f"\n      é”šç‚¹å‘½ä¸­ç‡: {anchor_hit}/{total_anchored} "
          f"({anchor_hit / max(total_anchored, 1) * 100:.1f}%)")
    print(f"      å†™å…¥ reads: {written}")

    # =========================================================================
    # Step 3.4: å¤–éƒ¨æ’åº
    # =========================================================================
    print("\n[3.4] å¤–éƒ¨æ’åº...")
    subprocess.run(f"sort -n -k1,1 -S 50% {temp_unsorted} -o {temp_sorted}",
                   shell=True, check=True)
    os.remove(temp_unsorted)

    # =========================================================================
    # Step 3.5: å†™å…¥æœ€ç»ˆæ–‡ä»¶
    # =========================================================================
    print("\n[3.5] å†™å…¥æœ€ç»ˆ read.txt / ref.txt ...")

    # å¤‡ä»½æ—§æ–‡ä»¶
    old_read = os.path.join(FEDDNA_DIR, "read.txt")
    old_ref = os.path.join(FEDDNA_DIR, "ref.txt")
    if os.path.exists(old_read):
        shutil.move(old_read, old_read + ".bak")
    if os.path.exists(old_ref):
        shutil.move(old_ref, old_ref + ".bak")

    out_read = os.path.join(FEDDNA_DIR, "read.txt")
    out_ref = os.path.join(FEDDNA_DIR, "ref.txt")

    current_cid = None
    cluster_count = 0
    read_count = 0

    with open(temp_sorted, 'r') as fin, \
            open(out_read, 'w') as fr, \
            open(out_ref, 'w') as ff:
        for line in fin:
            parts = line.strip().split('\t')
            if len(parts) != 2:
                continue
            cid = int(parts[0])
            seq = parts[1]
            if cid != current_cid:
                if current_cid is not None:
                    fr.write("===============================\n")
                current_cid = cid
                cluster_count += 1
                ref_seq = cluster_ref_seqs[cid]
                ff.write(ref_seq + "\n")
                fr.write(ref_seq + "\n")
            fr.write(seq + "\n")
            read_count += 1
        if current_cid is not None:
            fr.write("===============================\n")

    if os.path.exists(temp_sorted):
        os.remove(temp_sorted)

    print(f"\nğŸ‰ id20 Step 3 ä¿®å¤å®Œæˆï¼")
    print(f"ğŸ“Š æœ‰æ•ˆç°‡:  {cluster_count}")
    print(f"ğŸ“Š æœ‰æ•ˆ reads: {read_count}")
    print(f"ğŸ“Š Read é•¿åº¦: {REF_LEN}bp (ä¸ ref ä¸€è‡´)")

    # å¿«é€ŸéªŒè¯
    print(f"\nğŸ” å¿«é€ŸéªŒè¯...")
    with open(out_read, 'r') as f:
        for i, line in enumerate(f):
            if i >= 5:
                break
            line = line.strip()
            if not line.startswith("="):
                print(f"   read[{i}]: len={len(line)}, head={line[:30]}...")


if __name__ == "__main__":
    main()