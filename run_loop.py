import os
import sys
import torch
import glob
from types import SimpleNamespace
import numpy as np

# å¯¼å…¥ä½ çš„æ¨¡å—
from models.step1_train import train_step1
from models.step2_runner import run_step2
from models.step1_data import CloverDataLoader

# ================= é…ç½®åŒºåŸŸ =================
# 1. åªéœ€è¦ä¿®æ”¹è¿™é‡Œçš„è¾“å…¥è·¯å¾„ï¼Œè¾“å‡ºè·¯å¾„ä¼šè‡ªåŠ¨è·Ÿéš
INPUT_EXP_DIR = "CC/Step0/Experiments/20251224_155232_Cluster_GT_Test"

# è‡ªåŠ¨æå–æ–‡ä»¶å¤¹åç§° (e.g., "20251218_231311_Cluster_GT_Test")
EXP_NAME = os.path.basename(os.path.normpath(INPUT_EXP_DIR))

CONFIG = {
    "experiment_dir": INPUT_EXP_DIR,
    "feddna_checkpoint": "result/FLDNA_I/I_1214234233/model/epoch1_I.pth",
    
    # âœ… ä¿®æ”¹ç‚¹1ï¼šè¾“å‡ºç›®å½•è‡ªåŠ¨å¸¦ä¸Šæ—¶é—´æˆ³
    "base_output_dir": os.path.join("./iterative_results", EXP_NAME),
    
    "max_rounds": 3,
    "device": "cuda",
    "epochs": 15,       # å¤§æ•°æ®é‡ä¸‹ï¼Œ15è½®é€šå¸¸è¶³å¤Ÿï¼Œ30è½®å¯èƒ½å¤ªä¹…
    
    # âœ… ä¿®æ”¹ç‚¹2ï¼šé’ˆå¯¹ç™¾ä¸‡çº§æ•°æ®ï¼Œå¿…é¡»å¢å¤§ Batch Size
    "batch_size": 512,  # å»ºè®® 512 æˆ– 1024
    
    "lr": 1e-4
}
# ===========================================

def calculate_identity(seq1, seq2):
    """è®¡ç®—åºåˆ—ä¸€è‡´æ€§"""
    if not seq1 or not seq2: return 0.0
    L = min(len(seq1), len(seq2))
    matches = sum(1 for a, b in zip(seq1[:L], seq2[:L]) if a == b)
    return matches / max(len(seq1), len(seq2))

def verify_accuracy_smart(consensus_file, gt_data_loader):
    """
    âš ï¸ æ³¨æ„ï¼šå¯¹äº 10,000 ä¸ªç°‡ï¼Œè¿™ä¸ªå‡½æ•°çš„è¿è¡Œæ—¶é—´ä¼šéå¸¸é•¿ï¼ˆO(N^2)å¤æ‚åº¦ï¼‰ã€‚
    å¦‚æœæ˜¯ç™¾ä¸‡çº§æ•°æ®å®éªŒï¼Œå»ºè®®å…ˆè·³è¿‡æ­¤æ­¥éª¤ï¼Œæˆ–è€…åªåœ¨æœ€ç»ˆè½®æ¬¡ç¦»çº¿è¿è¡Œã€‚
    """
    if not os.path.exists(consensus_file): return

    print(f"\nğŸ“Š [Verify] æ™ºèƒ½éªŒè¯å‡†ç¡®åº¦ (Best Match Mode)...")
    
    # 1. è¯»å–é¢„æµ‹åºåˆ—
    pred_seqs = {}
    with open(consensus_file, 'r') as f:
        header = None; seq = []
        for line in f:
            line = line.strip()
            if line.startswith(">"):
                if header: pred_seqs[int(header.split('_')[1])] = "".join(seq)
                header = line; seq = []
            else: seq.append(line)
        if header: pred_seqs[int(header.split('_')[1])] = "".join(seq)

    # 2. è·å– GT
    gt_seqs = gt_data_loader.gt_cluster_seqs
    if not gt_seqs: return

    # ç®€å•è·³è¿‡æ£€æŸ¥ï¼šå¦‚æœç°‡å¤ªå¤šï¼Œä¸ºäº†é˜²æ­¢å¡æ­»ï¼ŒåªéªŒè¯å‰ 100 ä¸ª (å¯é€‰)
    # å¦‚æœä½ æƒ³å…¨é‡éªŒè¯ï¼Œè¯·æ³¨é‡Šæ‰ä¸‹é¢è¿™ä¸¤è¡Œ
    if len(pred_seqs) > 2000:
        print(f"   âš ï¸ ç°‡æ•°é‡è¿‡å¤§ ({len(pred_seqs)})ï¼Œä¸ºèŠ‚çœæ—¶é—´ï¼Œæœ¬æ¬¡è¿­ä»£è·³è¿‡å…¨é‡éªŒè¯ã€‚")
        return

    # 3. å¯»æ‰¾æœ€ä½³åŒ¹é… (Greedy Best Match)
    matches = []
    
    # å¯¹æ¯ä¸ªé¢„æµ‹ç°‡ï¼Œå» GT é‡Œæ‰¾ä¸€ä¸ªæœ€åƒçš„
    for pid, pseq in pred_seqs.items():
        best_id = -1
        best_score = -1.0
        
        for gid, gseq in gt_seqs.items():
            score = calculate_identity(pseq, gseq)
            if score > best_score:
                best_score = score
                best_id = gid
        
        matches.append({
            'pred_id': pid,
            'gt_id': best_id,
            'identity': best_score,
            'pred_seq': pseq,
            'gt_seq': gt_seqs[best_id]
        })

    # 4. ç»Ÿè®¡ç»“æœ
    avg_identity = np.mean([m['identity'] for m in matches])
    perfect_matches = sum(1 for m in matches if m['identity'] > 0.99)
    
    print("\n   ğŸ” æœ€ä½³åŒ¹é…æ ·ä¾‹ (Top 3):")
    for m in sorted(matches, key=lambda x: x['identity'], reverse=True)[:3]:
        print(f"   Pred {m['pred_id']} -> GT {m['gt_id']} | Identity: {m['identity']:.2%}")
        print(f"     GT  : {m['gt_seq'][:30]}...")
        print(f"     PRED: {m['pred_seq'][:30]}...")

    print("\n" + "-"*40)
    print(f"ğŸ† çœŸå®éªŒè¯ç»“æœ (æ ¡æ­£IDå)")
    print(f"âœ… å¹³å‡ä¸€è‡´æ€§: {avg_identity:.2%}")
    print(f"âœ… å®Œç¾åŒ¹é…æ•°: {perfect_matches}/{len(matches)}")
    print("-"*40 + "\n")

def run_loop():
    print(f"ğŸš€ å¼€å§‹ Python è‡ªåŠ¨è¿­ä»£è®­ç»ƒ")
    print(f"ğŸ“‚ è¾“å…¥ç›®å½•: {CONFIG['experiment_dir']}")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {CONFIG['base_output_dir']}")
    print(f"âš™ï¸  Batch Size: {CONFIG['batch_size']}")
    
    prev_labels = None
    current_checkpoint = CONFIG['feddna_checkpoint']
    
    # åŠ è½½ GT æ•°æ® (å¦‚æœæ–‡ä»¶å¾ˆå¤§ï¼Œè¿™ä¸€æ­¥å¯èƒ½ä¼šèŠ±ç‚¹æ—¶é—´)
    print("ğŸ“‚ å°è¯•åŠ è½½ GT æ•°æ®...")
    try: gt_loader = CloverDataLoader(CONFIG['experiment_dir'])
    except: gt_loader = None

    for round_idx in range(1, CONFIG['max_rounds'] + 1):
        print(f"\n{'='*50}\nğŸ”„ Round {round_idx} / {CONFIG['max_rounds']}\n{'='*50}")

        round_dir = os.path.join(CONFIG['base_output_dir'], f"round_{round_idx}")
        step1_out = os.path.join(round_dir, "step1")
        step2_out = os.path.join(round_dir, "step2")
        os.makedirs(step1_out, exist_ok=True)

        # Step 1: è®­ç»ƒ
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æŠŠ batch_size ä¼ è¿›å»
        args_s1 = SimpleNamespace(
            experiment_dir=CONFIG['experiment_dir'],
            output_dir=step1_out,
            epochs=CONFIG['epochs'],
            batch_size=CONFIG['batch_size'],
            lr=CONFIG['lr'],
            weight_decay=1e-5,
            device=CONFIG['device'],
            dim=256, max_length=150, min_clusters=50, max_clusters_per_batch=5,
            save_interval=100,
            feddna_checkpoint=current_checkpoint,
            refined_labels=prev_labels
        )
        print("â–¶ï¸  Running Step 1 (Training)...")
        model_path = train_step1(args_s1)
        current_checkpoint = model_path

        # Step 2: æ¨ç†ä¸ä¿®æ­£
        args_s2 = SimpleNamespace(
            experiment_dir=CONFIG['experiment_dir'],
            step1_checkpoint=model_path,
            output_dir=step2_out,
            uncertainty_percentile=0.2, delta=None, delta_percentile=10,
            dim=256, max_length=150, device=CONFIG['device']
        )
        print("â–¶ï¸  Running Step 2 (Refining)...")
        run_step2(args_s2)
        
        # Verify: éªŒè¯
        # æˆ‘åœ¨ verify_accuracy_smart é‡ŒåŠ äº†ä¿æŠ¤é€»è¾‘ï¼Œå¦‚æœç°‡å¤ªå¤šä¼šè‡ªåŠ¨è·³è¿‡
        if gt_loader:
            verify_accuracy_smart(os.path.join(step2_out, "consensus_sequences.fasta"), gt_loader)

        # Next Round: å‡†å¤‡ä¸‹ä¸€è½®æ ‡ç­¾
        label_dir = os.path.join(CONFIG['experiment_dir'], "04_Iterative_Labels")
        files = glob.glob(os.path.join(label_dir, 'refined_labels_*.txt'))
        if files: 
            # æ‰¾åˆ°æœ€æ–°çš„æ ‡ç­¾æ–‡ä»¶
            prev_labels = max(files, key=os.path.getctime)
            print(f"ğŸ”„ ä¸‹ä¸€è½®å°†ä½¿ç”¨æ ‡ç­¾: {os.path.basename(prev_labels)}")
        else: 
            print("âŒ æœªæ‰¾åˆ°æ–°ç”Ÿæˆçš„æ ‡ç­¾æ–‡ä»¶ï¼Œè¿­ä»£åœæ­¢ã€‚")
            break

if __name__ == "__main__":
    run_loop()