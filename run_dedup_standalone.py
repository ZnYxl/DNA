import os
import argparse
from collections import defaultdict

def parse_header_meta(header):
    """
    è§£æ Header å…ƒæ•°æ®
    æ ¼å¼ç¤ºä¾‹: >cluster_0_reads50_highconf40_strength12.5
    """
    meta = {'header': header, 'count': 0, 'id': -1}
    try:
        parts = header[1:].split('_')
        for p in parts:
            if p.startswith('reads'):
                meta['count'] = int(p.replace('reads', ''))
            elif p.startswith('cluster'):
                meta['id'] = int(p.replace('cluster', ''))
    except:
        pass
    return meta

def load_fasta(path):
    """è¯»å–FASTAå¹¶è§£æ"""
    entries = []
    if not os.path.exists(path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        return entries
    
    with open(path, 'r') as f:
        header = None
        seq_lines = []
        for line in f:
            line = line.strip()
            if line.startswith(">"):
                if header:
                    full_seq = "".join(seq_lines)
                    meta = parse_header_meta(header)
                    meta['seq'] = full_seq
                    entries.append(meta)
                header = line
                seq_lines = []
            else:
                seq_lines.append(line)
        
        # å¤„ç†æœ€åä¸€æ¡
        if header:
            full_seq = "".join(seq_lines)
            meta = parse_header_meta(header)
            meta['seq'] = full_seq
            entries.append(meta)
            
    return entries

def deduplicate(input_path, output_path):
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œåå¤„ç†å»é‡ (Post-processing Deduplication)...")
    print(f"ğŸ“‚ è¾“å…¥æ–‡ä»¶: {input_path}")
    
    # 1. åŠ è½½æ•°æ®
    entries = load_fasta(input_path)
    if not entries: return
    
    total_before = len(entries)
    print(f"   ğŸ“Š åŸå§‹ç°‡æ•°é‡: {total_before}")
    
    # 2. æ’åºï¼šæŒ‰ reads æ•°é‡ä»å¤§åˆ°å°æ’åº
    # é€»è¾‘ï¼šå¦‚æœæœ‰ä¸¤ä¸ªç›¸åŒçš„åºåˆ—ï¼Œæˆ‘ä»¬ä¿ç•™ reads æ•°å¤šçš„é‚£ä¸ªä½œä¸ºä¸»ç°‡
    entries.sort(key=lambda x: x['count'], reverse=True)
    
    # 3. å»é‡é€»è¾‘
    unique_map = {} # seq -> entry
    merged_count = 0
    substring_merged_count = 0
    
    # å…ˆåšä¸€éå®Œå…¨ç²¾ç¡®åŒ¹é…
    for entry in entries:
        seq = entry['seq']
        if seq not in unique_map:
            unique_map[seq] = entry
        else:
            # å‘ç°å®Œå…¨ä¸€æ ·çš„åºåˆ—ï¼Œè§†ä¸ºå†—ä½™ï¼Œç›´æ¥ä¸¢å¼ƒï¼ˆæˆ–åˆå¹¶è®¡æ•°ï¼‰
            merged_count += 1
            # å¯é€‰ï¼šå¦‚æœä½ æƒ³ç´¯åŠ  reads æ•°ï¼Œå¯ä»¥åœ¨è¿™é‡Œåš
            # unique_map[seq]['count'] += entry['count']

    # (å¯é€‰) åšä¸€éå­ä¸²åˆå¹¶ï¼šå¦‚æœé•¿åºåˆ—åŒ…å«äº†çŸ­åºåˆ—ï¼Œä¸”çŸ­åºåˆ—å¾ˆå¯èƒ½æ˜¯ç¢ç‰‡
    # ä¸ºäº†å®‰å…¨ï¼Œè¿™é‡Œåªå¤„ç†éå¸¸æ˜æ˜¾çš„åŒ…å«å…³ç³»
    # æ³¨æ„ï¼šè¿™æ­¥å¤æ‚åº¦è¾ƒé«˜ O(N^2)ï¼Œå¦‚æœåªæœ‰1ä¸‡æ¡æ•°æ®å¾ˆå¿«ï¼Œä½†å¦‚æœæœ‰å‡ åä¸‡æ¡ä¼šæ…¢
    # é‰´äºæˆ‘ä»¬è¦ä¿Recallï¼Œå…ˆåªåšç²¾ç¡®å»é‡ï¼Œè¿™é€šå¸¸èƒ½è§£å†³95%çš„é—®é¢˜
    
    final_entries = list(unique_map.values())
    
    # æ¢å¤æŒ‰IDæ’åºï¼ˆå¯é€‰ï¼Œä¸ºäº†å¥½çœ‹ï¼‰
    final_entries.sort(key=lambda x: x['id'])
    
    # 4. ä¿å­˜
    with open(output_path, 'w') as f:
        for e in final_entries:
            f.write(f"{e['header']}\n{e['seq']}\n")
            
    total_after = len(final_entries)
    
    print(f"\nâœ… å»é‡å®Œæˆ!")
    print(f"   ğŸ“‰ æ¶ˆé™¤å†—ä½™: {merged_count} ({(merged_count/total_before)*100:.2f}%)")
    print(f"   ğŸ æœ€ç»ˆç°‡æ•°: {total_after}")
    print(f"   ğŸ’¾ è¾“å‡ºä¿å­˜: {output_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    # é»˜è®¤ä½¿ç”¨ä½ æä¾›çš„è·¯å¾„
    default_path = "/mnt/st_data/liangxinyi/code/iterative_results/20251224_155232_Cluster_GT_Test copy/round_3/step2/consensus_sequences.fasta"
    
    parser.add_argument('--input', type=str, default=default_path, help='è¾“å…¥FASTAè·¯å¾„')
    parser.add_argument('--output', type=str, default=None, help='è¾“å‡ºFASTAè·¯å¾„ (é»˜è®¤åœ¨åŒç›®å½•ä¸‹åŠ _deduplicated)')
    
    args = parser.parse_args()
    
    if args.output is None:
        args.output = args.input.replace(".fasta", "_deduplicated.fasta")
        
    deduplicate(args.input, args.output)