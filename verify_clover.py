# verify_clover.py
import os
import glob
import numpy as np
import multiprocessing
from functools import partial
import time

# ==========================================
# ğŸ“ ã€é…ç½®åŒºåŸŸã€‘ä¿®æ”¹è¿™é‡Œå³å¯ï¼
# ==========================================
# ä½ çš„å®éªŒè·¯å¾„
EXPERIMENT_DIR = "/mnt/st_data/liangxinyi/code/CC/Step0/Experiments/20251224_155232_Cluster_GT_Test"
# ==========================================

def calculate_identity(seq1, seq2):
    """è®¡ç®—åºåˆ—ä¸€è‡´æ€§ (SOTAæ ‡å‡†)"""
    if not seq1 or not seq2: return 0.0
    L = min(len(seq1), len(seq2))
    matches = sum(1 for a, b in zip(seq1[:L], seq2[:L]) if a == b)
    return matches / max(len(seq1), len(seq2))

def find_best_match_chunk(chunk_data, gt_seqs):
    """
    å¤šè¿›ç¨‹å­ä»»åŠ¡ï¼šä¸ºä¸€æ‰¹ Clover åºåˆ—æ‰¾æœ€ä½³ GT
    chunk_data: list of (clover_id, clover_seq)
    """
    results = []
    gt_items = list(gt_seqs.items())
    
    for cid, c_seq in chunk_data:
        best_score = 0.0
        best_gt_id = -1
        
        # ä¼˜åŒ–ï¼šè™½ç„¶ Clover ID é€šå¸¸ä¸ç­‰äº GT IDï¼Œä½†ä¸‡ä¸€æ’ä¸Šäº†å‘¢ï¼Ÿå…ˆè¯•ä¸€ä¸‹
        if cid in gt_seqs:
            direct_score = calculate_identity(c_seq, gt_seqs[cid])
            if direct_score > 0.8:
                results.append((cid, cid, direct_score))
                continue

        # å…¨é‡æœç´¢ (Full Scan)
        for gid, g_seq in gt_items:
            # ç®€å•é•¿åº¦è¿‡æ»¤åŠ é€Ÿ
            if abs(len(c_seq) - len(g_seq)) > 10: continue
            
            score = calculate_identity(c_seq, g_seq)
            if score > best_score:
                best_score = score
                best_gt_id = gid
            if score == 1.0: break
        
        results.append((cid, best_gt_id, best_score))
    
    return results

class CloverEvaluator:
    def __init__(self, experiment_dir):
        self.exp_dir = experiment_dir
        self.raw_dir = os.path.join(experiment_dir, "01_RawData")
        self.feddna_dir = os.path.join(experiment_dir, "03_FedDNA_In")
        self.gt_cluster_seqs = {} # GT ID -> åºåˆ—
        self.clover_centers = {}  # Clover ID -> åºåˆ—

    def load_ground_truth(self):
        print("ğŸ“‚ 1. åŠ è½½ Ground Truth (GT)...")
        gt_path = os.path.join(self.raw_dir, "ground_truth_clusters.txt")
        if os.path.exists(gt_path):
            with open(gt_path, 'r') as f:
                f.readline()
                for line in f:
                    p = line.strip().split('\t')
                    if len(p) >= 2: 
                        try: self.gt_cluster_seqs[int(p[0])] = p[1]
                        except: continue
        print(f"   - GTç»Ÿè®¡: {len(self.gt_cluster_seqs)} ä¸ª Clusters")

    def load_clover_results(self):
        print("ğŸ“‚ 2. åŠ è½½ Clover ç»“æœ...")
        # å¯»æ‰¾ Clover è¾“å‡ºçš„ä¸­å¿ƒåºåˆ—æ–‡ä»¶ (é€šå¸¸åŒ…å« 'ref' æˆ– 'center')
        center_files = glob.glob(os.path.join(self.feddna_dir, "*ref*.txt")) + \
                       glob.glob(os.path.join(self.feddna_dir, "*center*.txt"))
        
        if center_files:
            target_file = center_files[0]
            print(f"   - å‘ç°ä¸­å¿ƒåºåˆ—æ–‡ä»¶: {os.path.basename(target_file)}")
            
            with open(target_file, 'r') as f:
                # è¿‡æ»¤æ‰ç©ºè¡Œå’Œåˆ†å‰²çº¿
                lines = [line.strip() for line in f if line.strip() and not line.startswith('=')]
            
            has_headers = any(line.startswith('>') for line in lines)
            
            if has_headers:
                # æœ‰ Header çš„æƒ…å†µ
                current_id = 0
                seq_buffer = []
                for line in lines:
                    if line.startswith('>'):
                        if seq_buffer:
                            self.clover_centers[current_id] = "".join(seq_buffer)
                            current_id += 1
                            seq_buffer = []
                        # å°è¯•ä» header è§£æ ID (å¦‚æœæ ¼å¼å…è®¸)
                        try:
                            parts = line.split('_')
                            if len(parts) > 1 and parts[1].isdigit():
                                current_id = int(parts[1])
                        except: pass
                    else:
                        seq_buffer.append(line)
                if seq_buffer:
                    self.clover_centers[current_id] = "".join(seq_buffer)
            else:
                # æ—  Header çš„æƒ…å†µ (Clover é»˜è®¤è¾“å‡º)
                print("   - æœªæ£€æµ‹åˆ° Headerï¼Œå‡è®¾æ¯è¡Œä¸€æ¡åºåˆ— (è¡Œå·=ID)...")
                valid_count = 0
                for idx, line in enumerate(lines):
                    # ç®€å•çš„é•¿åº¦è¿‡æ»¤ï¼Œé˜²æ­¢è¯»å…¥åƒåœ¾æ•°æ®
                    if len(line) > 20: 
                        self.clover_centers[idx] = line
                        valid_count += 1
            print(f"   - åŠ è½½äº† {len(self.clover_centers)} æ¡ Clover ç”Ÿæˆçš„åºåˆ—")
        else:
            print("   âš ï¸ é”™è¯¯ï¼šæœªæ‰¾åˆ° Clover ä¸­å¿ƒåºåˆ—æ–‡ä»¶ï¼è¯·æ£€æŸ¥ 03_FedDNA_In ç›®å½•ã€‚")

    def evaluate(self):
        if not self.clover_centers or not self.gt_cluster_seqs:
            print("âŒ æ•°æ®ç¼ºå¤±ï¼Œæ— æ³•è¯„ä¼°ã€‚")
            return

        print(f"\nâš¡ å¯åŠ¨å¤šè¿›ç¨‹åŒ¹é… (CPUæ ¸å¿ƒæ•°: {min(64, multiprocessing.cpu_count())})...")
        start_time = time.time()

        clover_items = list(self.clover_centers.items())
        num_processes = min(64, multiprocessing.cpu_count())
        chunk_size = len(clover_items) // num_processes + 1
        chunks = [clover_items[i:i + chunk_size] for i in range(0, len(clover_items), chunk_size)]

        pool = multiprocessing.Pool(processes=num_processes)
        func = partial(find_best_match_chunk, gt_seqs=self.gt_cluster_seqs)
        
        all_matches = []
        # å…¼å®¹ tqdm è¿›åº¦æ¡ (å¦‚æœæœ‰å®‰è£…)
        try:
            from tqdm import tqdm
            for res in tqdm(pool.imap_unordered(func, chunks), total=len(chunks), desc="åŒ¹é…è¿›åº¦"):
                all_matches.extend(res)
        except ImportError:
            for res in pool.map(func, chunks):
                all_matches.extend(res)
        
        pool.close()
        pool.join()

        print(f"âœ… åŒ¹é…å®Œæˆ! è€—æ—¶: {time.time() - start_time:.1f}ç§’")

        # ==========================================
        # ğŸ“Š æ ¸å¿ƒç»Ÿè®¡éƒ¨åˆ† (å®Œå…¨å¯¹é½ verify_final)
        # ==========================================
        
        # 1. åŸºç¡€æŒ‡æ ‡
        avg_identity = np.mean([m[2] for m in all_matches])
        
        # 2. Precision (å®Œç¾åŒ¹é…çš„é¢„æµ‹ç°‡å æ¯”)
        perfect_preds = sum(1 for m in all_matches if m[2] > 0.999)
        precision = perfect_preds / len(all_matches) if all_matches else 0

        # 3. Recall (å”¯ä¸€æ‰¾å›çš„GTå æ¯”)
        recovered_gt_ids = set()
        for m in all_matches:
            if m[2] > 0.999:
                recovered_gt_ids.add(m[1]) # m[1] æ˜¯ GT_ID
        
        unique_recovered = len(recovered_gt_ids)
        total_gt = len(self.gt_cluster_seqs)
        recall = unique_recovered / total_gt if total_gt > 0 else 0

        # 4. è¾“å‡ºæŠ¥å‘Š
        print("\n" + "="*60)
        print(f"ğŸ† Clover Baseline éªŒè¯ç»“æœ")
        print("="*60)
        print(f"ğŸ“Š åŸºç¡€æŒ‡æ ‡:")
        print(f"   - é¢„æµ‹ç°‡æ•° (Pred): {len(all_matches)}")
        print(f"   - çœŸå®ç°‡æ•° (GT)  : {total_gt}")
        print(f"   - å¹³å‡ä¸€è‡´æ€§ (Avg Identity): {avg_identity:.2%}")
        print("-" * 30)
        print(f"ğŸ¯ å…³é”®æŒ‡æ ‡ (Strict > 99.9%):")
        print(f"   - å®Œç¾åŒ¹é…æ•° (Perfect Matches): {perfect_preds}")
        print(f"   - å”¯ä¸€GTæ‰¾å›æ•° (Unique GT Recovered): {unique_recovered}")
        print("-" * 30)
        print(f"ğŸŒŸ æœ€ç»ˆå¾—åˆ†:")
        print(f"   âœ… Precision (å‡†ç¡®ç‡): {precision:.2%}")
        print(f"   âœ… Recall    (å¬å›ç‡): {recall:.2%}")
        print("="*60)

if __name__ == "__main__":
    evaluator = CloverEvaluator(EXPERIMENT_DIR)
    evaluator.load_ground_truth()
    evaluator.load_clover_results()
    evaluator.evaluate()