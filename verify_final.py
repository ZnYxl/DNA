# verify_final.py
import os
import numpy as np
import multiprocessing
from functools import partial
import time

# ==========================================
# ğŸ“ ã€è¿™é‡Œæ˜¯ä½ è¦ä¿®æ”¹çš„è·¯å¾„åŒºåŸŸã€‘
# ==========================================
HARDCODED_CONFIG = {
    # 1. é¢„æµ‹ç»“æœæ–‡ä»¶è·¯å¾„ (å¡«é‚£ä¸ªæœªå»é‡çš„æ–‡ä»¶å³å¯ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨æ‰¾å»é‡ç‰ˆçš„)
    "pred_file": "/mnt/st_data/liangxinyi/code/iterative_results/20251224_155232_Cluster_GT_Test copy/round_3/step2/consensus_sequences.fasta",
    
    # 2. Ground Truth æ‰€åœ¨çš„å®éªŒæ ¹ç›®å½•
    "gt_dir": "/mnt/st_data/liangxinyi/code/CC/Step0/Experiments/20251224_155232_Cluster_GT_Test"
}
# ==========================================

def calculate_identity(seq1, seq2):
    """è®¡ç®—åºåˆ—ä¸€è‡´æ€§"""
    if not seq1 or not seq2: return 0.0
    L = min(len(seq1), len(seq2))
    matches = sum(1 for a, b in zip(seq1[:L], seq2[:L]) if a == b)
    return matches / max(len(seq1), len(seq2))

def load_fasta(path):
    """è¯»å–FASTAæ–‡ä»¶"""
    seqs = {}
    if not os.path.exists(path): return seqs
    with open(path, 'r') as f:
        header = None; seq = []
        for line in f:
            line = line.strip()
            if line.startswith(">"):
                # è§£æHeaderä¸­çš„ID
                try:
                    cluster_id = int(header.split('_')[1])
                except:
                    cluster_id = len(seqs) 
                
                if header: seqs[cluster_id] = "".join(seq)
                header = line; seq = []
            else: seq.append(line)
        if header: 
            try:
                cluster_id = int(header.split('_')[1])
            except:
                cluster_id = len(seqs)
            seqs[cluster_id] = "".join(seq)
    return seqs

def load_gt_clusters(experiment_dir):
    """åŠ è½½Ground Truth"""
    gt_path = os.path.join(experiment_dir, "01_RawData", "ground_truth_clusters.txt")
    seqs = {}
    if not os.path.exists(gt_path): return seqs
    with open(gt_path, 'r') as f:
        f.readline()
        for line in f:
            parts = line.strip().split('\t')
            if len(parts) >= 2:
                seqs[int(parts[0])] = parts[1]
    return seqs

def find_best_match_for_chunk(chunk_preds, gt_seqs):
    """å¤šè¿›ç¨‹å­ä»»åŠ¡"""
    results = []
    gt_items = list(gt_seqs.items()) 
    
    for pid, pseq in chunk_preds:
        best_id = -1
        best_score = -1.0
        
        # 1. å¿«é€Ÿè·¯å¾„ï¼šæ£€æŸ¥ç›¸åŒID
        if pid in gt_seqs:
            direct_score = calculate_identity(pseq, gt_seqs[pid])
            if direct_score > 0.8: 
                results.append((pid, pid, direct_score))
                continue
        
        # 2. å…¨ç›˜æ‰«æ
        for gid, gseq in gt_items:
            score = calculate_identity(pseq, gseq)
            if score > best_score:
                best_score = score
                best_id = gid
            if score == 1.0: break 
            
        results.append((pid, best_id, best_score))
    return results

def main():
    print(f"âš™ï¸  è¯»å–ç¡¬ç¼–ç é…ç½®...")
    target_pred = HARDCODED_CONFIG['pred_file']
    gt_dir = HARDCODED_CONFIG['gt_dir']

    # æ™ºèƒ½åˆ‡æ¢é€»è¾‘
    dedup_path = target_pred.replace(".fasta", "_deduplicated.fasta")
    
    if os.path.exists(dedup_path):
        print(f"âœ¨ æ£€æµ‹åˆ°å»é‡ç‰ˆæ–‡ä»¶å­˜åœ¨ï¼Œä¼˜å…ˆéªŒè¯å»é‡ç‰ˆï¼")
        final_pred_path = dedup_path
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°å»é‡ç‰ˆï¼ŒéªŒè¯åŸå§‹æ–‡ä»¶ã€‚")
        final_pred_path = target_pred

    print(f"ğŸ“‚ æ­£åœ¨éªŒè¯æ–‡ä»¶: {final_pred_path}")
    if not os.path.exists(final_pred_path):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ -> {final_pred_path}")
        return

    # åŠ è½½æ•°æ®
    pred_seqs = load_fasta(final_pred_path)
    print(f"   - é¢„æµ‹ç°‡æ•°é‡: {len(pred_seqs)}")
    
    print(f"ğŸ“‚ è¯»å– GT: {gt_dir}")
    gt_seqs = load_gt_clusters(gt_dir)
    print(f"   - çœŸå®ç°‡æ•°é‡: {len(gt_seqs)}")
    
    if not pred_seqs or not gt_seqs:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥ã€‚")
        return

    # å¤šè¿›ç¨‹åŒ¹é…
    num_cpus = min(64, multiprocessing.cpu_count())
    print(f"\nâš¡ å¯åŠ¨å¤šè¿›ç¨‹åŒ¹é… (CPUæ ¸å¿ƒæ•°: {num_cpus})...")
    start_time = time.time()
    
    pred_items = list(pred_seqs.items())
    chunk_size = len(pred_items) // num_cpus + 1
    chunks = [pred_items[i:i + chunk_size] for i in range(0, len(pred_items), chunk_size)]
    
    pool = multiprocessing.Pool(processes=num_cpus)
    func = partial(find_best_match_for_chunk, gt_seqs=gt_seqs)
    
    all_matches = []
    # å…¼å®¹ tqdm
    try:
        from tqdm import tqdm
        for res in tqdm(pool.imap_unordered(func, chunks), total=len(chunks), desc="åŒ¹é…ä¸­"):
            all_matches.extend(res)
    except ImportError:
        for res in pool.map(func, chunks):
            all_matches.extend(res)
        
    pool.close()
    pool.join()
    
    print(f"âœ… åŒ¹é…å®Œæˆ! è€—æ—¶: {time.time() - start_time:.1f}ç§’")

    # ç»Ÿè®¡æŒ‡æ ‡
    avg_identity = np.mean([m[2] for m in all_matches])
    
    # Precision: å®Œç¾åŒ¹é…çš„é¢„æµ‹ç°‡å æ¯”
    perfect_preds = sum(1 for m in all_matches if m[2] > 0.999)
    precision = perfect_preds / len(all_matches) if all_matches else 0

    # Recall: å”¯ä¸€æ‰¾å›çš„GTå æ¯”
    recovered_gt_ids = set()
    for m in all_matches:
        if m[2] > 0.999:
            recovered_gt_ids.add(m[1]) 
            
    unique_recovered = len(recovered_gt_ids)
    recall = unique_recovered / len(gt_seqs)

    print("\n" + "="*60)
    print(f"ğŸ† æœ€ç»ˆéªŒè¯ç»“æœ")
    print("="*60)
    print(f"ğŸ“‚ éªŒè¯æ–‡ä»¶: {os.path.basename(final_pred_path)}")
    print(f"ğŸ“Š åŸºç¡€æŒ‡æ ‡:")
    print(f"   - é¢„æµ‹ç°‡æ•° (Pred): {len(all_matches)}")
    print(f"   - çœŸå®ç°‡æ•° (GT)  : {len(gt_seqs)}")
    print(f"   - å¹³å‡ä¸€è‡´æ€§ (Avg Identity): {avg_identity:.2%}")
    print("-" * 30)
    print(f"ğŸ¯ å…³é”®æŒ‡æ ‡ (Strict > 99.9%):")
    print(f"   - å®Œç¾åŒ¹é…æ•° (Perfect Matches): {perfect_preds}")
    print(f"   - å”¯ä¸€GTæ‰¾å›æ•° (Unique GT Recovered): {unique_recovered}")
    print("-" * 30)
    print(f"ğŸŒŸ æœ€ç»ˆå¾—åˆ†:")
    print(f"   âœ… Precision (å‡†ç¡®ç‡/å»å™ªèƒ½åŠ›): {precision:.2%}")
    print(f"   âœ… Recall    (å¬å›ç‡/æ¢å¤èƒ½åŠ›): {recall:.2%}")
    print("="*60)

if __name__ == "__main__":
    main()